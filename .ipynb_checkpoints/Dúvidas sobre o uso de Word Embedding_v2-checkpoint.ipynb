{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/share/tfhome/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/share/tfhome/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/share/tfhome/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/share/tfhome/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/share/tfhome/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/share/tfhome/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import text, sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers, models, optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "#from keras.layers import Attention\n",
    "from keras.initializers import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import nltk\n",
    "from  nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teses_mesmas_areas_Large = pd.read_json('teses_mesmas_areas.json', orient = 'index')\n",
    "tese_area_oposta_Large = pd.read_json('teses_areas_opostas.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assuntos em Ingl√™s:</th>\n",
       "      <th>Assuntos em Portug√™s:</th>\n",
       "      <th>Autor/a:</th>\n",
       "      <th>Banca:</th>\n",
       "      <th>Cita√ß√£o:</th>\n",
       "      <th>Co-advisor:</th>\n",
       "      <th>Data de Defesa:</th>\n",
       "      <th>Departamento:</th>\n",
       "      <th>Download Texto Completo:</th>\n",
       "      <th>Idioma:</th>\n",
       "      <th>...</th>\n",
       "      <th>N√≠vel de Acesso:</th>\n",
       "      <th>Orientador/a:</th>\n",
       "      <th>Outros Autores:</th>\n",
       "      <th>Programa:</th>\n",
       "      <th>Resumo Portugu√™s:</th>\n",
       "      <th>Resumo ingl√™s:</th>\n",
       "      <th>Spanish Subjects:</th>\n",
       "      <th>Tipo Documento:</th>\n",
       "      <th>Title</th>\n",
       "      <th>√Åreas de Conhecimento:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UFMA_d45638bb09fc68a4155a3096665bd1bc</th>\n",
       "      <td>[nitrogen, irrigation interval, chlorophyll, s...</td>\n",
       "      <td>[nitrog√™nio, intervalo de irriga√ß√£o, clorofila...</td>\n",
       "      <td>\\n\\n        Silva, Antonia de Lima da\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SILVA, Antonia de Lima da. COVERAGE OF THE USE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>\\nBiologia\\n\\n</td>\n",
       "      <td>http://tedebc.ufma.br:8080/jspui/handle/tede/556</td>\n",
       "      <td>por</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        Moura, Emanoel Gomes de\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nPROGRAMA DE P√ìS-GRADUA√á√ÉO EM CI√äNCIA ANIMAL ...</td>\n",
       "      <td>No tr√≥pico √∫mido, a constru√ß√£o e manuten√ß√£o da...</td>\n",
       "      <td>In the humid tropics, construction and soil fe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disserta√ß√£o\\n</td>\n",
       "      <td>INFLU√äNCIA DO USO DE COBERTURA SOBRE A RESIST√ä...</td>\n",
       "      <td>[CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef9f2bfc2fb2fd7a033b0d24586</th>\n",
       "      <td>[ontologies reuse, ontologies join, similarity...</td>\n",
       "      <td>[re√∫so de ontologias, jun√ß√£o de ontologias, an...</td>\n",
       "      <td>\\n\\n        Silva, Antonio Fhillipi Maciel\\n\\n</td>\n",
       "      <td>\\n\\n        Silva, Francisco Jos√© da Silva e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>\\nEngenharia\\n\\n</td>\n",
       "      <td>http://tedebc.ufma.br:8080/jspui/handle/tede/288</td>\n",
       "      <td>por</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        GIRARDI, Rosario\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nPROGRAMA DE P√ìS-GRADUA√á√ÉO EM ENGENHARIA DE E...</td>\n",
       "      <td>O re√∫so de ontologias √© um processo em que o c...</td>\n",
       "      <td>The reuse of ontologies is a process in which ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disserta√ß√£o\\n</td>\n",
       "      <td>UMA ABORDAGEM PARA A JUN√á√ÉO DE ONTOLOGIAS E SU...</td>\n",
       "      <td>[CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UFMA_44c077ce968f29f322703453ca6893b4</th>\n",
       "      <td>[surface temperature, radiation balance, SEBAL]</td>\n",
       "      <td>[temperatura de superf√≠cie, saldo de radia√ß√£o,...</td>\n",
       "      <td>\\n\\n        Marques, F√°bio Marcelo Ferreira\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARQUES, F√°bio Marcelo Ferreira. ESTIMATE OF T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>\\nEnergia e Ambiente\\n\\n</td>\n",
       "      <td>http://tedebc.ufma.br:8080/jspui/handle/tede/681</td>\n",
       "      <td>por</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        BEZERRA, C√≠cero Wellington Brito\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nPROGRAMA DE P√ìS-GRADUA√á√ÉO EM ENERGIA E AMBIE...</td>\n",
       "      <td>Muito se discute sobre as contribui√ß√µes antr√≥p...</td>\n",
       "      <td>A lot of discussion about anthropogenic contri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disserta√ß√£o\\n</td>\n",
       "      <td>ESTIMATIVA DA TEMPERATURA SUPERFICIAL E DO SAL...</td>\n",
       "      <td>[CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UFG_24e5b485acfc4d60002260f45106c5b7</th>\n",
       "      <td>[Cultural-Historical theory, Education for you...</td>\n",
       "      <td>[Teoria Hist√≥rico-Cultural, Educa√ß√£o de Jovens...</td>\n",
       "      <td>\\n\\n        JACINTO, Everton Lacerda\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JACINTO, Everton Lacerda. The pedagogical acti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>\\nCi√™ncias Exatas e da Terra\\n\\n</td>\n",
       "      <td>http://repositorio.bc.ufg.br/tede/handle/tde/552</td>\n",
       "      <td>por</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        CEDRO, Wellington Lima\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nMestrado em Educa√ß√£o em Ci√™ncias e Matem√°tic...</td>\n",
       "      <td>Esta disserta√ß√£o discute a rela√ß√£o existente e...</td>\n",
       "      <td>This thesis shall discuss the existent relatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disserta√ß√£o\\n</td>\n",
       "      <td>A atividade pedag√≥gica do professor de Matem√°t...</td>\n",
       "      <td>[CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UFG_991bc2cbce926c68edac691fc4c530a1</th>\n",
       "      <td>[Performance, Educational management and educa...</td>\n",
       "      <td>[Avalia√ß√£o de professores, Desempenho, Gest√£o ...</td>\n",
       "      <td>\\n\\n        SIQUEIRA, Ivone dos Santos\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIQUEIRA, Ivone dos Santos. Avalia√ß√£o de desem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>\\nCi√™ncias Exatas e da Terra\\n\\n</td>\n",
       "      <td>http://repositorio.bc.ufg.br/tede/handle/tde/553</td>\n",
       "      <td>por</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        CHAVES, Sandramara Matias\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nMestrado em Educa√ß√£o em Ci√™ncias e Matem√°tic...</td>\n",
       "      <td>Esta investiga√ß√£o tem a avalia√ß√£o de desempenh...</td>\n",
       "      <td>This investigation has the evaluation of teach...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disserta√ß√£o\\n</td>\n",
       "      <td>Avalia√ß√£o de desempenho de professores na rede...</td>\n",
       "      <td>[CNPQ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  Assuntos em Ingl√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  [nitrogen, irrigation interval, chlorophyll, s...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  [ontologies reuse, ontologies join, similarity...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...    [surface temperature, radiation balance, SEBAL]   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  [Cultural-Historical theory, Education for you...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  [Performance, Educational management and educa...   \n",
       "\n",
       "                                                                                Assuntos em Portug√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  [nitrog√™nio, intervalo de irriga√ß√£o, clorofila...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  [re√∫so de ontologias, jun√ß√£o de ontologias, an...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  [temperatura de superf√≠cie, saldo de radia√ß√£o,...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  [Teoria Hist√≥rico-Cultural, Educa√ß√£o de Jovens...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  [Avalia√ß√£o de professores, Desempenho, Gest√£o ...   \n",
       "\n",
       "                                                                                           Autor/a:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...        \\n\\n        Silva, Antonia de Lima da\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...   \\n\\n        Silva, Antonio Fhillipi Maciel\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  \\n\\n        Marques, F√°bio Marcelo Ferreira\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...         \\n\\n        JACINTO, Everton Lacerda\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...       \\n\\n        SIQUEIRA, Ivone dos Santos\\n\\n   \n",
       "\n",
       "                                                                                          Banca:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...                                           NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  \\n\\n        Silva, Francisco Jos√© da Silva e   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...                                           NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...                                           NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...                                           NaN   \n",
       "\n",
       "                                                                                             Cita√ß√£o:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  SILVA, Antonia de Lima da. COVERAGE OF THE USE...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...                                                NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  MARQUES, F√°bio Marcelo Ferreira. ESTIMATE OF T...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  JACINTO, Everton Lacerda. The pedagogical acti...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  SIQUEIRA, Ivone dos Santos. Avalia√ß√£o de desem...   \n",
       "\n",
       "                                                   Co-advisor:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...         NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...         NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...         NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...         NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...         NaN   \n",
       "\n",
       "                                                    Data de Defesa:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...             2015   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...             2014   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...             2014   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...             2011   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...             2011   \n",
       "\n",
       "                                                                       Departamento:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...                    \\nBiologia\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...                  \\nEngenharia\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...          \\nEnergia e Ambiente\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  \\nCi√™ncias Exatas e da Terra\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  \\nCi√™ncias Exatas e da Terra\\n\\n   \n",
       "\n",
       "                                                                            Download Texto Completo:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  http://tedebc.ufma.br:8080/jspui/handle/tede/556   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  http://tedebc.ufma.br:8080/jspui/handle/tede/288   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  http://tedebc.ufma.br:8080/jspui/handle/tede/681   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  http://repositorio.bc.ufg.br/tede/handle/tde/552   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  http://repositorio.bc.ufg.br/tede/handle/tde/553   \n",
       "\n",
       "                                                   Idioma:  ...  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...     por  ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...     por  ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...     por  ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...     por  ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...     por  ...   \n",
       "\n",
       "                                                   N√≠vel de Acesso:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...       openAccess   \n",
       "\n",
       "                                                                                       Orientador/a:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...           \\n\\n        Moura, Emanoel Gomes de\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...                  \\n\\n        GIRARDI, Rosario\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  \\n\\n        BEZERRA, C√≠cero Wellington Brito\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...            \\n\\n        CEDRO, Wellington Lima\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...         \\n\\n        CHAVES, Sandramara Matias\\n\\n   \n",
       "\n",
       "                                                   Outros Autores:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...             NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...             NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...             NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...             NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...             NaN   \n",
       "\n",
       "                                                                                            Programa:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  \\nPROGRAMA DE P√ìS-GRADUA√á√ÉO EM CI√äNCIA ANIMAL ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  \\nPROGRAMA DE P√ìS-GRADUA√á√ÉO EM ENGENHARIA DE E...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  \\nPROGRAMA DE P√ìS-GRADUA√á√ÉO EM ENERGIA E AMBIE...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  \\nMestrado em Educa√ß√£o em Ci√™ncias e Matem√°tic...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  \\nMestrado em Educa√ß√£o em Ci√™ncias e Matem√°tic...   \n",
       "\n",
       "                                                                                    Resumo Portugu√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  No tr√≥pico √∫mido, a constru√ß√£o e manuten√ß√£o da...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  O re√∫so de ontologias √© um processo em que o c...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  Muito se discute sobre as contribui√ß√µes antr√≥p...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  Esta disserta√ß√£o discute a rela√ß√£o existente e...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  Esta investiga√ß√£o tem a avalia√ß√£o de desempenh...   \n",
       "\n",
       "                                                                                       Resumo ingl√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  In the humid tropics, construction and soil fe...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  The reuse of ontologies is a process in which ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  A lot of discussion about anthropogenic contri...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  This thesis shall discuss the existent relatio...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  This investigation has the evaluation of teach...   \n",
       "\n",
       "                                                   Spanish Subjects:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...               NaN   \n",
       "\n",
       "                                                   Tipo Documento:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...   Disserta√ß√£o\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...   Disserta√ß√£o\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...   Disserta√ß√£o\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...   Disserta√ß√£o\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...   Disserta√ß√£o\\n   \n",
       "\n",
       "                                                                                                Title  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...  INFLU√äNCIA DO USO DE COBERTURA SOBRE A RESIST√ä...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...  UMA ABORDAGEM PARA A JUN√á√ÉO DE ONTOLOGIAS E SU...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...  ESTIMATIVA DA TEMPERATURA SUPERFICIAL E DO SAL...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...  A atividade pedag√≥gica do professor de Matem√°t...   \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...  Avalia√ß√£o de desempenho de professores na rede...   \n",
       "\n",
       "                                                   √Åreas de Conhecimento:  \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_d45638b...                 [CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_4d026ef...                 [CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UFMA_44c077c...                 [CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_24e5b485...                 [CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UFG_991bc2cb...                 [CNPQ]  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teses_mesmas_areas_Large.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assuntos em Ingl√™s:</th>\n",
       "      <th>Assuntos em Portug√™s:</th>\n",
       "      <th>Autor/a:</th>\n",
       "      <th>Banca:</th>\n",
       "      <th>Cita√ß√£o:</th>\n",
       "      <th>Co-advisor:</th>\n",
       "      <th>Data de Defesa:</th>\n",
       "      <th>Departamento:</th>\n",
       "      <th>Download Texto Completo:</th>\n",
       "      <th>Idioma:</th>\n",
       "      <th>Institui√ß√£o de Defesa:</th>\n",
       "      <th>N√≠vel de Acesso:</th>\n",
       "      <th>Orientador/a:</th>\n",
       "      <th>Programa:</th>\n",
       "      <th>Resumo Portugu√™s:</th>\n",
       "      <th>Resumo ingl√™s:</th>\n",
       "      <th>Spanish Subjects:</th>\n",
       "      <th>Tipo Documento:</th>\n",
       "      <th>Title</th>\n",
       "      <th>√Åreas de Conhecimento:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UPM_86400ff41b4cf4bb2218f2e65700dd99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[explos√µes solares, processos nucleares de alt...</td>\n",
       "      <td>\\n\\n        Serra, Jordi Tuneu\\n\\n</td>\n",
       "      <td>\\n\\n        Raulin, Jean Pierre\\n\\n, \\n\\n     ...</td>\n",
       "      <td>SERRA, Jordi Tuneu. Contribui√ß√£o de p√≥sitrons ...</td>\n",
       "      <td>\\n\\n        Castro, Carlos Guillermo Gim√©nez d...</td>\n",
       "      <td>2017</td>\n",
       "      <td>\\nEscola de Engenharia Mackenzie (EE)\\n\\n</td>\n",
       "      <td>http://tede.mackenzie.br/jspui/handle/tede/3550</td>\n",
       "      <td>por</td>\n",
       "      <td>\\nUniversidade Presbiteriana Mackenzie\\n\\n</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        Szpigel, S√©rgio\\n\\n</td>\n",
       "      <td>\\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n</td>\n",
       "      <td>Observa√ß√µes recentes de explos√µes solares em a...</td>\n",
       "      <td>Recent observations of solar flares at high-fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disserta√ß√£o\\n</td>\n",
       "      <td>Contribui√ß√£o de p√≥sitrons e el√©trons secund√°ri...</td>\n",
       "      <td>[CNPQ, CNPQ, CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UPM_e2c110c67f2cb061bdc5fbca1a72cc98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[interfaces gestuais, framework, guidelins, tr...</td>\n",
       "      <td>\\n\\n        Sousa, Leonardo Ramon Nunes de\\n\\n</td>\n",
       "      <td>\\n\\n        Martins, Val√©ria Farinazzo\\n\\n, \\n...</td>\n",
       "      <td>SOUSA, Leonardo Ramon Nunes de. Framework para...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>\\nFaculdade de Computa√ß√£o e Inform√°tica (FCI)\\n\\n</td>\n",
       "      <td>http://tede.mackenzie.br/jspui/handle/tede/3452</td>\n",
       "      <td>por</td>\n",
       "      <td>\\nUniversidade Presbiteriana Mackenzie\\n\\n</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        Silveira, Ismar Frango\\n\\n</td>\n",
       "      <td>\\nEngenharia El√©trica\\n\\n</td>\n",
       "      <td>Ferramentas computacionais que se utilizam de ...</td>\n",
       "      <td>Gestural interfaces-based computational tools ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tese\\n</td>\n",
       "      <td>Framework para cria√ß√£o de interfaces gestuais ...</td>\n",
       "      <td>[CNPQ, CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UPM_d0797ffcd897867689e3fc605d16fc97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[periodograma, box fitting, detec√ß√£o de exopla...</td>\n",
       "      <td>\\n\\n        Basile, Antonio Luiz\\n\\n</td>\n",
       "      <td>\\n\\n        Silveira, Ismar Frango\\n\\n, \\n\\n  ...</td>\n",
       "      <td>BASILE, Antonio Luiz. Servi√ßo local de periodo...</td>\n",
       "      <td>\\n\\n        Silva, Luciano\\n\\n</td>\n",
       "      <td>2017</td>\n",
       "      <td>\\nEscola de Engenharia Mackenzie (EE)\\n\\n</td>\n",
       "      <td>http://tede.mackenzie.br/jspui/handle/tede/3469</td>\n",
       "      <td>por</td>\n",
       "      <td>\\nUniversidade Presbiteriana Mackenzie\\n\\n</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        Valio, Adriana Benetti Marques\\n\\n</td>\n",
       "      <td>\\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n</td>\n",
       "      <td>A compreens√£o de outros sistemas estelares √© c...</td>\n",
       "      <td>Understanding other stellar systems is crucial...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tese\\n</td>\n",
       "      <td>Servi√ßo local de periodograma em GPU para dete...</td>\n",
       "      <td>[CNPQ, CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84252a7e1a8487e2cd386cd3fa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[explos√µes solares, processos nucleares de alt...</td>\n",
       "      <td>\\n\\n        Tusnski, Daneele Sara√ßol\\n\\n</td>\n",
       "      <td>\\n\\n        Valio, Adriana Benetti Marques\\n\\n...</td>\n",
       "      <td>TUSNSKI, Daneele Sara√ßol. Modelagem de process...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>\\nEscola de Engenharia Mackenzie (EE)\\n\\n</td>\n",
       "      <td>http://tede.mackenzie.br/jspui/handle/tede/3695</td>\n",
       "      <td>por</td>\n",
       "      <td>\\nUniversidade Presbiteriana Mackenzie\\n\\n</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        Szpigel, S√©rgio\\n\\n</td>\n",
       "      <td>\\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n</td>\n",
       "      <td>A emiss√£o de raios-ùõæ em explos√µes solares √© pr...</td>\n",
       "      <td>The emission of ùõæ-rays in solar flares is prod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tese\\n</td>\n",
       "      <td>Modelagem de processos nucleares de alta energ...</td>\n",
       "      <td>[CNPQ, CNPQ, CNPQ, CNPQ, CNPQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://bdtd.ibict.br/vufind/Record/UPM_7539ec7aa2a2ee38b2ae47b3fe5ae091</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[atmosfera solar, sol, SST, emiss√£o milim√©tric...</td>\n",
       "      <td>\\n\\n        Pereira, Andr√© Luiz Garcia\\n\\n</td>\n",
       "      <td>\\n\\n        Correia, Emilia\\n\\n, \\n\\n        S...</td>\n",
       "      <td>PEREIRA, Andr√© Luiz Garcia. Desenvolvimento de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>\\nEscola de Engenharia Mackenzie (EE)\\n\\n</td>\n",
       "      <td>http://tede.mackenzie.br/jspui/handle/tede/3691</td>\n",
       "      <td>por</td>\n",
       "      <td>\\nUniversidade Presbiteriana Mackenzie\\n\\n</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>\\n\\n        Castro, Carlos Guillermo Gim√©nez d...</td>\n",
       "      <td>\\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n</td>\n",
       "      <td>O Telesc√≥pio Solar Submilim√©trico (SST) opera ...</td>\n",
       "      <td>The Submillimeter Solar Telescope (SST) operat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tese\\n</td>\n",
       "      <td>Desenvolvimento de metodologias para o reconhe...</td>\n",
       "      <td>[CNPQ, CNPQ, CNPQ, CNPQ, CNPQ, CNPQ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Assuntos em Ingl√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...                 NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...                 NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...                 NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...                 NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...                 NaN   \n",
       "\n",
       "                                                                                Assuntos em Portug√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  [explos√µes solares, processos nucleares de alt...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  [interfaces gestuais, framework, guidelins, tr...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  [periodograma, box fitting, detec√ß√£o de exopla...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  [explos√µes solares, processos nucleares de alt...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  [atmosfera solar, sol, SST, emiss√£o milim√©tric...   \n",
       "\n",
       "                                                                                          Autor/a:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...              \\n\\n        Serra, Jordi Tuneu\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  \\n\\n        Sousa, Leonardo Ramon Nunes de\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...            \\n\\n        Basile, Antonio Luiz\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...        \\n\\n        Tusnski, Daneele Sara√ßol\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...      \\n\\n        Pereira, Andr√© Luiz Garcia\\n\\n   \n",
       "\n",
       "                                                                                               Banca:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  \\n\\n        Raulin, Jean Pierre\\n\\n, \\n\\n     ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  \\n\\n        Martins, Val√©ria Farinazzo\\n\\n, \\n...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  \\n\\n        Silveira, Ismar Frango\\n\\n, \\n\\n  ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  \\n\\n        Valio, Adriana Benetti Marques\\n\\n...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  \\n\\n        Correia, Emilia\\n\\n, \\n\\n        S...   \n",
       "\n",
       "                                                                                             Cita√ß√£o:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  SERRA, Jordi Tuneu. Contribui√ß√£o de p√≥sitrons ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  SOUSA, Leonardo Ramon Nunes de. Framework para...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  BASILE, Antonio Luiz. Servi√ßo local de periodo...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  TUSNSKI, Daneele Sara√ßol. Modelagem de process...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  PEREIRA, Andr√© Luiz Garcia. Desenvolvimento de...   \n",
       "\n",
       "                                                                                          Co-advisor:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  \\n\\n        Castro, Carlos Guillermo Gim√©nez d...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...                                                NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...                     \\n\\n        Silva, Luciano\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...                                                NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...                                                NaN   \n",
       "\n",
       "                                                    Data de Defesa:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...             2017   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...             2017   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...             2017   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...             2018   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...             2018   \n",
       "\n",
       "                                                                                        Departamento:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...          \\nEscola de Engenharia Mackenzie (EE)\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  \\nFaculdade de Computa√ß√£o e Inform√°tica (FCI)\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...          \\nEscola de Engenharia Mackenzie (EE)\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...          \\nEscola de Engenharia Mackenzie (EE)\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...          \\nEscola de Engenharia Mackenzie (EE)\\n\\n   \n",
       "\n",
       "                                                                           Download Texto Completo:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  http://tede.mackenzie.br/jspui/handle/tede/3550   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  http://tede.mackenzie.br/jspui/handle/tede/3452   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  http://tede.mackenzie.br/jspui/handle/tede/3469   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  http://tede.mackenzie.br/jspui/handle/tede/3695   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  http://tede.mackenzie.br/jspui/handle/tede/3691   \n",
       "\n",
       "                                                   Idioma:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...     por   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...     por   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...     por   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...     por   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...     por   \n",
       "\n",
       "                                                                        Institui√ß√£o de Defesa:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  \\nUniversidade Presbiteriana Mackenzie\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  \\nUniversidade Presbiteriana Mackenzie\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  \\nUniversidade Presbiteriana Mackenzie\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  \\nUniversidade Presbiteriana Mackenzie\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  \\nUniversidade Presbiteriana Mackenzie\\n\\n   \n",
       "\n",
       "                                                   N√≠vel de Acesso:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...       openAccess   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...       openAccess   \n",
       "\n",
       "                                                                                        Orientador/a:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...                    \\n\\n        Szpigel, S√©rgio\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...             \\n\\n        Silveira, Ismar Frango\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...     \\n\\n        Valio, Adriana Benetti Marques\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...                    \\n\\n        Szpigel, S√©rgio\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  \\n\\n        Castro, Carlos Guillermo Gim√©nez d...   \n",
       "\n",
       "                                                                                   Programa:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  \\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...                 \\nEngenharia El√©trica\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  \\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  \\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  \\nCi√™ncias e Aplica√ß√µes Geoespaciais\\n\\n   \n",
       "\n",
       "                                                                                    Resumo Portugu√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  Observa√ß√µes recentes de explos√µes solares em a...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  Ferramentas computacionais que se utilizam de ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  A compreens√£o de outros sistemas estelares √© c...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  A emiss√£o de raios-ùõæ em explos√µes solares √© pr...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  O Telesc√≥pio Solar Submilim√©trico (SST) opera ...   \n",
       "\n",
       "                                                                                       Resumo ingl√™s:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  Recent observations of solar flares at high-fr...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  Gestural interfaces-based computational tools ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  Understanding other stellar systems is crucial...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  The emission of ùõæ-rays in solar flares is prod...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  The Submillimeter Solar Telescope (SST) operat...   \n",
       "\n",
       "                                                   Spanish Subjects:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...               NaN   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...               NaN   \n",
       "\n",
       "                                                   Tipo Documento:  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...   Disserta√ß√£o\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...          Tese\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...          Tese\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...          Tese\\n   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...          Tese\\n   \n",
       "\n",
       "                                                                                                Title  \\\n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...  Contribui√ß√£o de p√≥sitrons e el√©trons secund√°ri...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...  Framework para cria√ß√£o de interfaces gestuais ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...  Servi√ßo local de periodograma em GPU para dete...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...  Modelagem de processos nucleares de alta energ...   \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  Desenvolvimento de metodologias para o reconhe...   \n",
       "\n",
       "                                                                  √Åreas de Conhecimento:  \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_86400ff4...                    [CNPQ, CNPQ, CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_e2c110c6...                          [CNPQ, CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d0797ffc...                          [CNPQ, CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_d57d1f84...        [CNPQ, CNPQ, CNPQ, CNPQ, CNPQ]  \n",
       "http://bdtd.ibict.br/vufind/Record/UPM_7539ec7a...  [CNPQ, CNPQ, CNPQ, CNPQ, CNPQ, CNPQ]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tese_area_oposta_Large.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acrescentando a classe nos dois DataFrame\n",
    "teses_mesmas_areas_Large['classe'] = 'Mesma Area'\n",
    "tese_area_oposta_Large ['classe'] = 'Area Oposta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo teses sem resumo em portugues\n",
    "teses_mesmas_areas_Large = teses_mesmas_areas_Large[(teses_mesmas_areas_Large['Resumo Portugu√™s:'].notnull())]\n",
    "tese_area_oposta_Large = tese_area_oposta_Large[(tese_area_oposta_Large['Resumo Portugu√™s:'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessando o texto\n",
    "teses_mesmas_areas_Large['Resumo Portugu√™s:'] = (teses_mesmas_areas_Large['Resumo Portugu√™s:'].apply(gensim.utils.simple_preprocess)\n",
    "                                                 .str.join(\" \"))\n",
    "tese_area_oposta_Large['Resumo Portugu√™s:'] = (tese_area_oposta_Large['Resumo Portugu√™s:'].apply(gensim.utils.simple_preprocess)\n",
    "                                               .str.join(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo o conjunto de treino, valida√ß√£o e de teste\n",
    "\n",
    "Vamos dividir os dados em 80% treino e 20% teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/tfhome/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "frames = [teses_mesmas_areas_Large, tese_area_oposta_Large]\n",
    "tese_area_large = pd.concat(frames)\n",
    "tese_area_large = tese_area_large.drop_duplicates(subset='Title', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fun√ß√£o que pega um dataframe com as teses e retorna tr√™s dataframes com dados de treino, valida√ß√£o e teste.\n",
    "#'train' √© a fra√ß√£o dos dados para treino, 'valid' √© a fra√ß√£o dos dados para valida√ß√£o, o restante √© para teste\n",
    "def train_test(teses, train):\n",
    "    corte_train = int(round((len(teses)*train),0))\n",
    "    teses = teses.sample(frac=1)\n",
    "    teses_train = teses[:corte_train]\n",
    "    teses_test = teses[corte_train:]\n",
    "    return(teses_train, teses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tese_train, tese_test = train_test(tese_area_large, 0.8)\n",
    "tese_train = tese_train.sample(frac=1).reset_index(drop=True)\n",
    "tese_test = tese_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesmas_areas_train, mesmas_areas_test = train_test(teses_mesmas_areas_Large, 0.8)\n",
    "#area_oposta_train, area_oposta_test = train_test(tese_area_oposta_Large, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "#tese_train = mesmas_areas_train\n",
    "#tese_train = tese_train.append(area_oposta_train)\n",
    "#tese_train = tese_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Test\n",
    "#tese_test = mesmas_areas_test\n",
    "#tese_test = tese_test.append(area_oposta_test)\n",
    "#tese_test = tese_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando texto e classe\n",
    "train_x = tese_train['Resumo Portugu√™s:']\n",
    "train_y = tese_train['classe']\n",
    "\n",
    "test_x = tese_test['Resumo Portugu√™s:']\n",
    "test_y = tese_test['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y  = encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petrobras =  1\n",
      "Outro =  0\n"
     ]
    }
   ],
   "source": [
    "print ('Petrobras = ', encoder.transform(['Mesma Area'])[0])\n",
    "print ('Outro = ', encoder.transform(['Area Oposta'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando modelo de Embeddings a partir dos documentos da BDTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = teses_mesmas_areas_Large['Resumo Portugu√™s:']\n",
    "corpus = corpus.append(tese_area_oposta_Large['Resumo Portugu√™s:'])\n",
    "corpus = corpus.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.sent_tokenize(corpus) # this gives us a list of sentences\n",
    "shuffle(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_processado = []\n",
    "for sentence in corpus:\n",
    "    corpus_processado.append(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDTD_word2vec_50 = Word2Vec(corpus_processado, size=50, window=10, min_count=1, workers=4, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06031311, -0.47872463, -0.22186443,  0.03946265,  0.03059704,\n",
       "        0.07376117, -0.3483484 ,  0.31627288, -0.11153589,  0.01794658,\n",
       "       -0.08084787, -0.09499344,  0.10590985, -0.15072359, -0.14159147,\n",
       "       -0.17657839,  0.02871069, -0.27410194,  0.05572611,  0.09521671,\n",
       "        0.36293727,  0.00838607,  0.21441245,  0.42894357, -0.05009334,\n",
       "       -0.05166749,  0.09839671,  0.2530429 ,  0.2504976 , -0.13194893,\n",
       "        0.18959577,  0.1700294 ,  0.00494603, -0.198466  ,  0.35110155,\n",
       "       -0.2588147 ,  0.01687798, -0.08099127,  0.22914074, -0.03404161,\n",
       "        0.22324914,  0.0856167 ,  0.10617966, -0.33265668, -0.34455225,\n",
       "       -0.18977797,  0.1400363 , -0.14446819,  0.29265848, -0.01113894],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BDTD_word2vec_50.wv['√°gua']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('efici√™ncia', 0.9983611702919006),\n",
       " ('umidade', 0.9957671165466309),\n",
       " ('irriga√ß√£o', 0.9884953498840332),\n",
       " ('agr√≠colas', 0.9860963225364685),\n",
       " ('camadas', 0.9842226505279541),\n",
       " ('esmiu√ßou', 0.9840334057807922),\n",
       " ('diferiram', 0.9813232421875),\n",
       " ('aplicadas', 0.9721246361732483),\n",
       " ('exceto', 0.9712122082710266),\n",
       " ('agroambientais', 0.9706734418869019)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BDTD_word2vec_50.wv.similar_by_word('√°gua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for index, word in enumerate(BDTD_word2vec_50.wv.index2word):\n",
    "    word2index[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_pad_text(text, maxlen, word2index):\n",
    "    maxlen = 400\n",
    "    new_text = [] \n",
    "    for sent in text:\n",
    "        temp_sent = []\n",
    "        for word in word_tokenize(sent):\n",
    "            try:\n",
    "                temp_sent.append(word2index[word])\n",
    "            except:\n",
    "                pass\n",
    "        # Add the padding for each sentence. Here I am padding with 0\n",
    "        if len(temp_sent) > maxlen:\n",
    "            temp_sent = temp_sent[:maxlen]\n",
    "        else:\n",
    "            temp_sent += [0] * (maxlen - len(temp_sent))\n",
    "        new_text.append(temp_sent)\n",
    "\n",
    "    return np.array(new_text)\n",
    "\n",
    "maxlen = 400\n",
    "train_seq_x = index_pad_text(train_x, maxlen, word2index)\n",
    "test_seq_x = index_pad_text(test_x, maxlen, word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Model Building**  \n",
    "The final step in the text classification framework is to train a classifier using the features created in the previous step. There are many different choices of machine learning models which can be used to train a final model. We will implement following different classifiers for this purpose:  \n",
    " \n",
    "* Naive Bayes Classifier\n",
    "* Linear Classifier\n",
    "* Support Vector Machine\n",
    "* Bagging Models\n",
    "* Boosting Models\n",
    "* Shallow Neural Networks\n",
    "* Deep Neural Networks\n",
    "* Convolutional Neural Network (CNN)\n",
    "* Long Short Term Modelr (LSTM)\n",
    "* Gated Recurrent Unit (GRU)\n",
    "* Bidirectional RNN\n",
    "* Recurrent Convolutional Neural Network (RCNN)\n",
    "* Other Variants of Deep Neural Networks  \n",
    "\n",
    "Lets implement these models and understand their details. The following function is a utility function which can be used to train a model. It accepts the classifier, feature_vector of training data, labels of training data and feature vectors of valid data as inputs. Using these inputs, the model is trained and accuracy score is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    \n",
    "    if is_neural_net:\n",
    "        callbacks = EarlyStopping(monitor='loss_acc', mode='max', patience=20, restore_best_weights=True)\n",
    "        history = classifier.fit(feature_vector_train,\n",
    "                                 label, #to_categorical(label),\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=64,\n",
    "                                 validation_split=0.25,\n",
    "                                 callbacks=[callbacks])\n",
    "        \n",
    "    # plot the loss\n",
    "        # list all data in history\n",
    "        print(history.history.keys())\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model acc')\n",
    "        plt.ylabel('acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "    predictions = np.rint(predictions)\n",
    "    \n",
    "    num_classes = 2\n",
    "    return (metrics.accuracy_score(predictions, test_y),\n",
    "            tf.confusion_matrix(predictions, test_y, num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7 Deep Neural Networks**  \n",
    "Deep Neural Networks are more complex neural networks in which the hidden layers performs much more complex operations than simple sigmoid or relu activations. Different types of deep learning models can be applied in text classification problems.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.1 Convolutional Neural Network\n",
    "In Convolutional neural networks, convolutions over the input layer are used to compute the output. This results in local connections, where each region of the input is connected to a neuron in the output. Each layer applies different filters and combines their results.\n",
    "image.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_23 (Embedding)     (None, 400, 50)           1871950   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 396, 128)          32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 194, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 93, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_23 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,084,815\n",
      "Trainable params: 2,084,815\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_cnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((maxlen, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = BDTD_word2vec_50.wv.get_keras_embedding(train_embeddings=True)(input_layer)\n",
    "    \n",
    "    embedding_layer = layers.SpatialDropout1D(0.05)(embedding_layer)\n",
    "\n",
    "    # Add the convolutional Layer e pooling layer\n",
    "    conv_layer_1 = layers.Convolution1D(128, 5, activation=\"relu\")(embedding_layer)\n",
    "    pooling_layer_1 = layers.MaxPooling1D(2)(conv_layer_1)\n",
    "    pooling_layer_1 = layers.Dropout(0.25)(pooling_layer_1)\n",
    "    \n",
    "    conv_layer_2 = layers.Convolution1D(128, 5, activation=\"relu\")(pooling_layer_1)\n",
    "    pooling_layer_2 = layers.MaxPooling1D(2)(conv_layer_2)\n",
    "    pooling_layer_2 = layers.Dropout(0.25)(pooling_layer_2)\n",
    "    \n",
    "    conv_layer_3 = layers.Convolution1D(128, 5, activation=\"relu\")(pooling_layer_2)\n",
    "    pooling_layer_3 = layers.GlobalMaxPooling1D()(conv_layer_3)\n",
    "    pooling_layer_3 = layers.Dropout(0.25)(pooling_layer_3)\n",
    "    \n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(512, activation=\"relu\")(pooling_layer_3)\n",
    "    output_layer1 = layers.Dropout(0.2)(output_layer1)\n",
    "    output_layer1 = layers.Dense(128)(pooling_layer_3)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "classifier = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 298 samples\n",
      "Epoch 1/1000\n",
      "891/891 [==============================] - 4s 5ms/step - loss: 1.8042 - acc: 0.5230 - val_loss: 0.6929 - val_acc: 0.4765\n",
      "Epoch 2/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.7579 - acc: 0.5129 - val_loss: 0.6913 - val_acc: 0.4564\n",
      "Epoch 3/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.7067 - acc: 0.5297 - val_loss: 0.6810 - val_acc: 0.5604\n",
      "Epoch 4/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.6823 - acc: 0.5466 - val_loss: 0.6762 - val_acc: 0.6208\n",
      "Epoch 5/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.6882 - acc: 0.5443 - val_loss: 0.6733 - val_acc: 0.6208\n",
      "Epoch 6/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.6901 - acc: 0.5331 - val_loss: 0.6711 - val_acc: 0.6141\n",
      "Epoch 7/1000\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.6838 - acc: 0.5477 - val_loss: 0.6701 - val_acc: 0.6174\n",
      "Epoch 8/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.6798 - acc: 0.5556 - val_loss: 0.6668 - val_acc: 0.6141\n",
      "Epoch 9/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.6839 - acc: 0.5556 - val_loss: 0.6763 - val_acc: 0.5973\n",
      "Epoch 10/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.6737 - acc: 0.5634 - val_loss: 0.6679 - val_acc: 0.6275\n",
      "Epoch 11/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.6872 - acc: 0.5511 - val_loss: 0.6811 - val_acc: 0.5168\n",
      "Epoch 12/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.6792 - acc: 0.5724 - val_loss: 0.6648 - val_acc: 0.6174\n",
      "Epoch 13/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.6856 - acc: 0.5657 - val_loss: 0.6716 - val_acc: 0.6242\n",
      "Epoch 14/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.6893 - acc: 0.5342 - val_loss: 0.6840 - val_acc: 0.4564\n",
      "Epoch 15/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.6875 - acc: 0.5331 - val_loss: 0.6693 - val_acc: 0.6174\n",
      "Epoch 16/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.6825 - acc: 0.5286 - val_loss: 0.6687 - val_acc: 0.6208\n",
      "Epoch 17/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.6844 - acc: 0.5185 - val_loss: 0.6691 - val_acc: 0.6208\n",
      "Epoch 18/1000\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.6743 - acc: 0.5511 - val_loss: 0.6693 - val_acc: 0.6141\n",
      "Epoch 19/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.6822 - acc: 0.5567 - val_loss: 0.6792 - val_acc: 0.6007\n",
      "Epoch 20/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.6773 - acc: 0.5578 - val_loss: 0.6683 - val_acc: 0.6074\n",
      "Epoch 21/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.6916 - acc: 0.5488 - val_loss: 0.6814 - val_acc: 0.4832\n",
      "Epoch 22/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.6718 - acc: 0.5634 - val_loss: 0.6738 - val_acc: 0.6107\n",
      "Epoch 23/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.6732 - acc: 0.5870 - val_loss: 0.6767 - val_acc: 0.6107\n",
      "Epoch 24/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.6778 - acc: 0.5466 - val_loss: 0.6721 - val_acc: 0.6208\n",
      "Epoch 25/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.6754 - acc: 0.5567 - val_loss: 0.6838 - val_acc: 0.4664\n",
      "Epoch 26/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.6822 - acc: 0.5556 - val_loss: 0.6775 - val_acc: 0.6040\n",
      "Epoch 27/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.6717 - acc: 0.5758 - val_loss: 0.6785 - val_acc: 0.5738\n",
      "Epoch 28/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.6735 - acc: 0.5499 - val_loss: 0.6694 - val_acc: 0.6208\n",
      "Epoch 29/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.6708 - acc: 0.5802 - val_loss: 0.6913 - val_acc: 0.4631\n",
      "Epoch 30/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.6771 - acc: 0.5724 - val_loss: 0.6741 - val_acc: 0.6074\n",
      "Epoch 31/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.6718 - acc: 0.5746 - val_loss: 0.6750 - val_acc: 0.5839\n",
      "Epoch 32/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.6745 - acc: 0.5589 - val_loss: 0.6678 - val_acc: 0.6242\n",
      "Epoch 33/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.6680 - acc: 0.5881 - val_loss: 0.6710 - val_acc: 0.5839\n",
      "Epoch 34/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.6623 - acc: 0.6072 - val_loss: 0.6648 - val_acc: 0.6007\n",
      "Epoch 35/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.6598 - acc: 0.6038 - val_loss: 0.6665 - val_acc: 0.5839\n",
      "Epoch 36/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.6745 - acc: 0.6027 - val_loss: 0.6604 - val_acc: 0.5973\n",
      "Epoch 37/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.6734 - acc: 0.5623 - val_loss: 0.6666 - val_acc: 0.6208\n",
      "Epoch 38/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.6698 - acc: 0.5802 - val_loss: 0.6878 - val_acc: 0.4899\n",
      "Epoch 39/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.6845 - acc: 0.5567 - val_loss: 0.6890 - val_acc: 0.4732\n",
      "Epoch 40/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.6589 - acc: 0.6061 - val_loss: 0.6673 - val_acc: 0.5872\n",
      "Epoch 41/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.6615 - acc: 0.6038 - val_loss: 0.6685 - val_acc: 0.6074\n",
      "Epoch 42/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.6484 - acc: 0.6072 - val_loss: 0.6787 - val_acc: 0.5738\n",
      "Epoch 43/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.6431 - acc: 0.6195 - val_loss: 0.6613 - val_acc: 0.6107\n",
      "Epoch 44/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.6371 - acc: 0.6409 - val_loss: 0.6772 - val_acc: 0.5906\n",
      "Epoch 45/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.6334 - acc: 0.6465 - val_loss: 0.6922 - val_acc: 0.5671\n",
      "Epoch 46/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.6193 - acc: 0.6712 - val_loss: 0.6516 - val_acc: 0.5906\n",
      "Epoch 47/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.5997 - acc: 0.6790 - val_loss: 0.6795 - val_acc: 0.5772\n",
      "Epoch 48/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.5680 - acc: 0.6700 - val_loss: 0.6478 - val_acc: 0.6174\n",
      "Epoch 49/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4594 - acc: 0.8025 - val_loss: 0.6647 - val_acc: 0.6074\n",
      "Epoch 50/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3436 - acc: 0.8552 - val_loss: 0.7069 - val_acc: 0.6242\n",
      "Epoch 51/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.2085 - acc: 0.9270 - val_loss: 0.8093 - val_acc: 0.6409\n",
      "Epoch 52/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.1041 - acc: 0.9551 - val_loss: 0.8296 - val_acc: 0.6812\n",
      "Epoch 53/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0716 - acc: 0.9764 - val_loss: 1.5269 - val_acc: 0.5839\n",
      "Epoch 54/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.1462 - acc: 0.9428 - val_loss: 1.0275 - val_acc: 0.6242\n",
      "Epoch 55/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0827 - acc: 0.9719 - val_loss: 1.1625 - val_acc: 0.6611\n",
      "Epoch 56/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0409 - acc: 0.9888 - val_loss: 1.0683 - val_acc: 0.6711\n",
      "Epoch 57/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.9902 - val_acc: 0.7114\n",
      "Epoch 58/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0154 - acc: 0.9944 - val_loss: 1.0675 - val_acc: 0.6913\n",
      "Epoch 59/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 1.3222 - val_acc: 0.6711\n",
      "Epoch 60/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0119 - acc: 0.9955 - val_loss: 1.2324 - val_acc: 0.6913\n",
      "Epoch 61/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0080 - acc: 0.9978 - val_loss: 1.2643 - val_acc: 0.6913\n",
      "Epoch 62/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0093 - acc: 0.9955 - val_loss: 1.3097 - val_acc: 0.6913\n",
      "Epoch 63/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 1.2316 - val_acc: 0.7047\n",
      "Epoch 64/1000\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.0082 - acc: 0.9966 - val_loss: 1.2057 - val_acc: 0.7148\n",
      "Epoch 65/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0102 - acc: 0.9955 - val_loss: 1.8026 - val_acc: 0.6477\n",
      "Epoch 66/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0108 - acc: 0.9955 - val_loss: 1.3559 - val_acc: 0.6779\n",
      "Epoch 67/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 1.3003 - val_acc: 0.6980\n",
      "Epoch 68/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0082 - acc: 0.9955 - val_loss: 1.2862 - val_acc: 0.7047\n",
      "Epoch 69/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 1.2838 - val_acc: 0.7148\n",
      "Epoch 70/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0053 - acc: 0.9978 - val_loss: 1.4850 - val_acc: 0.6812\n",
      "Epoch 71/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0060 - acc: 0.9978 - val_loss: 1.3876 - val_acc: 0.6980\n",
      "Epoch 72/1000\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.0120 - acc: 0.9955 - val_loss: 1.3491 - val_acc: 0.6980\n",
      "Epoch 73/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 1.3664 - val_acc: 0.7013\n",
      "Epoch 74/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0064 - acc: 0.9966 - val_loss: 1.2738 - val_acc: 0.7013\n",
      "Epoch 75/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0051 - acc: 0.9978 - val_loss: 1.4016 - val_acc: 0.7013\n",
      "Epoch 76/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0099 - acc: 0.9955 - val_loss: 1.3090 - val_acc: 0.7047\n",
      "Epoch 77/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0089 - acc: 0.9966 - val_loss: 1.3206 - val_acc: 0.6946\n",
      "Epoch 78/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0060 - acc: 0.9978 - val_loss: 1.2741 - val_acc: 0.7081\n",
      "Epoch 79/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0107 - acc: 0.9955 - val_loss: 1.3498 - val_acc: 0.6913\n",
      "Epoch 80/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 1.2520 - val_acc: 0.7047\n",
      "Epoch 81/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0072 - acc: 0.9966 - val_loss: 1.3174 - val_acc: 0.6980\n",
      "Epoch 82/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 1.7064 - val_acc: 0.6879\n",
      "Epoch 83/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0057 - acc: 0.9978 - val_loss: 1.4366 - val_acc: 0.7013\n",
      "Epoch 84/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0058 - acc: 0.9966 - val_loss: 1.5318 - val_acc: 0.6946\n",
      "Epoch 85/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 1.3903 - val_acc: 0.7047\n",
      "Epoch 86/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.4468 - val_acc: 0.6913\n",
      "Epoch 87/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 1.4535 - val_acc: 0.7047\n",
      "Epoch 88/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.4754 - val_acc: 0.7013\n",
      "Epoch 89/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 1.4524 - val_acc: 0.7114\n",
      "Epoch 90/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.4515 - val_acc: 0.7148\n",
      "Epoch 91/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.4679 - val_acc: 0.7013\n",
      "Epoch 92/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5113 - val_acc: 0.7013\n",
      "Epoch 93/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5158 - val_acc: 0.6980\n",
      "Epoch 94/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.4796 - val_acc: 0.7114\n",
      "Epoch 95/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.4865 - val_acc: 0.7047\n",
      "Epoch 96/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.5065 - val_acc: 0.7114\n",
      "Epoch 97/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5135 - val_acc: 0.7081\n",
      "Epoch 98/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.5132 - val_acc: 0.7047\n",
      "Epoch 99/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5121 - val_acc: 0.7148\n",
      "Epoch 100/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0044 - acc: 0.9978 - val_loss: 1.5039 - val_acc: 0.7081\n",
      "Epoch 101/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 1.8064 - val_acc: 0.6946\n",
      "Epoch 102/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0098 - acc: 0.9966 - val_loss: 2.0521 - val_acc: 0.6577\n",
      "Epoch 103/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 1.6456 - val_acc: 0.7013\n",
      "Epoch 104/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0061 - acc: 0.9966 - val_loss: 2.1067 - val_acc: 0.6611\n",
      "Epoch 105/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0089 - acc: 0.9955 - val_loss: 1.8536 - val_acc: 0.6980\n",
      "Epoch 106/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6847 - val_acc: 0.6846\n",
      "Epoch 107/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0057 - acc: 0.9966 - val_loss: 1.5911 - val_acc: 0.6946\n",
      "Epoch 108/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0101 - acc: 0.9955 - val_loss: 2.2481 - val_acc: 0.6275\n",
      "Epoch 109/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0082 - acc: 0.9966 - val_loss: 1.7335 - val_acc: 0.6879\n",
      "Epoch 110/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0054 - acc: 0.9978 - val_loss: 1.5050 - val_acc: 0.7081\n",
      "Epoch 111/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.4440 - val_acc: 0.6946\n",
      "Epoch 112/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.4679 - val_acc: 0.6946\n",
      "Epoch 113/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.4806 - val_acc: 0.6946\n",
      "Epoch 114/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.4813 - val_acc: 0.6946\n",
      "Epoch 115/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.4909 - val_acc: 0.6946\n",
      "Epoch 116/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0057 - acc: 0.9978 - val_loss: 1.6103 - val_acc: 0.6913\n",
      "Epoch 117/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 1.6409 - val_acc: 0.6711\n",
      "Epoch 118/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.7202 - val_acc: 0.6577\n",
      "Epoch 119/1000\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 1.5254 - val_acc: 0.7081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.6043 - val_acc: 0.7081\n",
      "Epoch 121/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5805 - val_acc: 0.7181\n",
      "Epoch 122/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5696 - val_acc: 0.7148\n",
      "Epoch 123/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5620 - val_acc: 0.7013\n",
      "Epoch 124/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5602 - val_acc: 0.7081\n",
      "Epoch 125/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5654 - val_acc: 0.7148\n",
      "Epoch 126/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.5681 - val_acc: 0.7148\n",
      "Epoch 127/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.5757 - val_acc: 0.7081\n",
      "Epoch 128/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.5794 - val_acc: 0.7081\n",
      "Epoch 129/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.5838 - val_acc: 0.7013\n",
      "Epoch 130/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.5916 - val_acc: 0.7081\n",
      "Epoch 131/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6425 - val_acc: 0.7148\n",
      "Epoch 132/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6736 - val_acc: 0.7148\n",
      "Epoch 133/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.7091 - val_acc: 0.7013\n",
      "Epoch 134/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.6842 - val_acc: 0.7148\n",
      "Epoch 135/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.6441 - val_acc: 0.7114\n",
      "Epoch 136/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6457 - val_acc: 0.7114\n",
      "Epoch 137/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.6478 - val_acc: 0.7081\n",
      "Epoch 138/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6490 - val_acc: 0.7114\n",
      "Epoch 139/1000\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.0055 - acc: 0.9966 - val_loss: 2.0256 - val_acc: 0.6946\n",
      "Epoch 140/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0051 - acc: 0.9978 - val_loss: 1.8270 - val_acc: 0.6879\n",
      "Epoch 141/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.6534 - val_acc: 0.7114\n",
      "Epoch 142/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6639 - val_acc: 0.7047\n",
      "Epoch 143/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.6670 - val_acc: 0.7081\n",
      "Epoch 144/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.6743 - val_acc: 0.7047\n",
      "Epoch 145/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.6807 - val_acc: 0.7047\n",
      "Epoch 146/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6792 - val_acc: 0.7047\n",
      "Epoch 147/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.6928 - val_acc: 0.7047\n",
      "Epoch 148/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7085 - val_acc: 0.7047\n",
      "Epoch 149/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.7109 - val_acc: 0.7047\n",
      "Epoch 150/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.6985 - val_acc: 0.7047\n",
      "Epoch 151/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7015 - val_acc: 0.7081\n",
      "Epoch 152/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7097 - val_acc: 0.7047\n",
      "Epoch 153/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7114 - val_acc: 0.7081\n",
      "Epoch 154/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7110 - val_acc: 0.7081\n",
      "Epoch 155/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7167 - val_acc: 0.7081\n",
      "Epoch 156/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7217 - val_acc: 0.7081\n",
      "Epoch 157/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7282 - val_acc: 0.7047\n",
      "Epoch 158/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7349 - val_acc: 0.7081\n",
      "Epoch 159/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7395 - val_acc: 0.7148\n",
      "Epoch 160/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7432 - val_acc: 0.7148\n",
      "Epoch 161/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7564 - val_acc: 0.7047\n",
      "Epoch 162/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7705 - val_acc: 0.7047\n",
      "Epoch 163/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.7581 - val_acc: 0.7047\n",
      "Epoch 164/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7568 - val_acc: 0.7181\n",
      "Epoch 165/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7581 - val_acc: 0.7181\n",
      "Epoch 166/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 1.7609 - val_acc: 0.7181\n",
      "Epoch 167/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7647 - val_acc: 0.7148\n",
      "Epoch 168/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7698 - val_acc: 0.7148\n",
      "Epoch 169/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7735 - val_acc: 0.7148\n",
      "Epoch 170/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7808 - val_acc: 0.7081\n",
      "Epoch 171/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7876 - val_acc: 0.7081\n",
      "Epoch 172/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7877 - val_acc: 0.7081\n",
      "Epoch 173/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.7969 - val_acc: 0.7081\n",
      "Epoch 174/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.7966 - val_acc: 0.7081\n",
      "Epoch 175/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.8114 - val_acc: 0.7148\n",
      "Epoch 176/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 2.0789 - val_acc: 0.6980\n",
      "Epoch 177/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.8803 - val_acc: 0.6980\n",
      "Epoch 178/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.8075 - val_acc: 0.7148\n",
      "Epoch 179/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.8019 - val_acc: 0.7148\n",
      "Epoch 180/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.8140 - val_acc: 0.7114\n",
      "Epoch 181/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.8313 - val_acc: 0.7148\n",
      "Epoch 182/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.8336 - val_acc: 0.7148\n",
      "Epoch 183/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.8322 - val_acc: 0.7114\n",
      "Epoch 184/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0040 - acc: 0.9978 - val_loss: 1.8280 - val_acc: 0.7081\n",
      "Epoch 185/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 1.8302 - val_acc: 0.7148\n",
      "Epoch 186/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0042 - acc: 0.9978 - val_loss: 1.8341 - val_acc: 0.7148\n",
      "Epoch 187/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 1.8375 - val_acc: 0.7148\n",
      "Epoch 188/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0041 - acc: 0.9978 - val_loss: 1.8369 - val_acc: 0.7114\n",
      "Epoch 189/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 1.8472 - val_acc: 0.7181\n",
      "Epoch 190/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.8584 - val_acc: 0.7181\n",
      "Epoch 191/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.8626 - val_acc: 0.7248\n",
      "Epoch 192/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.8632 - val_acc: 0.7181\n",
      "Epoch 193/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0040 - acc: 0.9978 - val_loss: 1.8679 - val_acc: 0.7148\n",
      "Epoch 194/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 1.8704 - val_acc: 0.7114\n",
      "Epoch 195/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.8799 - val_acc: 0.7114\n",
      "Epoch 196/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.8839 - val_acc: 0.7114\n",
      "Epoch 197/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 2.5625 - val_acc: 0.6443\n",
      "Epoch 198/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0053 - acc: 0.9978 - val_loss: 1.7497 - val_acc: 0.7081\n",
      "Epoch 199/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 1.8088 - val_acc: 0.7181\n",
      "Epoch 200/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 1.8224 - val_acc: 0.7215\n",
      "Epoch 201/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 2.2590 - val_acc: 0.6946\n",
      "Epoch 202/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0083 - acc: 0.9955 - val_loss: 2.1770 - val_acc: 0.7081\n",
      "Epoch 203/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0210 - acc: 0.9933 - val_loss: 3.9191 - val_acc: 0.5604\n",
      "Epoch 204/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0082 - acc: 0.9955 - val_loss: 1.9075 - val_acc: 0.7013\n",
      "Epoch 205/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0081 - acc: 0.9966 - val_loss: 2.4717 - val_acc: 0.6745\n",
      "Epoch 206/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 2.2491 - val_acc: 0.6678\n",
      "Epoch 207/1000\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.3671 - val_acc: 0.6644\n",
      "Epoch 208/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0053 - acc: 0.9978 - val_loss: 3.1492 - val_acc: 0.6376\n",
      "Epoch 209/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0074 - acc: 0.9966 - val_loss: 2.4558 - val_acc: 0.6745\n",
      "Epoch 210/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0062 - acc: 0.9978 - val_loss: 3.9732 - val_acc: 0.5738\n",
      "Epoch 211/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 2.2182 - val_acc: 0.7047\n",
      "Epoch 212/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0097 - acc: 0.9978 - val_loss: 4.9104 - val_acc: 0.5839\n",
      "Epoch 213/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0121 - acc: 0.9955 - val_loss: 2.3448 - val_acc: 0.7081\n",
      "Epoch 214/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0123 - acc: 0.9966 - val_loss: 2.2922 - val_acc: 0.6946\n",
      "Epoch 215/1000\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.0073 - acc: 0.9978 - val_loss: 4.4696 - val_acc: 0.5604\n",
      "Epoch 216/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0114 - acc: 0.9966 - val_loss: 2.2689 - val_acc: 0.6879\n",
      "Epoch 217/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 2.1578 - val_acc: 0.6779\n",
      "Epoch 218/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0151 - acc: 0.9944 - val_loss: 2.0776 - val_acc: 0.6946\n",
      "Epoch 219/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 2.5775 - val_acc: 0.6846\n",
      "Epoch 220/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 2.2129 - val_acc: 0.7114\n",
      "Epoch 221/1000\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 2.0026 - val_acc: 0.7181\n",
      "Epoch 222/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.0799 - val_acc: 0.7181\n",
      "Epoch 223/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 1.9812 - val_acc: 0.7315\n",
      "Epoch 224/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.9813 - val_acc: 0.7349\n",
      "Epoch 225/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.9886 - val_acc: 0.7181\n",
      "Epoch 226/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.0007 - val_acc: 0.7215\n",
      "Epoch 227/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0069 - acc: 0.9966 - val_loss: 2.1859 - val_acc: 0.7047\n",
      "Epoch 228/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.6310 - val_acc: 0.6779\n",
      "Epoch 229/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.6683 - val_acc: 0.6040\n",
      "Epoch 230/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 2.2395 - val_acc: 0.7114\n",
      "Epoch 231/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.0803 - val_acc: 0.7248\n",
      "Epoch 232/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1134 - val_acc: 0.7248\n",
      "Epoch 233/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.1236 - val_acc: 0.7248\n",
      "Epoch 234/1000\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1301 - val_acc: 0.7248\n",
      "Epoch 235/1000\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1309 - val_acc: 0.7248\n",
      "Epoch 236/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.1348 - val_acc: 0.7248\n",
      "Epoch 237/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.1371 - val_acc: 0.7248\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 183us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 2.1370 - val_acc: 0.7215\n",
      "Epoch 239/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1368 - val_acc: 0.7248\n",
      "Epoch 240/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1371 - val_acc: 0.7248\n",
      "Epoch 241/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.1371 - val_acc: 0.7248\n",
      "Epoch 242/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 2.1368 - val_acc: 0.7248\n",
      "Epoch 243/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0044 - acc: 0.9978 - val_loss: 2.1273 - val_acc: 0.7248\n",
      "Epoch 244/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1268 - val_acc: 0.7248\n",
      "Epoch 245/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.1403 - val_acc: 0.7248\n",
      "Epoch 246/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.1450 - val_acc: 0.7215\n",
      "Epoch 247/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1510 - val_acc: 0.7248\n",
      "Epoch 248/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 2.1459 - val_acc: 0.7215\n",
      "Epoch 249/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 2.1434 - val_acc: 0.7248\n",
      "Epoch 250/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.1446 - val_acc: 0.7248\n",
      "Epoch 251/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.1499 - val_acc: 0.7248\n",
      "Epoch 252/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1565 - val_acc: 0.7248\n",
      "Epoch 253/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0043 - acc: 0.9978 - val_loss: 2.1499 - val_acc: 0.7215\n",
      "Epoch 254/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0040 - acc: 0.9978 - val_loss: 2.1407 - val_acc: 0.7215\n",
      "Epoch 255/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1559 - val_acc: 0.7215\n",
      "Epoch 256/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.1612 - val_acc: 0.7215\n",
      "Epoch 257/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1634 - val_acc: 0.7215\n",
      "Epoch 258/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.1677 - val_acc: 0.7215\n",
      "Epoch 259/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1754 - val_acc: 0.7215\n",
      "Epoch 260/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0043 - acc: 0.9978 - val_loss: 2.1696 - val_acc: 0.7215\n",
      "Epoch 261/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.1683 - val_acc: 0.7215\n",
      "Epoch 262/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1694 - val_acc: 0.7215\n",
      "Epoch 263/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1725 - val_acc: 0.7215\n",
      "Epoch 264/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 3.1485 - val_acc: 0.6711\n",
      "Epoch 265/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.3779 - val_acc: 0.7047\n",
      "Epoch 266/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0044 - acc: 0.9978 - val_loss: 2.6355 - val_acc: 0.6946\n",
      "Epoch 267/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.5214 - val_acc: 0.7047\n",
      "Epoch 268/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0042 - acc: 0.9978 - val_loss: 3.0602 - val_acc: 0.6745\n",
      "Epoch 269/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2814 - val_acc: 0.6644\n",
      "Epoch 270/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.3224 - val_acc: 0.7114\n",
      "Epoch 271/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.4700 - val_acc: 0.7114\n",
      "Epoch 272/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.5718 - val_acc: 0.7047\n",
      "Epoch 273/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.6106 - val_acc: 0.7013\n",
      "Epoch 274/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.5479 - val_acc: 0.7047\n",
      "Epoch 275/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.5175 - val_acc: 0.7114\n",
      "Epoch 276/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.5014 - val_acc: 0.7114\n",
      "Epoch 277/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.5159 - val_acc: 0.7114\n",
      "Epoch 278/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.5042 - val_acc: 0.7114\n",
      "Epoch 279/1000\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.5270 - val_acc: 0.7081\n",
      "Epoch 280/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.5726 - val_acc: 0.7013\n",
      "Epoch 281/1000\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6471 - val_acc: 0.7047\n",
      "Epoch 282/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 2.6531 - val_acc: 0.7047\n",
      "Epoch 283/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.6323 - val_acc: 0.7047\n",
      "Epoch 284/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6560 - val_acc: 0.7047\n",
      "Epoch 285/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6314 - val_acc: 0.7047\n",
      "Epoch 286/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6474 - val_acc: 0.7047\n",
      "Epoch 287/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6630 - val_acc: 0.7013\n",
      "Epoch 288/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6582 - val_acc: 0.7047\n",
      "Epoch 289/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6074 - val_acc: 0.7081\n",
      "Epoch 290/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7273 - val_acc: 0.6980\n",
      "Epoch 291/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6595 - val_acc: 0.7013\n",
      "Epoch 292/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0819 - acc: 0.9820 - val_loss: 5.0275 - val_acc: 0.5671\n",
      "Epoch 293/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0836 - acc: 0.9787 - val_loss: 1.4177 - val_acc: 0.6980\n",
      "Epoch 294/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 1.9693 - val_acc: 0.6745\n",
      "Epoch 295/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0058 - acc: 0.9966 - val_loss: 1.9269 - val_acc: 0.7315\n",
      "Epoch 296/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.9245 - val_acc: 0.7349\n",
      "Epoch 297/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 1.9121 - val_acc: 0.7383\n",
      "Epoch 298/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.9118 - val_acc: 0.7349\n",
      "Epoch 299/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.9142 - val_acc: 0.7282\n",
      "Epoch 300/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.9219 - val_acc: 0.7248\n",
      "Epoch 301/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 1.9308 - val_acc: 0.7215\n",
      "Epoch 302/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 1.9403 - val_acc: 0.7181\n",
      "Epoch 303/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.9474 - val_acc: 0.7181\n",
      "Epoch 304/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 1.9596 - val_acc: 0.7215\n",
      "Epoch 305/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.9682 - val_acc: 0.7181\n",
      "Epoch 306/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 2.1708 - val_acc: 0.7181\n",
      "Epoch 307/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 1.8099 - val_acc: 0.7181\n",
      "Epoch 308/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.7478 - val_acc: 0.7248\n",
      "Epoch 309/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0043 - acc: 0.9978 - val_loss: 1.8727 - val_acc: 0.7215\n",
      "Epoch 310/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.8771 - val_acc: 0.7248\n",
      "Epoch 311/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.8758 - val_acc: 0.7248\n",
      "Epoch 312/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 1.8738 - val_acc: 0.7248\n",
      "Epoch 313/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.8729 - val_acc: 0.7248\n",
      "Epoch 314/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.8720 - val_acc: 0.7215\n",
      "Epoch 315/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.8714 - val_acc: 0.7215\n",
      "Epoch 316/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.8704 - val_acc: 0.7282\n",
      "Epoch 317/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.8735 - val_acc: 0.7315\n",
      "Epoch 318/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.8763 - val_acc: 0.7315\n",
      "Epoch 319/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.8852 - val_acc: 0.7349\n",
      "Epoch 320/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 1.8882 - val_acc: 0.7315\n",
      "Epoch 321/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.8913 - val_acc: 0.7315\n",
      "Epoch 322/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 1.8942 - val_acc: 0.7315\n",
      "Epoch 323/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.8973 - val_acc: 0.7349\n",
      "Epoch 324/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.8977 - val_acc: 0.7349\n",
      "Epoch 325/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 1.9024 - val_acc: 0.7349\n",
      "Epoch 326/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.9052 - val_acc: 0.7349\n",
      "Epoch 327/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 1.9097 - val_acc: 0.7282\n",
      "Epoch 328/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0057 - acc: 0.9978 - val_loss: 2.7229 - val_acc: 0.6946\n",
      "Epoch 329/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0054 - acc: 0.9978 - val_loss: 2.3896 - val_acc: 0.7148\n",
      "Epoch 330/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.1921 - val_acc: 0.7483\n",
      "Epoch 331/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 2.2114 - val_acc: 0.7282\n",
      "Epoch 332/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.2193 - val_acc: 0.7315\n",
      "Epoch 333/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.2260 - val_acc: 0.7315\n",
      "Epoch 334/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.2156 - val_acc: 0.7315\n",
      "Epoch 335/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.2173 - val_acc: 0.7282\n",
      "Epoch 336/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.2224 - val_acc: 0.7315\n",
      "Epoch 337/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.2261 - val_acc: 0.7282\n",
      "Epoch 338/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.2327 - val_acc: 0.7315\n",
      "Epoch 339/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 2.2356 - val_acc: 0.7315\n",
      "Epoch 340/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 2.7043 - val_acc: 0.7013\n",
      "Epoch 341/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0041 - acc: 0.9978 - val_loss: 2.1873 - val_acc: 0.7215\n",
      "Epoch 342/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.1456 - val_acc: 0.7215\n",
      "Epoch 343/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.1793 - val_acc: 0.7148\n",
      "Epoch 344/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.2404 - val_acc: 0.7148\n",
      "Epoch 345/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.2544 - val_acc: 0.7181\n",
      "Epoch 346/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.2800 - val_acc: 0.7215\n",
      "Epoch 347/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.3109 - val_acc: 0.7181\n",
      "Epoch 348/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.2248 - val_acc: 0.7248\n",
      "Epoch 349/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.2383 - val_acc: 0.7215\n",
      "Epoch 350/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.2532 - val_acc: 0.7215\n",
      "Epoch 351/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0051 - acc: 0.9978 - val_loss: 3.1033 - val_acc: 0.6611\n",
      "Epoch 352/1000\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.0098 - acc: 0.9966 - val_loss: 3.1340 - val_acc: 0.6779\n",
      "Epoch 353/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7561 - val_acc: 0.6980\n",
      "Epoch 354/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.6911 - val_acc: 0.7081\n",
      "Epoch 355/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6807 - val_acc: 0.7114\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 179us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 2.6808 - val_acc: 0.7081\n",
      "Epoch 357/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.6784 - val_acc: 0.7114\n",
      "Epoch 358/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.6815 - val_acc: 0.7114\n",
      "Epoch 359/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 2.6828 - val_acc: 0.7114\n",
      "Epoch 360/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.6823 - val_acc: 0.7114\n",
      "Epoch 361/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6845 - val_acc: 0.7114\n",
      "Epoch 362/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6780 - val_acc: 0.7114\n",
      "Epoch 363/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0271 - acc: 0.9910 - val_loss: 3.0818 - val_acc: 0.6644\n",
      "Epoch 364/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 2.4441 - val_acc: 0.7148\n",
      "Epoch 365/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0121 - acc: 0.9966 - val_loss: 3.0684 - val_acc: 0.6946\n",
      "Epoch 366/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 3.7090 - val_acc: 0.6644\n",
      "Epoch 367/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 3.5076 - val_acc: 0.6678\n",
      "Epoch 368/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0144 - acc: 0.9933 - val_loss: 2.7572 - val_acc: 0.6879\n",
      "Epoch 369/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0166 - acc: 0.9966 - val_loss: 2.5503 - val_acc: 0.6779\n",
      "Epoch 370/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0101 - acc: 0.9955 - val_loss: 2.1598 - val_acc: 0.7416\n",
      "Epoch 371/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 2.5557 - val_acc: 0.7114\n",
      "Epoch 372/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0065 - acc: 0.9966 - val_loss: 3.0941 - val_acc: 0.7047\n",
      "Epoch 373/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0345 - acc: 0.9955 - val_loss: 3.1668 - val_acc: 0.6812\n",
      "Epoch 374/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 4.5580 - val_acc: 0.6309\n",
      "Epoch 375/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0212 - acc: 0.9966 - val_loss: 3.6732 - val_acc: 0.6544\n",
      "Epoch 376/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 3.2326 - val_acc: 0.6812\n",
      "Epoch 377/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.9502 - val_acc: 0.6745\n",
      "Epoch 378/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.4113 - val_acc: 0.6644\n",
      "Epoch 379/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.3072 - val_acc: 0.6611\n",
      "Epoch 380/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0710 - val_acc: 0.6812\n",
      "Epoch 381/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.9599 - val_acc: 0.6644\n",
      "Epoch 382/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0069 - acc: 0.9966 - val_loss: 2.9279 - val_acc: 0.7114\n",
      "Epoch 383/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 3.1370 - val_acc: 0.7081\n",
      "Epoch 384/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2321 - val_acc: 0.7081\n",
      "Epoch 385/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.2665 - val_acc: 0.7114\n",
      "Epoch 386/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.2807 - val_acc: 0.7114\n",
      "Epoch 387/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 3.2734 - val_acc: 0.7114\n",
      "Epoch 388/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2735 - val_acc: 0.7114\n",
      "Epoch 389/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.2731 - val_acc: 0.7114\n",
      "Epoch 390/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2807 - val_acc: 0.7114\n",
      "Epoch 391/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2777 - val_acc: 0.7114\n",
      "Epoch 392/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2752 - val_acc: 0.7148\n",
      "Epoch 393/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0166 - acc: 0.9966 - val_loss: 3.8766 - val_acc: 0.6477\n",
      "Epoch 394/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 3.9286 - val_acc: 0.6879\n",
      "Epoch 395/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 4.2044 - val_acc: 0.6678\n",
      "Epoch 396/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0051 - acc: 0.9978 - val_loss: 4.2528 - val_acc: 0.6678\n",
      "Epoch 397/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0084 - acc: 0.9966 - val_loss: 3.9093 - val_acc: 0.6980\n",
      "Epoch 398/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0041 - acc: 0.9978 - val_loss: 3.7427 - val_acc: 0.6980\n",
      "Epoch 399/1000\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.0551 - acc: 0.9888 - val_loss: 5.6398 - val_acc: 0.5940\n",
      "Epoch 400/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0491 - acc: 0.9899 - val_loss: 2.7380 - val_acc: 0.7148\n",
      "Epoch 401/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0044 - acc: 0.9978 - val_loss: 3.5023 - val_acc: 0.6745\n",
      "Epoch 402/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0072 - acc: 0.9955 - val_loss: 3.4247 - val_acc: 0.6846\n",
      "Epoch 403/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0307 - acc: 0.9933 - val_loss: 4.3694 - val_acc: 0.6242\n",
      "Epoch 404/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 3.1652 - val_acc: 0.7148\n",
      "Epoch 405/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0043 - acc: 0.9978 - val_loss: 2.5451 - val_acc: 0.7383\n",
      "Epoch 406/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 2.5502 - val_acc: 0.7282\n",
      "Epoch 407/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.5581 - val_acc: 0.7349\n",
      "Epoch 408/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 2.5713 - val_acc: 0.7315\n",
      "Epoch 409/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 2.6257 - val_acc: 0.7315\n",
      "Epoch 410/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.6674 - val_acc: 0.7315\n",
      "Epoch 411/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.7190 - val_acc: 0.7349\n",
      "Epoch 412/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7599 - val_acc: 0.7416\n",
      "Epoch 413/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.7833 - val_acc: 0.7416\n",
      "Epoch 414/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7894 - val_acc: 0.7383\n",
      "Epoch 415/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 2.5871 - val_acc: 0.7315\n",
      "Epoch 416/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.5254 - val_acc: 0.7315\n",
      "Epoch 417/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 2.5310 - val_acc: 0.7315\n",
      "Epoch 418/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 2.5782 - val_acc: 0.7282\n",
      "Epoch 419/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 2.6191 - val_acc: 0.7349\n",
      "Epoch 420/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.6434 - val_acc: 0.7315\n",
      "Epoch 421/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0051 - acc: 0.9978 - val_loss: 2.6757 - val_acc: 0.7349\n",
      "Epoch 422/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6233 - val_acc: 0.7315\n",
      "Epoch 423/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 2.5976 - val_acc: 0.7383\n",
      "Epoch 424/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.5929 - val_acc: 0.7349\n",
      "Epoch 425/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.5669 - val_acc: 0.7349\n",
      "Epoch 426/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 2.5621 - val_acc: 0.7315\n",
      "Epoch 427/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 2.5807 - val_acc: 0.7349\n",
      "Epoch 428/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 2.5923 - val_acc: 0.7349\n",
      "Epoch 429/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 2.5859 - val_acc: 0.7349\n",
      "Epoch 430/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6013 - val_acc: 0.7349\n",
      "Epoch 431/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.6113 - val_acc: 0.7383\n",
      "Epoch 432/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 2.6780 - val_acc: 0.7315\n",
      "Epoch 433/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.7523 - val_acc: 0.7349\n",
      "Epoch 434/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 2.7903 - val_acc: 0.7383\n",
      "Epoch 435/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.7915 - val_acc: 0.7383\n",
      "Epoch 436/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7947 - val_acc: 0.7383\n",
      "Epoch 437/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.7980 - val_acc: 0.7383\n",
      "Epoch 438/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.8055 - val_acc: 0.7383\n",
      "Epoch 439/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.8333 - val_acc: 0.7383\n",
      "Epoch 440/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.8386 - val_acc: 0.7383\n",
      "Epoch 441/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.8356 - val_acc: 0.7383\n",
      "Epoch 442/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.8319 - val_acc: 0.7383\n",
      "Epoch 443/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.8287 - val_acc: 0.7383\n",
      "Epoch 444/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.8245 - val_acc: 0.7383\n",
      "Epoch 445/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 2.8235 - val_acc: 0.7383\n",
      "Epoch 446/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.8163 - val_acc: 0.7383\n",
      "Epoch 447/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.8158 - val_acc: 0.7416\n",
      "Epoch 448/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.8144 - val_acc: 0.7349\n",
      "Epoch 449/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.8009 - val_acc: 0.7315\n",
      "Epoch 450/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.7864 - val_acc: 0.7315\n",
      "Epoch 451/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7797 - val_acc: 0.7315\n",
      "Epoch 452/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.7810 - val_acc: 0.7315\n",
      "Epoch 453/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.7788 - val_acc: 0.7315\n",
      "Epoch 454/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.7745 - val_acc: 0.7315\n",
      "Epoch 455/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7739 - val_acc: 0.7315\n",
      "Epoch 456/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7719 - val_acc: 0.7315\n",
      "Epoch 457/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.6798 - val_acc: 0.7315\n",
      "Epoch 458/1000\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.6327 - val_acc: 0.7315\n",
      "Epoch 459/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.6729 - val_acc: 0.7315\n",
      "Epoch 460/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.7446 - val_acc: 0.7248\n",
      "Epoch 461/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7918 - val_acc: 0.7315\n",
      "Epoch 462/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7973 - val_acc: 0.7315\n",
      "Epoch 463/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7991 - val_acc: 0.7349\n",
      "Epoch 464/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7947 - val_acc: 0.7315\n",
      "Epoch 465/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7948 - val_acc: 0.7282\n",
      "Epoch 466/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 2.7982 - val_acc: 0.7282\n",
      "Epoch 467/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7931 - val_acc: 0.7282\n",
      "Epoch 468/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7916 - val_acc: 0.7248\n",
      "Epoch 469/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 2.7917 - val_acc: 0.7248\n",
      "Epoch 470/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7885 - val_acc: 0.7248\n",
      "Epoch 471/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7874 - val_acc: 0.7248\n",
      "Epoch 472/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7887 - val_acc: 0.7248\n",
      "Epoch 473/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 2.7934 - val_acc: 0.7248\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 184us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 2.7900 - val_acc: 0.7248\n",
      "Epoch 475/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.7833 - val_acc: 0.7248\n",
      "Epoch 476/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7816 - val_acc: 0.7248\n",
      "Epoch 477/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.7816 - val_acc: 0.7248\n",
      "Epoch 478/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 2.7796 - val_acc: 0.7248\n",
      "Epoch 479/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 4.5035 - val_acc: 0.6678\n",
      "Epoch 480/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.4321 - val_acc: 0.7148\n",
      "Epoch 481/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 4.2448 - val_acc: 0.6846\n",
      "Epoch 482/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.4028 - val_acc: 0.6711\n",
      "Epoch 483/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0211 - acc: 0.9966 - val_loss: 3.4754 - val_acc: 0.7047\n",
      "Epoch 484/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0052 - acc: 0.9989 - val_loss: 4.0304 - val_acc: 0.7013\n",
      "Epoch 485/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 4.4826 - val_acc: 0.6611\n",
      "Epoch 486/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 4.5872 - val_acc: 0.6544\n",
      "Epoch 487/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 4.0186 - val_acc: 0.6946\n",
      "Epoch 488/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.4851 - val_acc: 0.7181\n",
      "Epoch 489/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4270 - val_acc: 0.7215\n",
      "Epoch 490/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.4201 - val_acc: 0.7248\n",
      "Epoch 491/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.4135 - val_acc: 0.7248\n",
      "Epoch 492/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4150 - val_acc: 0.7248\n",
      "Epoch 493/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4143 - val_acc: 0.7215\n",
      "Epoch 494/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4156 - val_acc: 0.7215\n",
      "Epoch 495/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4218 - val_acc: 0.7181\n",
      "Epoch 496/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.4187 - val_acc: 0.7181\n",
      "Epoch 497/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.4130 - val_acc: 0.7181\n",
      "Epoch 498/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.4014 - val_acc: 0.7181\n",
      "Epoch 499/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.3994 - val_acc: 0.7181\n",
      "Epoch 500/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.3958 - val_acc: 0.7181\n",
      "Epoch 501/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3894 - val_acc: 0.7181\n",
      "Epoch 502/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3986 - val_acc: 0.7181\n",
      "Epoch 503/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.3982 - val_acc: 0.7181\n",
      "Epoch 504/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4019 - val_acc: 0.7181\n",
      "Epoch 505/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4038 - val_acc: 0.7181\n",
      "Epoch 506/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4124 - val_acc: 0.7148\n",
      "Epoch 507/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4098 - val_acc: 0.7148\n",
      "Epoch 508/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4139 - val_acc: 0.7148\n",
      "Epoch 509/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 3.3980 - val_acc: 0.7181\n",
      "Epoch 510/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.3951 - val_acc: 0.7181\n",
      "Epoch 511/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3904 - val_acc: 0.7181\n",
      "Epoch 512/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3871 - val_acc: 0.7181\n",
      "Epoch 513/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.3941 - val_acc: 0.7181\n",
      "Epoch 514/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.3928 - val_acc: 0.7181\n",
      "Epoch 515/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.4022 - val_acc: 0.7148\n",
      "Epoch 516/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0043 - acc: 0.9978 - val_loss: 4.8313 - val_acc: 0.6611\n",
      "Epoch 517/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0981 - acc: 0.9888 - val_loss: 3.9645 - val_acc: 0.7047\n",
      "Epoch 518/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 4.9843 - val_acc: 0.6275\n",
      "Epoch 519/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0128 - acc: 0.9978 - val_loss: 3.8715 - val_acc: 0.6946\n",
      "Epoch 520/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0048 - acc: 0.9989 - val_loss: 4.0933 - val_acc: 0.6980\n",
      "Epoch 521/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.1619 - val_acc: 0.6913\n",
      "Epoch 522/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 4.1332 - val_acc: 0.6913\n",
      "Epoch 523/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.8226 - val_acc: 0.7013\n",
      "Epoch 524/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.5042 - val_acc: 0.7148\n",
      "Epoch 525/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.4666 - val_acc: 0.7081\n",
      "Epoch 526/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.4522 - val_acc: 0.7081\n",
      "Epoch 527/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4469 - val_acc: 0.7081\n",
      "Epoch 528/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4661 - val_acc: 0.7081\n",
      "Epoch 529/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4025 - val_acc: 0.7013\n",
      "Epoch 530/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.4179 - val_acc: 0.7013\n",
      "Epoch 531/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4414 - val_acc: 0.7114\n",
      "Epoch 532/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 3.4302 - val_acc: 0.7081\n",
      "Epoch 533/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4213 - val_acc: 0.7081\n",
      "Epoch 534/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4161 - val_acc: 0.7081\n",
      "Epoch 535/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.4201 - val_acc: 0.7081\n",
      "Epoch 536/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4260 - val_acc: 0.7081\n",
      "Epoch 537/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.4586 - val_acc: 0.7081\n",
      "Epoch 538/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5001 - val_acc: 0.7114\n",
      "Epoch 539/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.5117 - val_acc: 0.7081\n",
      "Epoch 540/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5481 - val_acc: 0.7081\n",
      "Epoch 541/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6440 - val_acc: 0.7114\n",
      "Epoch 542/1000\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6626 - val_acc: 0.7114\n",
      "Epoch 543/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6364 - val_acc: 0.7114\n",
      "Epoch 544/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6158 - val_acc: 0.7047\n",
      "Epoch 545/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.6423 - val_acc: 0.7081\n",
      "Epoch 546/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.6406 - val_acc: 0.7081\n",
      "Epoch 547/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.6463 - val_acc: 0.7081\n",
      "Epoch 548/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6594 - val_acc: 0.7114\n",
      "Epoch 549/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6676 - val_acc: 0.7114\n",
      "Epoch 550/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.7251 - val_acc: 0.7047\n",
      "Epoch 551/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.2833 - val_acc: 0.7114\n",
      "Epoch 552/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1781 - val_acc: 0.7148\n",
      "Epoch 553/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1643 - val_acc: 0.7181\n",
      "Epoch 554/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1653 - val_acc: 0.7181\n",
      "Epoch 555/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1720 - val_acc: 0.7148\n",
      "Epoch 556/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1673 - val_acc: 0.7181\n",
      "Epoch 557/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1687 - val_acc: 0.7148\n",
      "Epoch 558/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1751 - val_acc: 0.7148\n",
      "Epoch 559/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 3.1637 - val_acc: 0.7148\n",
      "Epoch 560/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1706 - val_acc: 0.7148\n",
      "Epoch 561/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1683 - val_acc: 0.7148\n",
      "Epoch 562/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1716 - val_acc: 0.7148\n",
      "Epoch 563/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1812 - val_acc: 0.7148\n",
      "Epoch 564/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2018 - val_acc: 0.7114\n",
      "Epoch 565/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2093 - val_acc: 0.7114\n",
      "Epoch 566/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2231 - val_acc: 0.7081\n",
      "Epoch 567/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2730 - val_acc: 0.7148\n",
      "Epoch 568/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3046 - val_acc: 0.7181\n",
      "Epoch 569/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.3168 - val_acc: 0.7215\n",
      "Epoch 570/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3128 - val_acc: 0.7215\n",
      "Epoch 571/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3145 - val_acc: 0.7215\n",
      "Epoch 572/1000\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.3216 - val_acc: 0.7215\n",
      "Epoch 573/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.3203 - val_acc: 0.7215\n",
      "Epoch 574/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.3208 - val_acc: 0.7215\n",
      "Epoch 575/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0040 - acc: 0.9978 - val_loss: 3.3255 - val_acc: 0.7215\n",
      "Epoch 576/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.4103 - val_acc: 0.7148\n",
      "Epoch 577/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.4191 - val_acc: 0.7114\n",
      "Epoch 578/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4341 - val_acc: 0.7114\n",
      "Epoch 579/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4493 - val_acc: 0.7114\n",
      "Epoch 580/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4909 - val_acc: 0.7013\n",
      "Epoch 581/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4955 - val_acc: 0.7013\n",
      "Epoch 582/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.4891 - val_acc: 0.7013\n",
      "Epoch 583/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4759 - val_acc: 0.7013\n",
      "Epoch 584/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4852 - val_acc: 0.7013\n",
      "Epoch 585/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4843 - val_acc: 0.7013\n",
      "Epoch 586/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4774 - val_acc: 0.7013\n",
      "Epoch 587/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5164 - val_acc: 0.6980\n",
      "Epoch 588/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.5232 - val_acc: 0.6980\n",
      "Epoch 589/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.5270 - val_acc: 0.6980\n",
      "Epoch 590/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5253 - val_acc: 0.6980\n",
      "Epoch 591/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5285 - val_acc: 0.6980\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 183us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.5372 - val_acc: 0.6980\n",
      "Epoch 593/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.5407 - val_acc: 0.6980\n",
      "Epoch 594/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5417 - val_acc: 0.6980\n",
      "Epoch 595/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5366 - val_acc: 0.6980\n",
      "Epoch 596/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5519 - val_acc: 0.6980\n",
      "Epoch 597/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.5786 - val_acc: 0.6980\n",
      "Epoch 598/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6176 - val_acc: 0.7013\n",
      "Epoch 599/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6133 - val_acc: 0.7013\n",
      "Epoch 600/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.6295 - val_acc: 0.7013\n",
      "Epoch 601/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6518 - val_acc: 0.7013\n",
      "Epoch 602/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6416 - val_acc: 0.7013\n",
      "Epoch 603/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.7137 - val_acc: 0.6946\n",
      "Epoch 604/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.7113 - val_acc: 0.6946\n",
      "Epoch 605/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.7181 - val_acc: 0.6946\n",
      "Epoch 606/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.6275 - val_acc: 0.7013\n",
      "Epoch 607/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.6416 - val_acc: 0.7047\n",
      "Epoch 608/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.6435 - val_acc: 0.7047\n",
      "Epoch 609/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.3166 - val_acc: 0.7383\n",
      "Epoch 610/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4995 - val_acc: 0.7248\n",
      "Epoch 611/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5749 - val_acc: 0.7114\n",
      "Epoch 612/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5918 - val_acc: 0.7114\n",
      "Epoch 613/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5977 - val_acc: 0.7081\n",
      "Epoch 614/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 3.5952 - val_acc: 0.7114\n",
      "Epoch 615/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5973 - val_acc: 0.7081\n",
      "Epoch 616/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5955 - val_acc: 0.7114\n",
      "Epoch 617/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.5918 - val_acc: 0.7114\n",
      "Epoch 618/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5931 - val_acc: 0.7114\n",
      "Epoch 619/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5931 - val_acc: 0.7114\n",
      "Epoch 620/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5897 - val_acc: 0.7148\n",
      "Epoch 621/1000\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.0025 - acc: 0.9989 - val_loss: 3.5863 - val_acc: 0.7148\n",
      "Epoch 622/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5849 - val_acc: 0.7148\n",
      "Epoch 623/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5862 - val_acc: 0.7148\n",
      "Epoch 624/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.5855 - val_acc: 0.7148\n",
      "Epoch 625/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5856 - val_acc: 0.7148\n",
      "Epoch 626/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5858 - val_acc: 0.7148\n",
      "Epoch 627/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5832 - val_acc: 0.7114\n",
      "Epoch 628/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5822 - val_acc: 0.7215\n",
      "Epoch 629/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5802 - val_acc: 0.7215\n",
      "Epoch 630/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5810 - val_acc: 0.7215\n",
      "Epoch 631/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.5797 - val_acc: 0.7215\n",
      "Epoch 632/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5797 - val_acc: 0.7181\n",
      "Epoch 633/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5813 - val_acc: 0.7181\n",
      "Epoch 634/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.5834 - val_acc: 0.7148\n",
      "Epoch 635/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5843 - val_acc: 0.7148\n",
      "Epoch 636/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 3.5852 - val_acc: 0.7148\n",
      "Epoch 637/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5863 - val_acc: 0.7148\n",
      "Epoch 638/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5870 - val_acc: 0.7148\n",
      "Epoch 639/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6074 - val_acc: 0.7148\n",
      "Epoch 640/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.6199 - val_acc: 0.7148\n",
      "Epoch 641/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.6203 - val_acc: 0.7114\n",
      "Epoch 642/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6215 - val_acc: 0.7114\n",
      "Epoch 643/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6242 - val_acc: 0.7114\n",
      "Epoch 644/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6252 - val_acc: 0.7114\n",
      "Epoch 645/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6254 - val_acc: 0.7114\n",
      "Epoch 646/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.6227 - val_acc: 0.7114\n",
      "Epoch 647/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6205 - val_acc: 0.7114\n",
      "Epoch 648/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 3.6173 - val_acc: 0.7114\n",
      "Epoch 649/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6177 - val_acc: 0.7114\n",
      "Epoch 650/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6163 - val_acc: 0.7114\n",
      "Epoch 651/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.6145 - val_acc: 0.7114\n",
      "Epoch 652/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6173 - val_acc: 0.7148\n",
      "Epoch 653/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0179 - acc: 0.9978 - val_loss: 5.8540 - val_acc: 0.5973\n",
      "Epoch 654/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.2102 - acc: 0.9809 - val_loss: 7.1680 - val_acc: 0.5201\n",
      "Epoch 655/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.1508 - acc: 0.9865 - val_loss: 3.3635 - val_acc: 0.7349\n",
      "Epoch 656/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 3.4247 - val_acc: 0.7315\n",
      "Epoch 657/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.4646 - val_acc: 0.7282\n",
      "Epoch 658/1000\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3865 - val_acc: 0.7315\n",
      "Epoch 659/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4390 - val_acc: 0.7383\n",
      "Epoch 660/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5910 - val_acc: 0.7148\n",
      "Epoch 661/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0210 - acc: 0.9978 - val_loss: 3.6913 - val_acc: 0.7215\n",
      "Epoch 662/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0207 - acc: 0.9978 - val_loss: 3.7125 - val_acc: 0.7215\n",
      "Epoch 663/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.6458 - val_acc: 0.7148\n",
      "Epoch 664/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.6606 - val_acc: 0.7148\n",
      "Epoch 665/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.5180 - val_acc: 0.7383\n",
      "Epoch 666/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 5.1408 - val_acc: 0.6409\n",
      "Epoch 667/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0541 - acc: 0.9933 - val_loss: 4.9882 - val_acc: 0.6510\n",
      "Epoch 668/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0712 - acc: 0.9899 - val_loss: 3.5499 - val_acc: 0.7383\n",
      "Epoch 669/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.2337 - acc: 0.9731 - val_loss: 5.4428 - val_acc: 0.6074\n",
      "Epoch 670/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.1121 - acc: 0.9888 - val_loss: 3.1542 - val_acc: 0.7315\n",
      "Epoch 671/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0378 - acc: 0.9921 - val_loss: 3.0488 - val_acc: 0.7248\n",
      "Epoch 672/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0096 - acc: 0.9955 - val_loss: 3.3904 - val_acc: 0.7081\n",
      "Epoch 673/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0093 - acc: 0.9978 - val_loss: 3.0670 - val_acc: 0.6980\n",
      "Epoch 674/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0192 - acc: 0.9978 - val_loss: 3.0522 - val_acc: 0.7114\n",
      "Epoch 675/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.4508 - val_acc: 0.7148\n",
      "Epoch 676/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0044 - acc: 0.9978 - val_loss: 3.6766 - val_acc: 0.6879\n",
      "Epoch 677/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0063 - acc: 0.9978 - val_loss: 3.1139 - val_acc: 0.7148\n",
      "Epoch 678/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 3.0353 - val_acc: 0.7349\n",
      "Epoch 679/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0043 - acc: 0.9978 - val_loss: 3.0914 - val_acc: 0.7181\n",
      "Epoch 680/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 3.1171 - val_acc: 0.7181\n",
      "Epoch 681/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1350 - val_acc: 0.7181\n",
      "Epoch 682/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1403 - val_acc: 0.7148\n",
      "Epoch 683/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.1474 - val_acc: 0.7114\n",
      "Epoch 684/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 3.1507 - val_acc: 0.7114\n",
      "Epoch 685/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1567 - val_acc: 0.7114\n",
      "Epoch 686/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.1558 - val_acc: 0.7114\n",
      "Epoch 687/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.1642 - val_acc: 0.7114\n",
      "Epoch 688/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 3.1690 - val_acc: 0.7114\n",
      "Epoch 689/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0041 - acc: 0.9978 - val_loss: 3.1133 - val_acc: 0.7282\n",
      "Epoch 690/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1161 - val_acc: 0.7282\n",
      "Epoch 691/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1182 - val_acc: 0.7282\n",
      "Epoch 692/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.1199 - val_acc: 0.7282\n",
      "Epoch 693/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1240 - val_acc: 0.7282\n",
      "Epoch 694/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1258 - val_acc: 0.7282\n",
      "Epoch 695/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1290 - val_acc: 0.7282\n",
      "Epoch 696/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1306 - val_acc: 0.7282\n",
      "Epoch 697/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1340 - val_acc: 0.7282\n",
      "Epoch 698/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1352 - val_acc: 0.7282\n",
      "Epoch 699/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1389 - val_acc: 0.7282\n",
      "Epoch 700/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1418 - val_acc: 0.7282\n",
      "Epoch 701/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1427 - val_acc: 0.7282\n",
      "Epoch 702/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1443 - val_acc: 0.7282\n",
      "Epoch 703/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1491 - val_acc: 0.7282\n",
      "Epoch 704/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.1507 - val_acc: 0.7282\n",
      "Epoch 705/1000\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1507 - val_acc: 0.7282\n",
      "Epoch 706/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1528 - val_acc: 0.7282\n",
      "Epoch 707/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1522 - val_acc: 0.7282\n",
      "Epoch 708/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1551 - val_acc: 0.7282\n",
      "Epoch 709/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1557 - val_acc: 0.7282\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 183us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1613 - val_acc: 0.7282\n",
      "Epoch 711/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1618 - val_acc: 0.7282\n",
      "Epoch 712/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1640 - val_acc: 0.7282\n",
      "Epoch 713/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1659 - val_acc: 0.7282\n",
      "Epoch 714/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1690 - val_acc: 0.7282\n",
      "Epoch 715/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1717 - val_acc: 0.7282\n",
      "Epoch 716/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1710 - val_acc: 0.7282\n",
      "Epoch 717/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1758 - val_acc: 0.7248\n",
      "Epoch 718/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1732 - val_acc: 0.7248\n",
      "Epoch 719/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1756 - val_acc: 0.7248\n",
      "Epoch 720/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1814 - val_acc: 0.7248\n",
      "Epoch 721/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1774 - val_acc: 0.7248\n",
      "Epoch 722/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1782 - val_acc: 0.7248\n",
      "Epoch 723/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1829 - val_acc: 0.7248\n",
      "Epoch 724/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0044 - acc: 0.9978 - val_loss: 3.1821 - val_acc: 0.7248\n",
      "Epoch 725/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1835 - val_acc: 0.7248\n",
      "Epoch 726/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1793 - val_acc: 0.7248\n",
      "Epoch 727/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 3.1778 - val_acc: 0.7248\n",
      "Epoch 728/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1755 - val_acc: 0.7248\n",
      "Epoch 729/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1784 - val_acc: 0.7248\n",
      "Epoch 730/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1783 - val_acc: 0.7248\n",
      "Epoch 731/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1763 - val_acc: 0.7248\n",
      "Epoch 732/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1693 - val_acc: 0.7315\n",
      "Epoch 733/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1730 - val_acc: 0.7315\n",
      "Epoch 734/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1744 - val_acc: 0.7315\n",
      "Epoch 735/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1777 - val_acc: 0.7349\n",
      "Epoch 736/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1841 - val_acc: 0.7315\n",
      "Epoch 737/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1862 - val_acc: 0.7315\n",
      "Epoch 738/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1847 - val_acc: 0.7315\n",
      "Epoch 739/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1843 - val_acc: 0.7315\n",
      "Epoch 740/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1841 - val_acc: 0.7315\n",
      "Epoch 741/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1857 - val_acc: 0.7315\n",
      "Epoch 742/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1841 - val_acc: 0.7315\n",
      "Epoch 743/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1872 - val_acc: 0.7315\n",
      "Epoch 744/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1899 - val_acc: 0.7315\n",
      "Epoch 745/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1922 - val_acc: 0.7315\n",
      "Epoch 746/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1900 - val_acc: 0.7315\n",
      "Epoch 747/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1909 - val_acc: 0.7315\n",
      "Epoch 748/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1913 - val_acc: 0.7315\n",
      "Epoch 749/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1919 - val_acc: 0.7315\n",
      "Epoch 750/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1946 - val_acc: 0.7315\n",
      "Epoch 751/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1938 - val_acc: 0.7315\n",
      "Epoch 752/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1968 - val_acc: 0.7315\n",
      "Epoch 753/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 3.1967 - val_acc: 0.7315\n",
      "Epoch 754/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1970 - val_acc: 0.7315\n",
      "Epoch 755/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1964 - val_acc: 0.7315\n",
      "Epoch 756/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1959 - val_acc: 0.7315\n",
      "Epoch 757/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1941 - val_acc: 0.7315\n",
      "Epoch 758/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.1977 - val_acc: 0.7315\n",
      "Epoch 759/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1990 - val_acc: 0.7315\n",
      "Epoch 760/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2009 - val_acc: 0.7315\n",
      "Epoch 761/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.2069 - val_acc: 0.7282\n",
      "Epoch 762/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2048 - val_acc: 0.7282\n",
      "Epoch 763/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2031 - val_acc: 0.7282\n",
      "Epoch 764/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2084 - val_acc: 0.7282\n",
      "Epoch 765/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2629 - val_acc: 0.7315\n",
      "Epoch 766/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0081 - acc: 0.9978 - val_loss: 3.0947 - val_acc: 0.7282\n",
      "Epoch 767/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0905 - val_acc: 0.7282\n",
      "Epoch 768/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0901 - val_acc: 0.7282\n",
      "Epoch 769/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0956 - val_acc: 0.7282\n",
      "Epoch 770/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0913 - val_acc: 0.7282\n",
      "Epoch 771/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 3.0936 - val_acc: 0.7282\n",
      "Epoch 772/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0958 - val_acc: 0.7282\n",
      "Epoch 773/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0969 - val_acc: 0.7282\n",
      "Epoch 774/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0983 - val_acc: 0.7282\n",
      "Epoch 775/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1030 - val_acc: 0.7282\n",
      "Epoch 776/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1009 - val_acc: 0.7282\n",
      "Epoch 777/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1069 - val_acc: 0.7282\n",
      "Epoch 778/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.1118 - val_acc: 0.7282\n",
      "Epoch 779/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.1127 - val_acc: 0.7282\n",
      "Epoch 780/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 3.1150 - val_acc: 0.7282\n",
      "Epoch 781/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.1136 - val_acc: 0.7282\n",
      "Epoch 782/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.1141 - val_acc: 0.7282\n",
      "Epoch 783/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.1132 - val_acc: 0.7282\n",
      "Epoch 784/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0837 - val_acc: 0.7349\n",
      "Epoch 785/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0494 - val_acc: 0.7282\n",
      "Epoch 786/1000\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0511 - val_acc: 0.7315\n",
      "Epoch 787/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0535 - val_acc: 0.7315\n",
      "Epoch 788/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.0526 - val_acc: 0.7315\n",
      "Epoch 789/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0526 - val_acc: 0.7315\n",
      "Epoch 790/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0557 - val_acc: 0.7315\n",
      "Epoch 791/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0552 - val_acc: 0.7315\n",
      "Epoch 792/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0559 - val_acc: 0.7315\n",
      "Epoch 793/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.0575 - val_acc: 0.7315\n",
      "Epoch 794/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0572 - val_acc: 0.7315\n",
      "Epoch 795/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0606 - val_acc: 0.7315\n",
      "Epoch 796/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0586 - val_acc: 0.7315\n",
      "Epoch 797/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0590 - val_acc: 0.7315\n",
      "Epoch 798/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0589 - val_acc: 0.7315\n",
      "Epoch 799/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.0560 - val_acc: 0.7315\n",
      "Epoch 800/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0545 - val_acc: 0.7315\n",
      "Epoch 801/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0527 - val_acc: 0.7315\n",
      "Epoch 802/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0510 - val_acc: 0.7315\n",
      "Epoch 803/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0521 - val_acc: 0.7315\n",
      "Epoch 804/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.0472 - val_acc: 0.7315\n",
      "Epoch 805/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0470 - val_acc: 0.7315\n",
      "Epoch 806/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0480 - val_acc: 0.7315\n",
      "Epoch 807/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0488 - val_acc: 0.7315\n",
      "Epoch 808/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0493 - val_acc: 0.7315\n",
      "Epoch 809/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0541 - val_acc: 0.7315\n",
      "Epoch 810/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0531 - val_acc: 0.7315\n",
      "Epoch 811/1000\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0528 - val_acc: 0.7315\n",
      "Epoch 812/1000\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0537 - val_acc: 0.7315\n",
      "Epoch 813/1000\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0536 - val_acc: 0.7315\n",
      "Epoch 814/1000\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.0539 - val_acc: 0.7315\n",
      "Epoch 815/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0532 - val_acc: 0.7315\n",
      "Epoch 816/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0597 - val_acc: 0.7315\n",
      "Epoch 817/1000\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0555 - val_acc: 0.7315\n",
      "Epoch 818/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0553 - val_acc: 0.7315\n",
      "Epoch 819/1000\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0563 - val_acc: 0.7315\n",
      "Epoch 820/1000\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0566 - val_acc: 0.7315\n",
      "Epoch 821/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0605 - val_acc: 0.7349\n",
      "Epoch 822/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0586 - val_acc: 0.7349\n",
      "Epoch 823/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0624 - val_acc: 0.7349\n",
      "Epoch 824/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0610 - val_acc: 0.7349\n",
      "Epoch 825/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0635 - val_acc: 0.7349\n",
      "Epoch 826/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0638 - val_acc: 0.7349\n",
      "Epoch 827/1000\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.0626 - val_acc: 0.7349\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 172us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0639 - val_acc: 0.7315\n",
      "Epoch 829/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0641 - val_acc: 0.7315\n",
      "Epoch 830/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0659 - val_acc: 0.7315\n",
      "Epoch 831/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0674 - val_acc: 0.7315\n",
      "Epoch 832/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0693 - val_acc: 0.7282\n",
      "Epoch 833/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0690 - val_acc: 0.7315\n",
      "Epoch 834/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0721 - val_acc: 0.7315\n",
      "Epoch 835/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0723 - val_acc: 0.7282\n",
      "Epoch 836/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0761 - val_acc: 0.7315\n",
      "Epoch 837/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0795 - val_acc: 0.7315\n",
      "Epoch 838/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0843 - val_acc: 0.7315\n",
      "Epoch 839/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.0823 - val_acc: 0.7315\n",
      "Epoch 840/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.0816 - val_acc: 0.7315\n",
      "Epoch 841/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.0883 - val_acc: 0.7282\n",
      "Epoch 842/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.0875 - val_acc: 0.7315\n",
      "Epoch 843/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0830 - val_acc: 0.7315\n",
      "Epoch 844/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1468 - val_acc: 0.7383\n",
      "Epoch 845/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 3.2105 - val_acc: 0.7148\n",
      "Epoch 846/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0091 - acc: 0.9978 - val_loss: 3.2309 - val_acc: 0.7282\n",
      "Epoch 847/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0227 - acc: 0.9966 - val_loss: 5.8861 - val_acc: 0.6040\n",
      "Epoch 848/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.2336 - acc: 0.9809 - val_loss: 5.3030 - val_acc: 0.6040\n",
      "Epoch 849/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0184 - acc: 0.9921 - val_loss: 2.7788 - val_acc: 0.7013\n",
      "Epoch 850/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0180 - acc: 0.9966 - val_loss: 3.1138 - val_acc: 0.7013\n",
      "Epoch 851/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0173 - acc: 0.9978 - val_loss: 3.2051 - val_acc: 0.7047\n",
      "Epoch 852/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1318 - val_acc: 0.7013\n",
      "Epoch 853/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1533 - val_acc: 0.6980\n",
      "Epoch 854/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0053 - acc: 0.9978 - val_loss: 3.3306 - val_acc: 0.7081\n",
      "Epoch 855/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0088 - acc: 0.9978 - val_loss: 3.3793 - val_acc: 0.7047\n",
      "Epoch 856/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0062 - acc: 0.9978 - val_loss: 3.4028 - val_acc: 0.6980\n",
      "Epoch 857/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 3.3916 - val_acc: 0.6980\n",
      "Epoch 858/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 3.4011 - val_acc: 0.6980\n",
      "Epoch 859/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.4674 - val_acc: 0.7114\n",
      "Epoch 860/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.5074 - val_acc: 0.7081\n",
      "Epoch 861/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0051 - acc: 0.9978 - val_loss: 3.5043 - val_acc: 0.7081\n",
      "Epoch 862/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0056 - acc: 0.9966 - val_loss: 3.8625 - val_acc: 0.6745\n",
      "Epoch 863/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0109 - acc: 0.9966 - val_loss: 3.6891 - val_acc: 0.6711\n",
      "Epoch 864/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 2.4166 - val_acc: 0.7181\n",
      "Epoch 865/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0059 - acc: 0.9978 - val_loss: 2.5824 - val_acc: 0.7215\n",
      "Epoch 866/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0052 - acc: 0.9978 - val_loss: 2.8440 - val_acc: 0.7181\n",
      "Epoch 867/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.9303 - val_acc: 0.7081\n",
      "Epoch 868/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 2.9523 - val_acc: 0.7081\n",
      "Epoch 869/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 2.9650 - val_acc: 0.7081\n",
      "Epoch 870/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0046 - acc: 0.9978 - val_loss: 2.9530 - val_acc: 0.7047\n",
      "Epoch 871/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0061 - acc: 0.9966 - val_loss: 2.9787 - val_acc: 0.7081\n",
      "Epoch 872/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.0147 - val_acc: 0.7081\n",
      "Epoch 873/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.0277 - val_acc: 0.7081\n",
      "Epoch 874/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0049 - acc: 0.9978 - val_loss: 3.0347 - val_acc: 0.7047\n",
      "Epoch 875/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.0791 - val_acc: 0.7081\n",
      "Epoch 876/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.0894 - val_acc: 0.7081\n",
      "Epoch 877/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.1017 - val_acc: 0.7013\n",
      "Epoch 878/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1451 - val_acc: 0.7114\n",
      "Epoch 879/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1590 - val_acc: 0.7114\n",
      "Epoch 880/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.1847 - val_acc: 0.7081\n",
      "Epoch 881/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2070 - val_acc: 0.7081\n",
      "Epoch 882/1000\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2226 - val_acc: 0.7047\n",
      "Epoch 883/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0062 - acc: 0.9978 - val_loss: 3.2366 - val_acc: 0.7047\n",
      "Epoch 884/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1540 - val_acc: 0.7081\n",
      "Epoch 885/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1400 - val_acc: 0.7081\n",
      "Epoch 886/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1421 - val_acc: 0.7081\n",
      "Epoch 887/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1421 - val_acc: 0.7081\n",
      "Epoch 888/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1448 - val_acc: 0.7081\n",
      "Epoch 889/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1454 - val_acc: 0.7047\n",
      "Epoch 890/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1680 - val_acc: 0.7181\n",
      "Epoch 891/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1823 - val_acc: 0.7181\n",
      "Epoch 892/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1850 - val_acc: 0.7181\n",
      "Epoch 893/1000\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.1853 - val_acc: 0.7181\n",
      "Epoch 894/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.1903 - val_acc: 0.7181\n",
      "Epoch 895/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.2131 - val_acc: 0.7114\n",
      "Epoch 896/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2173 - val_acc: 0.7081\n",
      "Epoch 897/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2218 - val_acc: 0.7081\n",
      "Epoch 898/1000\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2244 - val_acc: 0.7081\n",
      "Epoch 899/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.2291 - val_acc: 0.7081\n",
      "Epoch 900/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.2330 - val_acc: 0.7081\n",
      "Epoch 901/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0156 - acc: 0.9966 - val_loss: 3.4277 - val_acc: 0.6879\n",
      "Epoch 902/1000\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.0153 - acc: 0.9944 - val_loss: 4.2134 - val_acc: 0.6409\n",
      "Epoch 903/1000\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.0205 - acc: 0.9955 - val_loss: 3.6920 - val_acc: 0.7148\n",
      "Epoch 904/1000\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 4.3351 - val_acc: 0.6678\n",
      "Epoch 905/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0067 - acc: 0.9978 - val_loss: 3.4347 - val_acc: 0.7215\n",
      "Epoch 906/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0224 - acc: 0.9978 - val_loss: 5.1856 - val_acc: 0.6007\n",
      "Epoch 907/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0563 - acc: 0.9944 - val_loss: 4.0935 - val_acc: 0.6443\n",
      "Epoch 908/1000\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 4.4582 - val_acc: 0.6611\n",
      "Epoch 909/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0218 - acc: 0.9978 - val_loss: 4.4695 - val_acc: 0.6611\n",
      "Epoch 910/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 4.2794 - val_acc: 0.6711\n",
      "Epoch 911/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0102 - acc: 0.9978 - val_loss: 3.7608 - val_acc: 0.7215\n",
      "Epoch 912/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0136 - acc: 0.9966 - val_loss: 3.8786 - val_acc: 0.6812\n",
      "Epoch 913/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0136 - acc: 0.9978 - val_loss: 4.3479 - val_acc: 0.6644\n",
      "Epoch 914/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 4.2997 - val_acc: 0.6678\n",
      "Epoch 915/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.2871 - val_acc: 0.6678\n",
      "Epoch 916/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 4.2824 - val_acc: 0.6678\n",
      "Epoch 917/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 4.2820 - val_acc: 0.6644\n",
      "Epoch 918/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.2816 - val_acc: 0.6678\n",
      "Epoch 919/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 4.2674 - val_acc: 0.6711\n",
      "Epoch 920/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.2588 - val_acc: 0.6711\n",
      "Epoch 921/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 4.2555 - val_acc: 0.6711\n",
      "Epoch 922/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.2548 - val_acc: 0.6711\n",
      "Epoch 923/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 4.2546 - val_acc: 0.6711\n",
      "Epoch 924/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 4.2546 - val_acc: 0.6711\n",
      "Epoch 925/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 4.2513 - val_acc: 0.6711\n",
      "Epoch 926/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.2432 - val_acc: 0.6711\n",
      "Epoch 927/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.2418 - val_acc: 0.6711\n",
      "Epoch 928/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 4.2422 - val_acc: 0.6711\n",
      "Epoch 929/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 4.2406 - val_acc: 0.6711\n",
      "Epoch 930/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 4.2397 - val_acc: 0.6711\n",
      "Epoch 931/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0125 - acc: 0.9978 - val_loss: 3.7449 - val_acc: 0.6980\n",
      "Epoch 932/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0228 - acc: 0.9966 - val_loss: 4.4913 - val_acc: 0.6678\n",
      "Epoch 933/1000\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.0368 - acc: 0.9978 - val_loss: 3.5341 - val_acc: 0.7215\n",
      "Epoch 934/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.2585 - val_acc: 0.7315\n",
      "Epoch 935/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2497 - val_acc: 0.7215\n",
      "Epoch 936/1000\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.2463 - val_acc: 0.7215\n",
      "Epoch 937/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2515 - val_acc: 0.7215\n",
      "Epoch 938/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2523 - val_acc: 0.7215\n",
      "Epoch 939/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2647 - val_acc: 0.7181\n",
      "Epoch 940/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2658 - val_acc: 0.7181\n",
      "Epoch 941/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2726 - val_acc: 0.7215\n",
      "Epoch 942/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2693 - val_acc: 0.7248\n",
      "Epoch 943/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.2834 - val_acc: 0.7248\n",
      "Epoch 944/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 3.2775 - val_acc: 0.7248\n",
      "Epoch 945/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2674 - val_acc: 0.7248\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 181us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2640 - val_acc: 0.7248\n",
      "Epoch 947/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 3.2729 - val_acc: 0.7248\n",
      "Epoch 948/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.2710 - val_acc: 0.7248\n",
      "Epoch 949/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2755 - val_acc: 0.7215\n",
      "Epoch 950/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2786 - val_acc: 0.7215\n",
      "Epoch 951/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2845 - val_acc: 0.7215\n",
      "Epoch 952/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2870 - val_acc: 0.7215\n",
      "Epoch 953/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2883 - val_acc: 0.7215\n",
      "Epoch 954/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.2878 - val_acc: 0.7215\n",
      "Epoch 955/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.2908 - val_acc: 0.7215\n",
      "Epoch 956/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.2895 - val_acc: 0.7215\n",
      "Epoch 957/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2928 - val_acc: 0.7215\n",
      "Epoch 958/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.2964 - val_acc: 0.7215\n",
      "Epoch 959/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.3045 - val_acc: 0.7215\n",
      "Epoch 960/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.3053 - val_acc: 0.7215\n",
      "Epoch 961/1000\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.3053 - val_acc: 0.7215\n",
      "Epoch 962/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3061 - val_acc: 0.7215\n",
      "Epoch 963/1000\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.3048 - val_acc: 0.7215\n",
      "Epoch 964/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3068 - val_acc: 0.7215\n",
      "Epoch 965/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3043 - val_acc: 0.7215\n",
      "Epoch 966/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.3036 - val_acc: 0.7215\n",
      "Epoch 967/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.3126 - val_acc: 0.7215\n",
      "Epoch 968/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.3084 - val_acc: 0.7215\n",
      "Epoch 969/1000\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.3137 - val_acc: 0.7215\n",
      "Epoch 970/1000\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.3195 - val_acc: 0.7215\n",
      "Epoch 971/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.3177 - val_acc: 0.7215\n",
      "Epoch 972/1000\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.3278 - val_acc: 0.7215\n",
      "Epoch 973/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 3.3078 - val_acc: 0.7215\n",
      "Epoch 974/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 3.2892 - val_acc: 0.7215\n",
      "Epoch 975/1000\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2950 - val_acc: 0.7215\n",
      "Epoch 976/1000\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.2937 - val_acc: 0.7248\n",
      "Epoch 977/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.2845 - val_acc: 0.7248\n",
      "Epoch 978/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 3.2900 - val_acc: 0.7248\n",
      "Epoch 979/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 3.3446 - val_acc: 0.7282\n",
      "Epoch 980/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.3219 - val_acc: 0.7248\n",
      "Epoch 981/1000\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 3.4830 - val_acc: 0.7148\n",
      "Epoch 982/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4760 - val_acc: 0.7148\n",
      "Epoch 983/1000\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4705 - val_acc: 0.7148\n",
      "Epoch 984/1000\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4620 - val_acc: 0.7148\n",
      "Epoch 985/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.4692 - val_acc: 0.7148\n",
      "Epoch 986/1000\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.0101 - acc: 0.9978 - val_loss: 5.8160 - val_acc: 0.5872\n",
      "Epoch 987/1000\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.0176 - acc: 0.9978 - val_loss: 3.9781 - val_acc: 0.5604\n",
      "Epoch 988/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0452 - acc: 0.9877 - val_loss: 2.6339 - val_acc: 0.7181\n",
      "Epoch 989/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0048 - acc: 0.9989 - val_loss: 3.4048 - val_acc: 0.7047\n",
      "Epoch 990/1000\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 3.6738 - val_acc: 0.7013\n",
      "Epoch 991/1000\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.0454 - acc: 0.9944 - val_loss: 2.3470 - val_acc: 0.7215\n",
      "Epoch 992/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0246 - acc: 0.9921 - val_loss: 3.1448 - val_acc: 0.7282\n",
      "Epoch 993/1000\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.5072 - val_acc: 0.7013\n",
      "Epoch 994/1000\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 3.7376 - val_acc: 0.6946\n",
      "Epoch 995/1000\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.0054 - acc: 0.9978 - val_loss: 3.4757 - val_acc: 0.7148\n",
      "Epoch 996/1000\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 3.8270 - val_acc: 0.7081\n",
      "Epoch 997/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0045 - acc: 0.9978 - val_loss: 3.9990 - val_acc: 0.6779\n",
      "Epoch 998/1000\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 4.0433 - val_acc: 0.6779\n",
      "Epoch 999/1000\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 0.9989 - val_loss: 4.0468 - val_acc: 0.6779\n",
      "Epoch 1000/1000\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.0047 - acc: 0.9978 - val_loss: 4.0501 - val_acc: 0.6779\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN, Word Embeddings 0.6835016835016835\n"
     ]
    }
   ],
   "source": [
    "accuracy, confusion = train_model(classifier, train_seq_x, train_y, test_seq_x, is_neural_net=True)\n",
    "print (\"CNN, Word Embeddings\",  accuracy)\n",
    "#with tf.Session() as sess:\n",
    "#    print(confusion.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
