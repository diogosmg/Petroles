{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para buscar resumos das teses elaboradas pelos empregados da Petrobras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from keras.models import load_model\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo configurações globais de proxy para realizar a extração dentro da rede Petrobras\n",
    "chave = 'upe2'\n",
    "pwd = 'fBO61291'\n",
    "proxy_url = 'http://'+chave+':'+pwd+'@inet-sys.gnet.petrobras.com.br:804/'\n",
    "proxies = {\n",
    "  'http' : proxy_url ,\n",
    "  'https' : proxy_url ,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente entraremos no site da BDTD e buscaremos os links de todas as teses de uma determinada intituição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para coletar os links das tese\n",
    "\n",
    "def get_links(page):\n",
    "        \n",
    "    #preparar a url\n",
    "    url = ('http://bdtd.ibict.br/vufind/Search/Results?filter%5B%5D=institution%3A\"UFRGS\"&type=AllFields&page=' +\n",
    "           str(page))\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Coletando link para as teses\n",
    "    links = []\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if 'title' in doc.get('class', []):\n",
    "            links.append(doc['href'])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000  links capturados,  1100  páginas\n",
      "24000  links capturados,  1200  páginas\n",
      "26000  links capturados,  1300  páginas\n",
      "28000  links capturados,  1400  páginas\n",
      "30000  links capturados,  1500  páginas\n",
      "32000  links capturados,  1600  páginas\n",
      "34000  links capturados,  1700  páginas\n",
      "35700  links capturados,  1785  páginas\n"
     ]
    }
   ],
   "source": [
    "#Coletar o link de todas as teses\n",
    "start_page = 1001\n",
    "n_pages = 1790 # Cada página retorna 20 teses\n",
    "\n",
    "links = []\n",
    "\n",
    "for p in range(start_page, n_pages):\n",
    "    link = get_links(p)\n",
    "    if link != []:\n",
    "        links = links + link\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    if p % 100 == 0:\n",
    "        print (p*20, ' links capturados, ', p, ' páginas')\n",
    "        with open('links_ufrgs', \"w\") as output:\n",
    "            writer = csv.writer(output, lineterminator='\\n')\n",
    "            for val in links:\n",
    "                writer.writerow([val])\n",
    "                \n",
    "with open('links_ufrgs', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in links:\n",
    "        writer.writerow([val]) \n",
    "print (p*20, ' links capturados, ', p, ' páginas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo arquivo gravado anteriormente\n",
    "\n",
    "#links = []\n",
    "#with open('links_ufrgs', 'r') as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    for link in reader:\n",
    "#        links.append(link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida vamos recuperar os metadados de cada link coletado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para buscar os metadados das teses no BDTD\n",
    "def tese_link(link):\n",
    "    #definir url\n",
    "    url = 'http://bdtd.ibict.br' + link\n",
    "    \n",
    "    #Requisitar html e fazer o parser\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Dicionário para armazenar as informações da tese\n",
    "    tese = {}  \n",
    "    \n",
    "    #Adicionar título\n",
    "    tese['Title'] = soup.find('h3').get_text()\n",
    "    for doc in soup.find_all('tr'):\n",
    "        #Identificar atributo\n",
    "        try:\n",
    "            atributo = doc.find('th').get_text()\n",
    "        except:\n",
    "            pass\n",
    "        #Verificar se o atributo possui mais de um dado\n",
    "        for row in doc.find_all('td'):\n",
    "            #Adicionar o atributo no dicionário\n",
    "            if row.find('div') == None:\n",
    "                try:\n",
    "                    tese[atributo] = doc.find('td').get_text()\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                element = []\n",
    "                #No dicionário, adicionar todos os dados ao seu respectivo atributo\n",
    "                for e in doc.find_all('div'):\n",
    "                    try:\n",
    "                        sub_e = []\n",
    "                        for sub_element in e.find_all('a'):\n",
    "                            element.append(sub_element.get_text()) \n",
    "                        #element.append(sub_e)\n",
    "                    except:\n",
    "                        pass\n",
    "                tese[atributo] = element\n",
    "    \n",
    "    return(tese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como em alguns casos o resumo português e inglês se misturaram, foi implementado uma função para separar os textos misturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar resumos português e inglês\n",
    "def separacao_port_engl(abstract):\n",
    "\n",
    "    mix_sent = nltk.sent_tokenize(abstract)\n",
    "\n",
    "    new_mix = []\n",
    "    for sent in mix_sent:\n",
    "        position = sent.find('.')\n",
    "        if position != len(sent)-1:\n",
    "            sent_1 = sent[:position+1]\n",
    "            sent_2 = sent[position+1:]\n",
    "            new_mix.append(sent_1)\n",
    "            new_mix.append(sent_2)\n",
    "        else:\n",
    "            new_mix.append(sent)\n",
    "\n",
    "    mix_sent = new_mix\n",
    "\n",
    "    port = []\n",
    "    engl = []\n",
    "\n",
    "    for sent in mix_sent:\n",
    "        try:\n",
    "            if detect (sent) == 'pt':\n",
    "                port.append(sent)\n",
    "            else:\n",
    "                engl.append (sent)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    port = \" \".join(port)\n",
    "    engl = \" \".join(engl)\n",
    "\n",
    "    return(port, engl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até esse momento estamos recuperando as informações de todas as teses de uma determinada instituição. No entanto o objetivo é gravar os metadados e salvar o arquivo apenas das teses relacionadas a O&G. Portanto, vamos carregar os algoritmos de classificação e de vetorização de palavras treinados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 400, 50)           9289150   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 396, 128)          32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 194, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 93, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,814,591\n",
      "Trainable params: 525,441\n",
      "Non-trainable params: 9,289,150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Carregando modelo Word2Vec\n",
    "BDTD_word2vec_50 = Word2Vec.load(\"..\\..\\..\\Embeddings\\BDTD_word2vec_50\")\n",
    "# Carregando modelo keras\n",
    "model_keras = load_model('..\\..\\..\\model_cnn.h5')\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário proveniente do modelo de word embedding para converter palavras em índices\n",
    "word2index = {}\n",
    "for index, word in enumerate(BDTD_word2vec_50.wv.index2word):\n",
    "    word2index[word] = index\n",
    "    \n",
    "# Função para converter texto em sequência de índices\n",
    "def index_pad_text(text, maxlen, word2index):\n",
    "    maxlen = 400\n",
    "    new_text = [] \n",
    "    \n",
    "    for word in word_tokenize(text):\n",
    "        try:\n",
    "            new_text.append(word2index[word])\n",
    "        except:\n",
    "            pass\n",
    "    # Add the padding for each sentence. Here I am padding with 0\n",
    "    if len(new_text) > maxlen:\n",
    "        new_text = new_text[:400]\n",
    "    else:\n",
    "        new_text += [0] * (maxlen - len(new_text))\n",
    "\n",
    "    return np.array(new_text)\n",
    "\n",
    "maxlen = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada link coletado será feita as seguintes tarefas:\n",
    "* verificar se o texto português e inglês estão misturados;\n",
    "* transformar o texto em sequência de índices;\n",
    "* classificar quanto a relevância ao domínio de O&G;\n",
    "* se for relevante, gravar os metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109  teses avaliadas e  1  teses relacionadas a O&G encontradas.\n",
      "140  teses avaliadas e  2  teses relacionadas a O&G encontradas.\n",
      "145  teses avaliadas e  3  teses relacionadas a O&G encontradas.\n",
      "164  teses avaliadas e  4  teses relacionadas a O&G encontradas.\n",
      "361  teses avaliadas e  5  teses relacionadas a O&G encontradas.\n",
      "440  teses avaliadas e  6  teses relacionadas a O&G encontradas.\n",
      "459  teses avaliadas e  7  teses relacionadas a O&G encontradas.\n",
      "574  teses avaliadas e  8  teses relacionadas a O&G encontradas.\n",
      "585  teses avaliadas e  9  teses relacionadas a O&G encontradas.\n",
      "683  teses avaliadas e  10  teses relacionadas a O&G encontradas.\n",
      "697  teses avaliadas e  11  teses relacionadas a O&G encontradas.\n",
      "698  teses avaliadas e  12  teses relacionadas a O&G encontradas.\n",
      "700  teses avaliadas e  13  teses relacionadas a O&G encontradas.\n",
      "704  teses avaliadas e  14  teses relacionadas a O&G encontradas.\n",
      "763  teses avaliadas e  15  teses relacionadas a O&G encontradas.\n",
      "999  teses avaliadas e  16  teses relacionadas a O&G encontradas.\n",
      "1001  teses avaliadas e  17  teses relacionadas a O&G encontradas.\n",
      "1073  teses avaliadas e  18  teses relacionadas a O&G encontradas.\n",
      "1128  teses avaliadas e  19  teses relacionadas a O&G encontradas.\n",
      "1187  teses avaliadas e  20  teses relacionadas a O&G encontradas.\n",
      "1346  teses avaliadas e  21  teses relacionadas a O&G encontradas.\n",
      "1347  teses avaliadas e  22  teses relacionadas a O&G encontradas.\n",
      "1349  teses avaliadas e  23  teses relacionadas a O&G encontradas.\n",
      "1350  teses avaliadas e  24  teses relacionadas a O&G encontradas.\n",
      "1351  teses avaliadas e  25  teses relacionadas a O&G encontradas.\n",
      "1366  teses avaliadas e  26  teses relacionadas a O&G encontradas.\n",
      "1389  teses avaliadas e  27  teses relacionadas a O&G encontradas.\n",
      "1390  teses avaliadas e  28  teses relacionadas a O&G encontradas.\n",
      "1396  teses avaliadas e  29  teses relacionadas a O&G encontradas.\n",
      "1530  teses avaliadas e  30  teses relacionadas a O&G encontradas.\n",
      "1543  teses avaliadas e  31  teses relacionadas a O&G encontradas.\n",
      "1719  teses avaliadas e  32  teses relacionadas a O&G encontradas.\n",
      "1725  teses avaliadas e  33  teses relacionadas a O&G encontradas.\n",
      "1734  teses avaliadas e  34  teses relacionadas a O&G encontradas.\n",
      "1771  teses avaliadas e  35  teses relacionadas a O&G encontradas.\n",
      "1877  teses avaliadas e  36  teses relacionadas a O&G encontradas.\n",
      "1942  teses avaliadas e  37  teses relacionadas a O&G encontradas.\n",
      "1964  teses avaliadas e  38  teses relacionadas a O&G encontradas.\n",
      "2096  teses avaliadas e  39  teses relacionadas a O&G encontradas.\n",
      "2430  teses avaliadas e  40  teses relacionadas a O&G encontradas.\n",
      "2579  teses avaliadas e  41  teses relacionadas a O&G encontradas.\n",
      "2581  teses avaliadas e  42  teses relacionadas a O&G encontradas.\n",
      "2685  teses avaliadas e  43  teses relacionadas a O&G encontradas.\n",
      "2690  teses avaliadas e  44  teses relacionadas a O&G encontradas.\n",
      "2691  teses avaliadas e  45  teses relacionadas a O&G encontradas.\n",
      "2698  teses avaliadas e  46  teses relacionadas a O&G encontradas.\n",
      "2892  teses avaliadas e  47  teses relacionadas a O&G encontradas.\n",
      "2921  teses avaliadas e  48  teses relacionadas a O&G encontradas.\n",
      "2971  teses avaliadas e  49  teses relacionadas a O&G encontradas.\n",
      "2983  teses avaliadas e  50  teses relacionadas a O&G encontradas.\n",
      "3597  teses avaliadas e  51  teses relacionadas a O&G encontradas.\n",
      "3605  teses avaliadas e  52  teses relacionadas a O&G encontradas.\n",
      "3799  teses avaliadas e  53  teses relacionadas a O&G encontradas.\n",
      "3802  teses avaliadas e  54  teses relacionadas a O&G encontradas.\n",
      "4009  teses avaliadas e  55  teses relacionadas a O&G encontradas.\n",
      "4041  teses avaliadas e  56  teses relacionadas a O&G encontradas.\n",
      "4152  teses avaliadas e  57  teses relacionadas a O&G encontradas.\n",
      "4158  teses avaliadas e  58  teses relacionadas a O&G encontradas.\n",
      "4159  teses avaliadas e  59  teses relacionadas a O&G encontradas.\n",
      "4284  teses avaliadas e  60  teses relacionadas a O&G encontradas.\n",
      "4387  teses avaliadas e  61  teses relacionadas a O&G encontradas.\n",
      "4577  teses avaliadas e  62  teses relacionadas a O&G encontradas.\n",
      "4578  teses avaliadas e  63  teses relacionadas a O&G encontradas.\n",
      "4740  teses avaliadas e  64  teses relacionadas a O&G encontradas.\n",
      "4880  teses avaliadas e  65  teses relacionadas a O&G encontradas.\n",
      "4889  teses avaliadas e  66  teses relacionadas a O&G encontradas.\n",
      "4905  teses avaliadas e  67  teses relacionadas a O&G encontradas.\n",
      "4907  teses avaliadas e  68  teses relacionadas a O&G encontradas.\n",
      "4943  teses avaliadas e  69  teses relacionadas a O&G encontradas.\n",
      "4947  teses avaliadas e  70  teses relacionadas a O&G encontradas.\n",
      "5068  teses avaliadas e  71  teses relacionadas a O&G encontradas.\n",
      "5074  teses avaliadas e  72  teses relacionadas a O&G encontradas.\n",
      "5194  teses avaliadas e  73  teses relacionadas a O&G encontradas.\n",
      "5249  teses avaliadas e  74  teses relacionadas a O&G encontradas.\n",
      "5290  teses avaliadas e  75  teses relacionadas a O&G encontradas.\n",
      "5325  teses avaliadas e  76  teses relacionadas a O&G encontradas.\n",
      "5336  teses avaliadas e  77  teses relacionadas a O&G encontradas.\n",
      "5567  teses avaliadas e  78  teses relacionadas a O&G encontradas.\n",
      "5660  teses avaliadas e  79  teses relacionadas a O&G encontradas.\n",
      "6034  teses avaliadas e  80  teses relacionadas a O&G encontradas.\n",
      "6232  teses avaliadas e  81  teses relacionadas a O&G encontradas.\n",
      "6316  teses avaliadas e  82  teses relacionadas a O&G encontradas.\n",
      "6445  teses avaliadas e  83  teses relacionadas a O&G encontradas.\n",
      "6496  teses avaliadas e  84  teses relacionadas a O&G encontradas.\n",
      "6535  teses avaliadas e  85  teses relacionadas a O&G encontradas.\n",
      "6539  teses avaliadas e  86  teses relacionadas a O&G encontradas.\n",
      "6586  teses avaliadas e  87  teses relacionadas a O&G encontradas.\n",
      "6615  teses avaliadas e  88  teses relacionadas a O&G encontradas.\n",
      "6622  teses avaliadas e  89  teses relacionadas a O&G encontradas.\n",
      "6628  teses avaliadas e  90  teses relacionadas a O&G encontradas.\n",
      "6631  teses avaliadas e  91  teses relacionadas a O&G encontradas.\n",
      "6654  teses avaliadas e  92  teses relacionadas a O&G encontradas.\n",
      "6806  teses avaliadas e  93  teses relacionadas a O&G encontradas.\n",
      "6883  teses avaliadas e  94  teses relacionadas a O&G encontradas.\n",
      "6931  teses avaliadas e  95  teses relacionadas a O&G encontradas.\n",
      "6933  teses avaliadas e  96  teses relacionadas a O&G encontradas.\n",
      "6968  teses avaliadas e  97  teses relacionadas a O&G encontradas.\n",
      "7062  teses avaliadas e  98  teses relacionadas a O&G encontradas.\n",
      "7089  teses avaliadas e  99  teses relacionadas a O&G encontradas.\n",
      "7131  teses avaliadas e  100  teses relacionadas a O&G encontradas.\n",
      "7142  teses avaliadas e  101  teses relacionadas a O&G encontradas.\n",
      "7251  teses avaliadas e  102  teses relacionadas a O&G encontradas.\n",
      "7320  teses avaliadas e  103  teses relacionadas a O&G encontradas.\n",
      "7342  teses avaliadas e  104  teses relacionadas a O&G encontradas.\n",
      "7537  teses avaliadas e  105  teses relacionadas a O&G encontradas.\n",
      "7678  teses avaliadas e  106  teses relacionadas a O&G encontradas.\n",
      "7715  teses avaliadas e  107  teses relacionadas a O&G encontradas.\n",
      "7716  teses avaliadas e  108  teses relacionadas a O&G encontradas.\n",
      "7723  teses avaliadas e  109  teses relacionadas a O&G encontradas.\n",
      "7725  teses avaliadas e  110  teses relacionadas a O&G encontradas.\n",
      "7731  teses avaliadas e  111  teses relacionadas a O&G encontradas.\n",
      "7791  teses avaliadas e  112  teses relacionadas a O&G encontradas.\n",
      "7816  teses avaliadas e  113  teses relacionadas a O&G encontradas.\n",
      "8064  teses avaliadas e  114  teses relacionadas a O&G encontradas.\n",
      "8231  teses avaliadas e  115  teses relacionadas a O&G encontradas.\n",
      "8460  teses avaliadas e  116  teses relacionadas a O&G encontradas.\n",
      "8739  teses avaliadas e  117  teses relacionadas a O&G encontradas.\n",
      "8883  teses avaliadas e  118  teses relacionadas a O&G encontradas.\n",
      "8965  teses avaliadas e  119  teses relacionadas a O&G encontradas.\n",
      "9043  teses avaliadas e  120  teses relacionadas a O&G encontradas.\n",
      "9066  teses avaliadas e  121  teses relacionadas a O&G encontradas.\n",
      "9083  teses avaliadas e  122  teses relacionadas a O&G encontradas.\n",
      "9404  teses avaliadas e  123  teses relacionadas a O&G encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9451  teses avaliadas e  124  teses relacionadas a O&G encontradas.\n",
      "9498  teses avaliadas e  125  teses relacionadas a O&G encontradas.\n",
      "9544  teses avaliadas e  126  teses relacionadas a O&G encontradas.\n",
      "9594  teses avaliadas e  127  teses relacionadas a O&G encontradas.\n",
      "9697  teses avaliadas e  128  teses relacionadas a O&G encontradas.\n",
      "9817  teses avaliadas e  129  teses relacionadas a O&G encontradas.\n",
      "9818  teses avaliadas e  130  teses relacionadas a O&G encontradas.\n",
      "9866  teses avaliadas e  131  teses relacionadas a O&G encontradas.\n",
      "9930  teses avaliadas e  132  teses relacionadas a O&G encontradas.\n",
      "9957  teses avaliadas e  133  teses relacionadas a O&G encontradas.\n",
      "10118  teses avaliadas e  134  teses relacionadas a O&G encontradas.\n",
      "10162  teses avaliadas e  135  teses relacionadas a O&G encontradas.\n",
      "10165  teses avaliadas e  136  teses relacionadas a O&G encontradas.\n",
      "10270  teses avaliadas e  137  teses relacionadas a O&G encontradas.\n",
      "10377  teses avaliadas e  138  teses relacionadas a O&G encontradas.\n",
      "10381  teses avaliadas e  139  teses relacionadas a O&G encontradas.\n",
      "10447  teses avaliadas e  140  teses relacionadas a O&G encontradas.\n",
      "10461  teses avaliadas e  141  teses relacionadas a O&G encontradas.\n",
      "10471  teses avaliadas e  142  teses relacionadas a O&G encontradas.\n",
      "10473  teses avaliadas e  143  teses relacionadas a O&G encontradas.\n",
      "10521  teses avaliadas e  144  teses relacionadas a O&G encontradas.\n",
      "10531  teses avaliadas e  145  teses relacionadas a O&G encontradas.\n",
      "10541  teses avaliadas e  146  teses relacionadas a O&G encontradas.\n",
      "10552  teses avaliadas e  147  teses relacionadas a O&G encontradas.\n",
      "10565  teses avaliadas e  148  teses relacionadas a O&G encontradas.\n",
      "10593  teses avaliadas e  149  teses relacionadas a O&G encontradas.\n",
      "10610  teses avaliadas e  150  teses relacionadas a O&G encontradas.\n",
      "10703  teses avaliadas e  151  teses relacionadas a O&G encontradas.\n",
      "10757  teses avaliadas e  152  teses relacionadas a O&G encontradas.\n",
      "10760  teses avaliadas e  153  teses relacionadas a O&G encontradas.\n",
      "10775  teses avaliadas e  154  teses relacionadas a O&G encontradas.\n",
      "10804  teses avaliadas e  155  teses relacionadas a O&G encontradas.\n",
      "11026  teses avaliadas e  156  teses relacionadas a O&G encontradas.\n",
      "11101  teses avaliadas e  157  teses relacionadas a O&G encontradas.\n",
      "11275  teses avaliadas e  158  teses relacionadas a O&G encontradas.\n",
      "11450  teses avaliadas e  159  teses relacionadas a O&G encontradas.\n",
      "11457  teses avaliadas e  160  teses relacionadas a O&G encontradas.\n",
      "11513  teses avaliadas e  161  teses relacionadas a O&G encontradas.\n",
      "11545  teses avaliadas e  162  teses relacionadas a O&G encontradas.\n",
      "11778  teses avaliadas e  163  teses relacionadas a O&G encontradas.\n",
      "11780  teses avaliadas e  164  teses relacionadas a O&G encontradas.\n",
      "11786  teses avaliadas e  165  teses relacionadas a O&G encontradas.\n",
      "11793  teses avaliadas e  166  teses relacionadas a O&G encontradas.\n",
      "11848  teses avaliadas e  167  teses relacionadas a O&G encontradas.\n",
      "11852  teses avaliadas e  168  teses relacionadas a O&G encontradas.\n",
      "11860  teses avaliadas e  169  teses relacionadas a O&G encontradas.\n",
      "11928  teses avaliadas e  170  teses relacionadas a O&G encontradas.\n",
      "11931  teses avaliadas e  171  teses relacionadas a O&G encontradas.\n",
      "12044  teses avaliadas e  172  teses relacionadas a O&G encontradas.\n",
      "12142  teses avaliadas e  173  teses relacionadas a O&G encontradas.\n",
      "12162  teses avaliadas e  174  teses relacionadas a O&G encontradas.\n",
      "12251  teses avaliadas e  175  teses relacionadas a O&G encontradas.\n",
      "12272  teses avaliadas e  176  teses relacionadas a O&G encontradas.\n",
      "12342  teses avaliadas e  177  teses relacionadas a O&G encontradas.\n",
      "12500  teses avaliadas e  178  teses relacionadas a O&G encontradas.\n",
      "12523  teses avaliadas e  179  teses relacionadas a O&G encontradas.\n",
      "12552  teses avaliadas e  180  teses relacionadas a O&G encontradas.\n",
      "12639  teses avaliadas e  181  teses relacionadas a O&G encontradas.\n",
      "12659  teses avaliadas e  182  teses relacionadas a O&G encontradas.\n",
      "12781  teses avaliadas e  183  teses relacionadas a O&G encontradas.\n",
      "12857  teses avaliadas e  184  teses relacionadas a O&G encontradas.\n",
      "12866  teses avaliadas e  185  teses relacionadas a O&G encontradas.\n",
      "12959  teses avaliadas e  186  teses relacionadas a O&G encontradas.\n",
      "12980  teses avaliadas e  187  teses relacionadas a O&G encontradas.\n",
      "13031  teses avaliadas e  188  teses relacionadas a O&G encontradas.\n",
      "13055  teses avaliadas e  189  teses relacionadas a O&G encontradas.\n",
      "13168  teses avaliadas e  190  teses relacionadas a O&G encontradas.\n",
      "13264  teses avaliadas e  191  teses relacionadas a O&G encontradas.\n",
      "13408  teses avaliadas e  192  teses relacionadas a O&G encontradas.\n",
      "13437  teses avaliadas e  193  teses relacionadas a O&G encontradas.\n",
      "13438  teses avaliadas e  194  teses relacionadas a O&G encontradas.\n",
      "13469  teses avaliadas e  195  teses relacionadas a O&G encontradas.\n",
      "13612  teses avaliadas e  196  teses relacionadas a O&G encontradas.\n",
      "13631  teses avaliadas e  197  teses relacionadas a O&G encontradas.\n",
      "13735  teses avaliadas e  198  teses relacionadas a O&G encontradas.\n",
      "13769  teses avaliadas e  199  teses relacionadas a O&G encontradas.\n",
      "13802  teses avaliadas e  200  teses relacionadas a O&G encontradas.\n",
      "13809  teses avaliadas e  201  teses relacionadas a O&G encontradas.\n",
      "13913  teses avaliadas e  202  teses relacionadas a O&G encontradas.\n",
      "14094  teses avaliadas e  203  teses relacionadas a O&G encontradas.\n",
      "14183  teses avaliadas e  204  teses relacionadas a O&G encontradas.\n",
      "14201  teses avaliadas e  205  teses relacionadas a O&G encontradas.\n",
      "14205  teses avaliadas e  206  teses relacionadas a O&G encontradas.\n",
      "14445  teses avaliadas e  207  teses relacionadas a O&G encontradas.\n",
      "14651  teses avaliadas e  208  teses relacionadas a O&G encontradas.\n",
      "14705  teses avaliadas e  209  teses relacionadas a O&G encontradas.\n",
      "14803  teses avaliadas e  210  teses relacionadas a O&G encontradas.\n",
      "14891  teses avaliadas e  211  teses relacionadas a O&G encontradas.\n",
      "14921  teses avaliadas e  212  teses relacionadas a O&G encontradas.\n",
      "14974  teses avaliadas e  213  teses relacionadas a O&G encontradas.\n",
      "14993  teses avaliadas e  214  teses relacionadas a O&G encontradas.\n",
      "15019  teses avaliadas e  215  teses relacionadas a O&G encontradas.\n",
      "15126  teses avaliadas e  216  teses relacionadas a O&G encontradas.\n",
      "15204  teses avaliadas e  217  teses relacionadas a O&G encontradas.\n",
      "15228  teses avaliadas e  218  teses relacionadas a O&G encontradas.\n",
      "15246  teses avaliadas e  219  teses relacionadas a O&G encontradas.\n",
      "15316  teses avaliadas e  220  teses relacionadas a O&G encontradas.\n",
      "15319  teses avaliadas e  221  teses relacionadas a O&G encontradas.\n",
      "15392  teses avaliadas e  222  teses relacionadas a O&G encontradas.\n",
      "15404  teses avaliadas e  223  teses relacionadas a O&G encontradas.\n",
      "15414  teses avaliadas e  224  teses relacionadas a O&G encontradas.\n",
      "15452  teses avaliadas e  225  teses relacionadas a O&G encontradas.\n",
      "15461  teses avaliadas e  226  teses relacionadas a O&G encontradas.\n"
     ]
    }
   ],
   "source": [
    "# Dicionário para agrupar os metadados\n",
    "metadados = {}\n",
    "# Contadores te links testados e classificados como O&G\n",
    "n_test = 0\n",
    "n_pet = 0\n",
    "# Testando cada link de links\n",
    "for link in links:\n",
    "    n_test += 1\n",
    "    try:\n",
    "        # Recuperar o metadados de uma tese\n",
    "        metadado = tese_link(link)\n",
    "        # Verificar se existe resumo em inglês, separar texto português/inglês e realocar \n",
    "        # os textos separados nas respectivas colunas\n",
    "        if 'Resumo inglês:' not in metadado:\n",
    "            metadado['Resumo inglês:'] = separacao_port_engl(metadado['Resumo Português:'])[1]\n",
    "        metadado['Resumo Português:'] = separacao_port_engl(metadado['Resumo Português:'])[0]\n",
    "        # Colocando o texto em minúscula\n",
    "        text = metadado['Resumo Português:'].lower()\n",
    "        # Convertendo as palavras em sequencias de acordo com o modelo word2vec\n",
    "        text_seq = index_pad_text(text, maxlen, word2index)\n",
    "        text_seq = text_seq.reshape((1, 400))\n",
    "        # Usando o algoritmo classificador para prever se a tese é relevante\n",
    "        pred = model_keras.predict(text_seq)[0]\n",
    "        #Se a classificação for menor do que 0.2 manter os metadados\n",
    "        if (pred < 0.2 and len(text) > 100):\n",
    "            metadado['Classificador'] = pred[0]\n",
    "            texto_completo = metadado['Download Texto Completo:']\n",
    "            metadados[texto_completo] = metadado\n",
    "            n_pet += 1\n",
    "            # Gravando os resultados em JSON\n",
    "            metadados_ufrgs = pd.DataFrame.from_dict(metadados, orient='index')\n",
    "            metadados_ufrgs.to_json('metadados_ufrgs_2.json', orient = 'index')\n",
    "            print(n_test, \" teses avaliadas e \", n_pet, \" teses relacionadas a O&G encontradas.\")\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluindo um ID para cada tese\n",
    "universidade = 'UFRGS'\n",
    "metadados_ufrgs['PDF_ID'] = metadados_ufrgs['Download Texto Completo:'].apply(lambda x: universidade + \n",
    "                                                                            '_' + \n",
    "                                                                            re.sub('/', '_', x[-6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadados_ufrgs.to_json('metadados_ufrgs_2.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando arquivos já gravados\n",
    "metadados_ufrgs = pd.read_json('metadados_ufrgs_2.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa será fazer o download das teses classificadas como relevante para o domínio de O&G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UFRGS__79848\n",
      "UFRGS__85049\n",
      "UFRGS__85177\n",
      "UFRGS__86401\n",
      "UFRGS__86451\n",
      "UFRGS__87357\n",
      "UFRGS__88350\n",
      "UFRGS__88551\n",
      "UFRGS__88552\n",
      "UFRGS__88617\n",
      "UFRGS__88619\n",
      "UFRGS__88626\n",
      "UFRGS__94674\n",
      "UFRGS__95994\n",
      "UFRGS__95995\n",
      "UFRGS__96306\n",
      "UFRGS__96317\n",
      "UFRGS__96328\n",
      "UFRGS__96470\n",
      "UFRGS__96482\n",
      "UFRGS__96492\n",
      "UFRGS__96503\n",
      "UFRGS__96631\n",
      "UFRGS__96636\n",
      "UFRGS__97840\n",
      "UFRGS__97869\n",
      "UFRGS__98144\n",
      "UFRGS__98635\n",
      "UFRGS__98639\n",
      "UFRGS_3_9991\n"
     ]
    }
   ],
   "source": [
    "for tese in metadados_ufrgs.iterrows():\n",
    "    print(tese[1]['PDF_ID'])\n",
    "    try:\n",
    "        #preparar a url\n",
    "        url = tese[1]['Download Texto Completo:']\n",
    "\n",
    "        #Fazer requisição e parsear o arquivo html\n",
    "        f = requests.get(url, proxies = proxies).text \n",
    "        soup = bs(f, \"html.parser\")\n",
    "\n",
    "        #Coletando link para arquivo das teses\n",
    "        links = []\n",
    "        for doc in soup.find_all('a', href=True):\n",
    "            if doc['href'][:17] == '/bitstream/handle':\n",
    "                links.append(doc['href'])\n",
    "\n",
    "        #Recuperando e gravando arquivo PDF\n",
    "        url = 'https://lume.ufrgs.br' + links[0]\n",
    "        pdf = requests.get(url, proxies = proxies)\n",
    "        filename = tese[1]['PDF_ID'] + '.pdf'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(pdf.content)\n",
    "    except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
