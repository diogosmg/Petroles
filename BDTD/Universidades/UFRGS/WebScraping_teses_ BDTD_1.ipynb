{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para buscar resumos das teses elaboradas pelos empregados da Petrobras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from keras.models import load_model\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo configurações globais de proxy para realizar a extração dentro da rede Petrobras\n",
    "chave = 'upe2'\n",
    "pwd = 'fBO61291'\n",
    "proxy_url = 'http://'+chave+':'+pwd+'@inet-sys.gnet.petrobras.com.br:804/'\n",
    "proxies = {\n",
    "  'http' : proxy_url ,\n",
    "  'https' : proxy_url ,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente entraremos no site da BDTD e buscaremos os links de todas as teses de uma determinada intituição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para coletar os links das tese\n",
    "\n",
    "def get_links(page):\n",
    "        \n",
    "    #preparar a url\n",
    "    url = ('http://bdtd.ibict.br/vufind/Search/Results?filter%5B%5D=institution%3A\"UFRGS\"&type=AllFields&page=' +\n",
    "           str(page))\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Coletando link para as teses\n",
    "    links = []\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if 'title' in doc.get('class', []):\n",
    "            links.append(doc['href'])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000  links capturados,  100  páginas\n",
      "4000  links capturados,  200  páginas\n",
      "6000  links capturados,  300  páginas\n",
      "8000  links capturados,  400  páginas\n",
      "10000  links capturados,  500  páginas\n",
      "12000  links capturados,  600  páginas\n",
      "14000  links capturados,  700  páginas\n",
      "16000  links capturados,  800  páginas\n",
      "18000  links capturados,  900  páginas\n",
      "19980  links capturados,  999  páginas\n"
     ]
    }
   ],
   "source": [
    "#Coletar o link de todas as teses\n",
    "start_page = 1\n",
    "n_pages = 1000 # Cada página retorna 20 teses\n",
    "\n",
    "links = []\n",
    "\n",
    "for p in range(start_page, n_pages):\n",
    "    link = get_links(p)\n",
    "    if link != []:\n",
    "        links = links + link\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    if p % 100 == 0:\n",
    "        print (p*20, ' links capturados, ', p, ' páginas')\n",
    "        with open('links_ufrgs', \"w\") as output:\n",
    "            writer = csv.writer(output, lineterminator='\\n')\n",
    "            for val in links:\n",
    "                writer.writerow([val])\n",
    "                \n",
    "with open('links_ufrgs', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in links:\n",
    "        writer.writerow([val]) \n",
    "print (p*20, ' links capturados, ', p, ' páginas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo arquivo gravado anteriormente\n",
    "\n",
    "#links = []\n",
    "#with open('links_ufrgs', 'r') as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    for link in reader:\n",
    "#        links.append(link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida vamos recuperar os metadados de cada link coletado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para buscar os metadados das teses no BDTD\n",
    "def tese_link(link):\n",
    "    #definir url\n",
    "    url = 'http://bdtd.ibict.br' + link\n",
    "    \n",
    "    #Requisitar html e fazer o parser\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Dicionário para armazenar as informações da tese\n",
    "    tese = {}  \n",
    "    \n",
    "    #Adicionar título\n",
    "    tese['Title'] = soup.find('h3').get_text()\n",
    "    for doc in soup.find_all('tr'):\n",
    "        #Identificar atributo\n",
    "        try:\n",
    "            atributo = doc.find('th').get_text()\n",
    "        except:\n",
    "            pass\n",
    "        #Verificar se o atributo possui mais de um dado\n",
    "        for row in doc.find_all('td'):\n",
    "            #Adicionar o atributo no dicionário\n",
    "            if row.find('div') == None:\n",
    "                try:\n",
    "                    tese[atributo] = doc.find('td').get_text()\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                element = []\n",
    "                #No dicionário, adicionar todos os dados ao seu respectivo atributo\n",
    "                for e in doc.find_all('div'):\n",
    "                    try:\n",
    "                        sub_e = []\n",
    "                        for sub_element in e.find_all('a'):\n",
    "                            element.append(sub_element.get_text()) \n",
    "                        #element.append(sub_e)\n",
    "                    except:\n",
    "                        pass\n",
    "                tese[atributo] = element\n",
    "    \n",
    "    return(tese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como em alguns casos o resumo português e inglês se misturaram, foi implementado uma função para separar os textos misturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar resumos português e inglês\n",
    "def separacao_port_engl(abstract):\n",
    "\n",
    "    mix_sent = nltk.sent_tokenize(abstract)\n",
    "\n",
    "    new_mix = []\n",
    "    for sent in mix_sent:\n",
    "        position = sent.find('.')\n",
    "        if position != len(sent)-1:\n",
    "            sent_1 = sent[:position+1]\n",
    "            sent_2 = sent[position+1:]\n",
    "            new_mix.append(sent_1)\n",
    "            new_mix.append(sent_2)\n",
    "        else:\n",
    "            new_mix.append(sent)\n",
    "\n",
    "    mix_sent = new_mix\n",
    "\n",
    "    port = []\n",
    "    engl = []\n",
    "\n",
    "    for sent in mix_sent:\n",
    "        try:\n",
    "            if detect (sent) == 'pt':\n",
    "                port.append(sent)\n",
    "            else:\n",
    "                engl.append (sent)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    port = \" \".join(port)\n",
    "    engl = \" \".join(engl)\n",
    "\n",
    "    return(port, engl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até esse momento estamos recuperando as informações de todas as teses de uma determinada instituição. No entanto o objetivo é gravar os metadados e salvar o arquivo apenas das teses relacionadas a O&G. Portanto, vamos carregar os algoritmos de classificação e de vetorização de palavras treinados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 400, 50)           9289150   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 396, 128)          32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 194, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 93, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,814,591\n",
      "Trainable params: 525,441\n",
      "Non-trainable params: 9,289,150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Carregando modelo Word2Vec\n",
    "BDTD_word2vec_50 = Word2Vec.load(\"..\\..\\..\\Embeddings\\BDTD_word2vec_50\")\n",
    "# Carregando modelo keras\n",
    "model_keras = load_model('..\\..\\..\\model_cnn.h5')\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário proveniente do modelo de word embedding para converter palavras em índices\n",
    "word2index = {}\n",
    "for index, word in enumerate(BDTD_word2vec_50.wv.index2word):\n",
    "    word2index[word] = index\n",
    "    \n",
    "# Função para converter texto em sequência de índices\n",
    "def index_pad_text(text, maxlen, word2index):\n",
    "    maxlen = 400\n",
    "    new_text = [] \n",
    "    \n",
    "    for word in word_tokenize(text):\n",
    "        try:\n",
    "            new_text.append(word2index[word])\n",
    "        except:\n",
    "            pass\n",
    "    # Add the padding for each sentence. Here I am padding with 0\n",
    "    if len(new_text) > maxlen:\n",
    "        new_text = new_text[:400]\n",
    "    else:\n",
    "        new_text += [0] * (maxlen - len(new_text))\n",
    "\n",
    "    return np.array(new_text)\n",
    "\n",
    "maxlen = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada link coletado será feita as seguintes tarefas:\n",
    "* verificar se o texto português e inglês estão misturados;\n",
    "* transformar o texto em sequência de índices;\n",
    "* classificar quanto a relevância ao domínio de O&G;\n",
    "* se for relevante, gravar os metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153  teses avaliadas e  1  teses relacionadas a O&G encontradas.\n",
      "556  teses avaliadas e  2  teses relacionadas a O&G encontradas.\n",
      "558  teses avaliadas e  3  teses relacionadas a O&G encontradas.\n",
      "836  teses avaliadas e  4  teses relacionadas a O&G encontradas.\n",
      "849  teses avaliadas e  5  teses relacionadas a O&G encontradas.\n",
      "1050  teses avaliadas e  6  teses relacionadas a O&G encontradas.\n",
      "1398  teses avaliadas e  7  teses relacionadas a O&G encontradas.\n",
      "1465  teses avaliadas e  8  teses relacionadas a O&G encontradas.\n",
      "1612  teses avaliadas e  9  teses relacionadas a O&G encontradas.\n",
      "1627  teses avaliadas e  10  teses relacionadas a O&G encontradas.\n",
      "1712  teses avaliadas e  11  teses relacionadas a O&G encontradas.\n",
      "1908  teses avaliadas e  12  teses relacionadas a O&G encontradas.\n",
      "1989  teses avaliadas e  13  teses relacionadas a O&G encontradas.\n",
      "2033  teses avaliadas e  14  teses relacionadas a O&G encontradas.\n",
      "2047  teses avaliadas e  15  teses relacionadas a O&G encontradas.\n",
      "2060  teses avaliadas e  16  teses relacionadas a O&G encontradas.\n",
      "2142  teses avaliadas e  17  teses relacionadas a O&G encontradas.\n",
      "2168  teses avaliadas e  18  teses relacionadas a O&G encontradas.\n",
      "2201  teses avaliadas e  19  teses relacionadas a O&G encontradas.\n",
      "2224  teses avaliadas e  20  teses relacionadas a O&G encontradas.\n",
      "2308  teses avaliadas e  21  teses relacionadas a O&G encontradas.\n",
      "2459  teses avaliadas e  22  teses relacionadas a O&G encontradas.\n",
      "2462  teses avaliadas e  23  teses relacionadas a O&G encontradas.\n",
      "2558  teses avaliadas e  24  teses relacionadas a O&G encontradas.\n",
      "2581  teses avaliadas e  25  teses relacionadas a O&G encontradas.\n",
      "2639  teses avaliadas e  26  teses relacionadas a O&G encontradas.\n",
      "2677  teses avaliadas e  27  teses relacionadas a O&G encontradas.\n",
      "2937  teses avaliadas e  28  teses relacionadas a O&G encontradas.\n",
      "2944  teses avaliadas e  29  teses relacionadas a O&G encontradas.\n",
      "2951  teses avaliadas e  30  teses relacionadas a O&G encontradas.\n",
      "2982  teses avaliadas e  31  teses relacionadas a O&G encontradas.\n",
      "3029  teses avaliadas e  32  teses relacionadas a O&G encontradas.\n",
      "3052  teses avaliadas e  33  teses relacionadas a O&G encontradas.\n",
      "3122  teses avaliadas e  34  teses relacionadas a O&G encontradas.\n",
      "3129  teses avaliadas e  35  teses relacionadas a O&G encontradas.\n",
      "3205  teses avaliadas e  36  teses relacionadas a O&G encontradas.\n",
      "3232  teses avaliadas e  37  teses relacionadas a O&G encontradas.\n",
      "3293  teses avaliadas e  38  teses relacionadas a O&G encontradas.\n",
      "3426  teses avaliadas e  39  teses relacionadas a O&G encontradas.\n",
      "3446  teses avaliadas e  40  teses relacionadas a O&G encontradas.\n",
      "3586  teses avaliadas e  41  teses relacionadas a O&G encontradas.\n",
      "3611  teses avaliadas e  42  teses relacionadas a O&G encontradas.\n",
      "4093  teses avaliadas e  43  teses relacionadas a O&G encontradas.\n",
      "4126  teses avaliadas e  44  teses relacionadas a O&G encontradas.\n",
      "4135  teses avaliadas e  45  teses relacionadas a O&G encontradas.\n",
      "4145  teses avaliadas e  46  teses relacionadas a O&G encontradas.\n",
      "4281  teses avaliadas e  47  teses relacionadas a O&G encontradas.\n",
      "4575  teses avaliadas e  48  teses relacionadas a O&G encontradas.\n",
      "4605  teses avaliadas e  49  teses relacionadas a O&G encontradas.\n",
      "4607  teses avaliadas e  50  teses relacionadas a O&G encontradas.\n",
      "4614  teses avaliadas e  51  teses relacionadas a O&G encontradas.\n",
      "4785  teses avaliadas e  52  teses relacionadas a O&G encontradas.\n",
      "4910  teses avaliadas e  53  teses relacionadas a O&G encontradas.\n",
      "4930  teses avaliadas e  54  teses relacionadas a O&G encontradas.\n",
      "5104  teses avaliadas e  55  teses relacionadas a O&G encontradas.\n",
      "5109  teses avaliadas e  56  teses relacionadas a O&G encontradas.\n",
      "5197  teses avaliadas e  57  teses relacionadas a O&G encontradas.\n",
      "5540  teses avaliadas e  58  teses relacionadas a O&G encontradas.\n",
      "5707  teses avaliadas e  59  teses relacionadas a O&G encontradas.\n",
      "5797  teses avaliadas e  60  teses relacionadas a O&G encontradas.\n",
      "5901  teses avaliadas e  61  teses relacionadas a O&G encontradas.\n",
      "6180  teses avaliadas e  62  teses relacionadas a O&G encontradas.\n",
      "6189  teses avaliadas e  63  teses relacionadas a O&G encontradas.\n",
      "6190  teses avaliadas e  64  teses relacionadas a O&G encontradas.\n",
      "6217  teses avaliadas e  65  teses relacionadas a O&G encontradas.\n",
      "6266  teses avaliadas e  66  teses relacionadas a O&G encontradas.\n",
      "6374  teses avaliadas e  67  teses relacionadas a O&G encontradas.\n",
      "6383  teses avaliadas e  68  teses relacionadas a O&G encontradas.\n",
      "6420  teses avaliadas e  69  teses relacionadas a O&G encontradas.\n",
      "6448  teses avaliadas e  70  teses relacionadas a O&G encontradas.\n",
      "6499  teses avaliadas e  71  teses relacionadas a O&G encontradas.\n",
      "6672  teses avaliadas e  72  teses relacionadas a O&G encontradas.\n",
      "6709  teses avaliadas e  73  teses relacionadas a O&G encontradas.\n",
      "6762  teses avaliadas e  74  teses relacionadas a O&G encontradas.\n",
      "6794  teses avaliadas e  75  teses relacionadas a O&G encontradas.\n",
      "6806  teses avaliadas e  76  teses relacionadas a O&G encontradas.\n",
      "6863  teses avaliadas e  77  teses relacionadas a O&G encontradas.\n",
      "7019  teses avaliadas e  78  teses relacionadas a O&G encontradas.\n",
      "7096  teses avaliadas e  79  teses relacionadas a O&G encontradas.\n",
      "7140  teses avaliadas e  80  teses relacionadas a O&G encontradas.\n",
      "7361  teses avaliadas e  81  teses relacionadas a O&G encontradas.\n",
      "7391  teses avaliadas e  82  teses relacionadas a O&G encontradas.\n",
      "7407  teses avaliadas e  83  teses relacionadas a O&G encontradas.\n",
      "7415  teses avaliadas e  84  teses relacionadas a O&G encontradas.\n",
      "7449  teses avaliadas e  85  teses relacionadas a O&G encontradas.\n",
      "7649  teses avaliadas e  86  teses relacionadas a O&G encontradas.\n",
      "7654  teses avaliadas e  87  teses relacionadas a O&G encontradas.\n",
      "7745  teses avaliadas e  88  teses relacionadas a O&G encontradas.\n",
      "7857  teses avaliadas e  89  teses relacionadas a O&G encontradas.\n",
      "7874  teses avaliadas e  90  teses relacionadas a O&G encontradas.\n",
      "7980  teses avaliadas e  91  teses relacionadas a O&G encontradas.\n",
      "8045  teses avaliadas e  92  teses relacionadas a O&G encontradas.\n",
      "8278  teses avaliadas e  93  teses relacionadas a O&G encontradas.\n",
      "8309  teses avaliadas e  94  teses relacionadas a O&G encontradas.\n",
      "8495  teses avaliadas e  95  teses relacionadas a O&G encontradas.\n",
      "8619  teses avaliadas e  96  teses relacionadas a O&G encontradas.\n",
      "8872  teses avaliadas e  97  teses relacionadas a O&G encontradas.\n",
      "9165  teses avaliadas e  98  teses relacionadas a O&G encontradas.\n",
      "9169  teses avaliadas e  99  teses relacionadas a O&G encontradas.\n",
      "9271  teses avaliadas e  100  teses relacionadas a O&G encontradas.\n",
      "9294  teses avaliadas e  101  teses relacionadas a O&G encontradas.\n",
      "9297  teses avaliadas e  102  teses relacionadas a O&G encontradas.\n",
      "9366  teses avaliadas e  103  teses relacionadas a O&G encontradas.\n",
      "9457  teses avaliadas e  104  teses relacionadas a O&G encontradas.\n",
      "9602  teses avaliadas e  105  teses relacionadas a O&G encontradas.\n",
      "9603  teses avaliadas e  106  teses relacionadas a O&G encontradas.\n",
      "9638  teses avaliadas e  107  teses relacionadas a O&G encontradas.\n",
      "9648  teses avaliadas e  108  teses relacionadas a O&G encontradas.\n",
      "9702  teses avaliadas e  109  teses relacionadas a O&G encontradas.\n",
      "9709  teses avaliadas e  110  teses relacionadas a O&G encontradas.\n",
      "9773  teses avaliadas e  111  teses relacionadas a O&G encontradas.\n",
      "9992  teses avaliadas e  112  teses relacionadas a O&G encontradas.\n",
      "9996  teses avaliadas e  113  teses relacionadas a O&G encontradas.\n",
      "10165  teses avaliadas e  114  teses relacionadas a O&G encontradas.\n",
      "10211  teses avaliadas e  115  teses relacionadas a O&G encontradas.\n",
      "10212  teses avaliadas e  116  teses relacionadas a O&G encontradas.\n",
      "10300  teses avaliadas e  117  teses relacionadas a O&G encontradas.\n",
      "10335  teses avaliadas e  118  teses relacionadas a O&G encontradas.\n",
      "10344  teses avaliadas e  119  teses relacionadas a O&G encontradas.\n",
      "10534  teses avaliadas e  120  teses relacionadas a O&G encontradas.\n",
      "10598  teses avaliadas e  121  teses relacionadas a O&G encontradas.\n",
      "10630  teses avaliadas e  122  teses relacionadas a O&G encontradas.\n",
      "10741  teses avaliadas e  123  teses relacionadas a O&G encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10751  teses avaliadas e  124  teses relacionadas a O&G encontradas.\n",
      "10854  teses avaliadas e  125  teses relacionadas a O&G encontradas.\n",
      "10896  teses avaliadas e  126  teses relacionadas a O&G encontradas.\n",
      "10985  teses avaliadas e  127  teses relacionadas a O&G encontradas.\n",
      "11020  teses avaliadas e  128  teses relacionadas a O&G encontradas.\n",
      "11175  teses avaliadas e  129  teses relacionadas a O&G encontradas.\n",
      "11183  teses avaliadas e  130  teses relacionadas a O&G encontradas.\n",
      "11217  teses avaliadas e  131  teses relacionadas a O&G encontradas.\n",
      "11237  teses avaliadas e  132  teses relacionadas a O&G encontradas.\n",
      "11295  teses avaliadas e  133  teses relacionadas a O&G encontradas.\n",
      "11307  teses avaliadas e  134  teses relacionadas a O&G encontradas.\n",
      "11540  teses avaliadas e  135  teses relacionadas a O&G encontradas.\n",
      "11548  teses avaliadas e  136  teses relacionadas a O&G encontradas.\n",
      "11552  teses avaliadas e  137  teses relacionadas a O&G encontradas.\n",
      "11639  teses avaliadas e  138  teses relacionadas a O&G encontradas.\n",
      "11761  teses avaliadas e  139  teses relacionadas a O&G encontradas.\n",
      "11778  teses avaliadas e  140  teses relacionadas a O&G encontradas.\n",
      "11888  teses avaliadas e  141  teses relacionadas a O&G encontradas.\n",
      "12014  teses avaliadas e  142  teses relacionadas a O&G encontradas.\n",
      "12108  teses avaliadas e  143  teses relacionadas a O&G encontradas.\n",
      "12140  teses avaliadas e  144  teses relacionadas a O&G encontradas.\n",
      "12217  teses avaliadas e  145  teses relacionadas a O&G encontradas.\n",
      "12298  teses avaliadas e  146  teses relacionadas a O&G encontradas.\n",
      "12309  teses avaliadas e  147  teses relacionadas a O&G encontradas.\n",
      "12337  teses avaliadas e  148  teses relacionadas a O&G encontradas.\n",
      "12376  teses avaliadas e  149  teses relacionadas a O&G encontradas.\n",
      "12407  teses avaliadas e  150  teses relacionadas a O&G encontradas.\n",
      "12410  teses avaliadas e  151  teses relacionadas a O&G encontradas.\n",
      "12411  teses avaliadas e  152  teses relacionadas a O&G encontradas.\n",
      "12483  teses avaliadas e  153  teses relacionadas a O&G encontradas.\n",
      "12514  teses avaliadas e  154  teses relacionadas a O&G encontradas.\n",
      "12520  teses avaliadas e  155  teses relacionadas a O&G encontradas.\n",
      "12541  teses avaliadas e  156  teses relacionadas a O&G encontradas.\n",
      "12546  teses avaliadas e  157  teses relacionadas a O&G encontradas.\n",
      "12633  teses avaliadas e  158  teses relacionadas a O&G encontradas.\n",
      "12656  teses avaliadas e  159  teses relacionadas a O&G encontradas.\n",
      "12770  teses avaliadas e  160  teses relacionadas a O&G encontradas.\n",
      "12789  teses avaliadas e  161  teses relacionadas a O&G encontradas.\n",
      "12940  teses avaliadas e  162  teses relacionadas a O&G encontradas.\n",
      "13005  teses avaliadas e  163  teses relacionadas a O&G encontradas.\n",
      "13075  teses avaliadas e  164  teses relacionadas a O&G encontradas.\n",
      "13421  teses avaliadas e  165  teses relacionadas a O&G encontradas.\n",
      "13476  teses avaliadas e  166  teses relacionadas a O&G encontradas.\n",
      "13649  teses avaliadas e  167  teses relacionadas a O&G encontradas.\n",
      "13947  teses avaliadas e  168  teses relacionadas a O&G encontradas.\n",
      "14180  teses avaliadas e  169  teses relacionadas a O&G encontradas.\n",
      "14207  teses avaliadas e  170  teses relacionadas a O&G encontradas.\n",
      "14680  teses avaliadas e  171  teses relacionadas a O&G encontradas.\n",
      "15044  teses avaliadas e  172  teses relacionadas a O&G encontradas.\n",
      "15049  teses avaliadas e  173  teses relacionadas a O&G encontradas.\n",
      "15055  teses avaliadas e  174  teses relacionadas a O&G encontradas.\n",
      "15279  teses avaliadas e  175  teses relacionadas a O&G encontradas.\n",
      "15280  teses avaliadas e  176  teses relacionadas a O&G encontradas.\n",
      "15364  teses avaliadas e  177  teses relacionadas a O&G encontradas.\n",
      "15441  teses avaliadas e  178  teses relacionadas a O&G encontradas.\n",
      "15549  teses avaliadas e  179  teses relacionadas a O&G encontradas.\n",
      "15589  teses avaliadas e  180  teses relacionadas a O&G encontradas.\n",
      "15675  teses avaliadas e  181  teses relacionadas a O&G encontradas.\n",
      "15717  teses avaliadas e  182  teses relacionadas a O&G encontradas.\n",
      "15847  teses avaliadas e  183  teses relacionadas a O&G encontradas.\n",
      "15909  teses avaliadas e  184  teses relacionadas a O&G encontradas.\n",
      "15917  teses avaliadas e  185  teses relacionadas a O&G encontradas.\n",
      "15925  teses avaliadas e  186  teses relacionadas a O&G encontradas.\n",
      "15931  teses avaliadas e  187  teses relacionadas a O&G encontradas.\n",
      "16026  teses avaliadas e  188  teses relacionadas a O&G encontradas.\n",
      "16027  teses avaliadas e  189  teses relacionadas a O&G encontradas.\n",
      "16113  teses avaliadas e  190  teses relacionadas a O&G encontradas.\n",
      "16177  teses avaliadas e  191  teses relacionadas a O&G encontradas.\n",
      "16197  teses avaliadas e  192  teses relacionadas a O&G encontradas.\n",
      "16315  teses avaliadas e  193  teses relacionadas a O&G encontradas.\n",
      "16325  teses avaliadas e  194  teses relacionadas a O&G encontradas.\n",
      "16359  teses avaliadas e  195  teses relacionadas a O&G encontradas.\n",
      "16365  teses avaliadas e  196  teses relacionadas a O&G encontradas.\n",
      "16368  teses avaliadas e  197  teses relacionadas a O&G encontradas.\n",
      "16392  teses avaliadas e  198  teses relacionadas a O&G encontradas.\n",
      "16539  teses avaliadas e  199  teses relacionadas a O&G encontradas.\n",
      "16623  teses avaliadas e  200  teses relacionadas a O&G encontradas.\n",
      "16865  teses avaliadas e  201  teses relacionadas a O&G encontradas.\n",
      "16870  teses avaliadas e  202  teses relacionadas a O&G encontradas.\n",
      "16903  teses avaliadas e  203  teses relacionadas a O&G encontradas.\n",
      "17020  teses avaliadas e  204  teses relacionadas a O&G encontradas.\n",
      "17037  teses avaliadas e  205  teses relacionadas a O&G encontradas.\n",
      "17223  teses avaliadas e  206  teses relacionadas a O&G encontradas.\n",
      "17249  teses avaliadas e  207  teses relacionadas a O&G encontradas.\n",
      "17412  teses avaliadas e  208  teses relacionadas a O&G encontradas.\n",
      "17603  teses avaliadas e  209  teses relacionadas a O&G encontradas.\n",
      "17753  teses avaliadas e  210  teses relacionadas a O&G encontradas.\n",
      "17805  teses avaliadas e  211  teses relacionadas a O&G encontradas.\n",
      "17870  teses avaliadas e  212  teses relacionadas a O&G encontradas.\n",
      "17881  teses avaliadas e  213  teses relacionadas a O&G encontradas.\n",
      "17921  teses avaliadas e  214  teses relacionadas a O&G encontradas.\n",
      "18053  teses avaliadas e  215  teses relacionadas a O&G encontradas.\n",
      "18125  teses avaliadas e  216  teses relacionadas a O&G encontradas.\n",
      "18234  teses avaliadas e  217  teses relacionadas a O&G encontradas.\n",
      "18423  teses avaliadas e  218  teses relacionadas a O&G encontradas.\n",
      "18451  teses avaliadas e  219  teses relacionadas a O&G encontradas.\n",
      "18600  teses avaliadas e  220  teses relacionadas a O&G encontradas.\n",
      "18615  teses avaliadas e  221  teses relacionadas a O&G encontradas.\n",
      "18631  teses avaliadas e  222  teses relacionadas a O&G encontradas.\n",
      "18646  teses avaliadas e  223  teses relacionadas a O&G encontradas.\n",
      "18650  teses avaliadas e  224  teses relacionadas a O&G encontradas.\n",
      "18687  teses avaliadas e  225  teses relacionadas a O&G encontradas.\n",
      "18725  teses avaliadas e  226  teses relacionadas a O&G encontradas.\n",
      "18801  teses avaliadas e  227  teses relacionadas a O&G encontradas.\n",
      "18819  teses avaliadas e  228  teses relacionadas a O&G encontradas.\n",
      "18867  teses avaliadas e  229  teses relacionadas a O&G encontradas.\n",
      "18937  teses avaliadas e  230  teses relacionadas a O&G encontradas.\n",
      "18941  teses avaliadas e  231  teses relacionadas a O&G encontradas.\n",
      "19074  teses avaliadas e  232  teses relacionadas a O&G encontradas.\n",
      "19075  teses avaliadas e  233  teses relacionadas a O&G encontradas.\n",
      "19077  teses avaliadas e  234  teses relacionadas a O&G encontradas.\n",
      "19149  teses avaliadas e  235  teses relacionadas a O&G encontradas.\n",
      "19265  teses avaliadas e  236  teses relacionadas a O&G encontradas.\n",
      "19424  teses avaliadas e  237  teses relacionadas a O&G encontradas.\n",
      "19425  teses avaliadas e  238  teses relacionadas a O&G encontradas.\n",
      "19547  teses avaliadas e  239  teses relacionadas a O&G encontradas.\n",
      "19558  teses avaliadas e  240  teses relacionadas a O&G encontradas.\n",
      "19693  teses avaliadas e  241  teses relacionadas a O&G encontradas.\n",
      "19720  teses avaliadas e  242  teses relacionadas a O&G encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19783  teses avaliadas e  243  teses relacionadas a O&G encontradas.\n",
      "19803  teses avaliadas e  244  teses relacionadas a O&G encontradas.\n",
      "19976  teses avaliadas e  245  teses relacionadas a O&G encontradas.\n"
     ]
    }
   ],
   "source": [
    "# Dicionário para agrupar os metadados\n",
    "metadados = {}\n",
    "# Contadores te links testados e classificados como O&G\n",
    "n_test = 0\n",
    "n_pet = 0\n",
    "# Testando cada link de links\n",
    "for link in links:\n",
    "    n_test += 1\n",
    "    try:\n",
    "        # Recuperar o metadados de uma tese\n",
    "        metadado = tese_link(link)\n",
    "        # Verificar se existe resumo em inglês, separar texto português/inglês e realocar \n",
    "        # os textos separados nas respectivas colunas\n",
    "        if 'Resumo inglês:' not in metadado:\n",
    "            metadado['Resumo inglês:'] = separacao_port_engl(metadado['Resumo Português:'])[1]\n",
    "        metadado['Resumo Português:'] = separacao_port_engl(metadado['Resumo Português:'])[0]\n",
    "        # Colocando o texto em minúscula\n",
    "        text = metadado['Resumo Português:'].lower()\n",
    "        # Convertendo as palavras em sequencias de acordo com o modelo word2vec\n",
    "        text_seq = index_pad_text(text, maxlen, word2index)\n",
    "        text_seq = text_seq.reshape((1, 400))\n",
    "        # Usando o algoritmo classificador para prever se a tese é relevante\n",
    "        pred = model_keras.predict(text_seq)[0]\n",
    "        #Se a classificação for menor do que 0.2 manter os metadados\n",
    "        if (pred < 0.2 and len(text) > 100):\n",
    "            metadado['Classificador'] = pred[0]\n",
    "            texto_completo = metadado['Download Texto Completo:']\n",
    "            metadados[texto_completo] = metadado\n",
    "            n_pet += 1\n",
    "            # Gravando os resultados em JSON\n",
    "            metadados_ufrgs = pd.DataFrame.from_dict(metadados, orient='index')\n",
    "            metadados_ufrgs.to_json('metadados_ufrgs_1.json', orient = 'index')\n",
    "            print(n_test, \" teses avaliadas e \", n_pet, \" teses relacionadas a O&G encontradas.\")\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluindo um ID para cada tese\n",
    "universidade = 'UFRGS'\n",
    "metadados_ufrgs['PDF_ID'] = metadados_ufrgs['Download Texto Completo:'].apply(lambda x: universidade + \n",
    "                                                                            '_' + \n",
    "                                                                            re.sub('/', '_', x[-6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadados_ufrgs.to_json('metadados_ufrgs_1.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando arquivos já gravados\n",
    "metadados_ufrgs = pd.read_json('metadados_ufrgs_1.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa será fazer o download das teses classificadas como relevante para o domínio de O&G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UFRGS__10095\n",
      "UFRGS__10190\n",
      "UFRGS__10247\n",
      "UFRGS__10331\n",
      "UFRGS__10701\n",
      "UFRGS__10767\n",
      "UFRGS__10900\n",
      "UFRGS__10920\n",
      "UFRGS__11150\n",
      "UFRGS__11799\n",
      "UFRGS__11964\n",
      "UFRGS__12004\n",
      "UFRGS__12441\n",
      "UFRGS__12720\n",
      "UFRGS__12771\n",
      "UFRGS__13447\n",
      "UFRGS__13458\n",
      "UFRGS__13473\n",
      "UFRGS__13474\n",
      "UFRGS__13476\n",
      "UFRGS__13548\n",
      "UFRGS_3_1363\n",
      "UFRGS__13645\n",
      "UFRGS__13649\n",
      "UFRGS_3_1365\n",
      "UFRGS__13709\n",
      "UFRGS__13728\n",
      "UFRGS__13776\n",
      "UFRGS__14350\n",
      "UFRGS__14351\n",
      "UFRGS_3_1457\n",
      "UFRGS__14859\n",
      "UFRGS_150496\n",
      "UFRGS_150497\n",
      "UFRGS_150754\n",
      "UFRGS_150873\n",
      "UFRGS_150996\n",
      "UFRGS_151511\n",
      "UFRGS_152945\n",
      "UFRGS__15360\n",
      "UFRGS_156415\n",
      "UFRGS_156472\n",
      "UFRGS_156580\n",
      "UFRGS_156608\n",
      "UFRGS_157838\n",
      "UFRGS_157860\n",
      "UFRGS_158151\n",
      "UFRGS_158170\n",
      "UFRGS_158268\n",
      "UFRGS_158443\n",
      "UFRGS_159051\n",
      "UFRGS_159068\n",
      "UFRGS_159454\n",
      "UFRGS__16199\n",
      "UFRGS_163728\n",
      "UFRGS_163746\n",
      "UFRGS_163767\n",
      "UFRGS_163890\n",
      "UFRGS_164624\n",
      "UFRGS_165153\n",
      "UFRGS_168603\n",
      "UFRGS_168884\n",
      "UFRGS_169754\n",
      "UFRGS_169775\n",
      "UFRGS_170018\n",
      "UFRGS_170575\n",
      "UFRGS_170928\n",
      "UFRGS_170948\n",
      "UFRGS_170959\n",
      "UFRGS_171359\n",
      "UFRGS_171381\n",
      "UFRGS_171707\n",
      "UFRGS_172023\n",
      "UFRGS_172054\n",
      "UFRGS_172185\n",
      "UFRGS_172287\n",
      "UFRGS_173308\n",
      "UFRGS_173563\n",
      "UFRGS_174418\n",
      "UFRGS_174993\n",
      "UFRGS_178179\n",
      "UFRGS_178258\n",
      "UFRGS_178317\n",
      "UFRGS_178338\n",
      "UFRGS_178411\n",
      "UFRGS_178794\n",
      "UFRGS_179650\n",
      "UFRGS_179656\n",
      "UFRGS_180088\n",
      "UFRGS_181329\n",
      "UFRGS_182027\n",
      "UFRGS_182368\n",
      "UFRGS_183139\n",
      "UFRGS_183165\n",
      "UFRGS_183273\n",
      "UFRGS_183316\n",
      "UFRGS_184710\n",
      "UFRGS_184878\n",
      "UFRGS_185241\n",
      "UFRGS_186151\n",
      "UFRGS_186162\n",
      "UFRGS_186163\n",
      "UFRGS_187217\n",
      "UFRGS_187221\n",
      "UFRGS_187224\n",
      "UFRGS_187573\n",
      "UFRGS_187954\n",
      "UFRGS_188023\n",
      "UFRGS_188220\n",
      "UFRGS_188270\n",
      "UFRGS_188495\n",
      "UFRGS_189096\n",
      "UFRGS_189672\n",
      "UFRGS_189864\n",
      "UFRGS_189880\n",
      "UFRGS_189934\n",
      "UFRGS_189944\n",
      "UFRGS_190188\n",
      "UFRGS_192794\n",
      "UFRGS_193007\n",
      "UFRGS_193118\n",
      "UFRGS_193162\n",
      "UFRGS_193177\n",
      "UFRGS_193433\n",
      "UFRGS_194370\n",
      "UFRGS_194374\n",
      "UFRGS_194547\n",
      "UFRGS_195693\n",
      "UFRGS_195805\n",
      "UFRGS_195809\n",
      "UFRGS_196045\n",
      "UFRGS_196063\n",
      "UFRGS_196154\n",
      "UFRGS_196159\n",
      "UFRGS_196517\n",
      "UFRGS_197112\n",
      "UFRGS_198850\n",
      "UFRGS_199201\n",
      "UFRGS_3_2164\n",
      "UFRGS_3_2278\n",
      "UFRGS_3_2303\n",
      "UFRGS_3_2392\n",
      "UFRGS_3_2399\n",
      "UFRGS_3_2406\n",
      "UFRGS__24150\n",
      "UFRGS_3_2438\n",
      "UFRGS_3_2486\n",
      "UFRGS_3_2509\n",
      "UFRGS_3_2588\n",
      "UFRGS_3_2605\n",
      "UFRGS_3_2671\n",
      "UFRGS_3_2854\n",
      "UFRGS_3_3012\n",
      "UFRGS_3_3039\n",
      "UFRGS__32432\n",
      "UFRGS__32615\n",
      "UFRGS__32848\n",
      "UFRGS_3_3312\n",
      "UFRGS_3_3339\n",
      "UFRGS_3_3414\n",
      "UFRGS__34149\n",
      "UFRGS_3_3427\n",
      "UFRGS__34685\n",
      "UFRGS_3_3509\n",
      "UFRGS__35400\n",
      "UFRGS__35444\n",
      "UFRGS__35608\n",
      "UFRGS__35623\n",
      "UFRGS__35628\n",
      "UFRGS__35926\n",
      "UFRGS__36062\n",
      "UFRGS__36755\n",
      "UFRGS__37372\n",
      "UFRGS_3_3857\n",
      "UFRGS__38631\n",
      "UFRGS_3_3864\n",
      "UFRGS__38641\n",
      "UFRGS__39109\n",
      "UFRGS__39413\n",
      "UFRGS_3_3977\n",
      "UFRGS_3_3992\n",
      "UFRGS_3_4005\n",
      "UFRGS_3_4064\n",
      "UFRGS_3_4169\n",
      "UFRGS_3_4196\n",
      "UFRGS_3_4497\n",
      "UFRGS_3_4501\n",
      "UFRGS_3_4597\n",
      "UFRGS_3_4649\n",
      "UFRGS_3_4739\n",
      "UFRGS_3_4762\n",
      "UFRGS_3_4846\n",
      "UFRGS_3_4893\n",
      "UFRGS__49302\n",
      "UFRGS__49696\n",
      "UFRGS__49747\n",
      "UFRGS__49941\n",
      "UFRGS_3_5349\n",
      "UFRGS__55434\n",
      "UFRGS_3_5572\n",
      "UFRGS_3_5587\n",
      "UFRGS__55987\n",
      "UFRGS__55988\n",
      "UFRGS__56293\n",
      "UFRGS__56326\n",
      "UFRGS__56334\n",
      "UFRGS__56340\n",
      "UFRGS__56591\n",
      "UFRGS_3_5725\n",
      "UFRGS_3_5773\n",
      "UFRGS_3_5778\n",
      "UFRGS_3_5911\n",
      "UFRGS__60536\n",
      "UFRGS__60628\n",
      "UFRGS__60670\n",
      "UFRGS__61139\n",
      "UFRGS__61373\n",
      "UFRGS__61384\n",
      "UFRGS__61568\n",
      "UFRGS_3_6166\n",
      "UFRGS__61680\n",
      "UFRGS__61685\n",
      "UFRGS__61774\n",
      "UFRGS_3_6199\n",
      "UFRGS_3_6208\n",
      "UFRGS_3_6218\n",
      "UFRGS_3_6416\n",
      "UFRGS_3_6580\n",
      "UFRGS_3_6837\n",
      "UFRGS_3_7026\n",
      "UFRGS_3_7225\n",
      "UFRGS_3_7348\n",
      "UFRGS_3_7378\n",
      "UFRGS_3_7380\n",
      "UFRGS_3_7387\n",
      "UFRGS_3_7707\n",
      "UFRGS_3_7857\n",
      "UFRGS_3_7858\n",
      "UFRGS_3_7983\n",
      "UFRGS_3_7999\n",
      "UFRGS_3_8530\n",
      "UFRGS_3_8704\n",
      "UFRGS_3_8709\n",
      "UFRGS_3_8715\n",
      "UFRGS_3_8958\n"
     ]
    }
   ],
   "source": [
    "for tese in metadados_ufrgs.iterrows():\n",
    "    print(tese[1]['PDF_ID'])\n",
    "    try:\n",
    "        #preparar a url\n",
    "        url = tese[1]['Download Texto Completo:']\n",
    "\n",
    "        #Fazer requisição e parsear o arquivo html\n",
    "        f = requests.get(url, proxies = proxies).text \n",
    "        soup = bs(f, \"html.parser\")\n",
    "\n",
    "        #Coletando link para arquivo das teses\n",
    "        links = []\n",
    "        for doc in soup.find_all('a', href=True):\n",
    "            if doc['href'][:17] == '/bitstream/handle':\n",
    "                links.append(doc['href'])\n",
    "\n",
    "        #Recuperando e gravando arquivo PDF\n",
    "        url = 'https://lume.ufrgs.br' + links[0]\n",
    "        pdf = requests.get(url, proxies = proxies)\n",
    "        filename = tese[1]['PDF_ID'] + '.pdf'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(pdf.content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
