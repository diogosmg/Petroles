{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para buscar resumos das teses elaboradas pelos empregados da Petrobras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from keras.models import load_model\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo configurações globais de proxy para realizar a extração dentro da rede Petrobras\n",
    "chave = 'upe2'\n",
    "pwd = 'fBO61290'\n",
    "proxy_url = 'http://'+chave+':'+pwd+'@inet-sys.gnet.petrobras.com.br:804/'\n",
    "proxies = {\n",
    "  'http' : proxy_url ,\n",
    "  'https' : proxy_url ,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente entraremos no site da BDTD e buscaremos os links de todas as teses de uma determinada intituição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para coletar os links das tese\n",
    "\n",
    "def get_links(page):\n",
    "        \n",
    "    #preparar a url\n",
    "    url = ('http://bdtd.ibict.br/vufind/Search/Results?filter%5B%5D=institution%3A\"UFSC\"&type=AllFields&page=' +\n",
    "           str(page))\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Coletando link para as teses\n",
    "    links = []\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if 'title' in doc.get('class', []):\n",
    "            links.append(doc['href'])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000  links capturados,  100  páginas\n",
      "4000  links capturados,  200  páginas\n",
      "6000  links capturados,  300  páginas\n",
      "8000  links capturados,  400  páginas\n",
      "10000  links capturados,  500  páginas\n",
      "12000  links capturados,  600  páginas\n",
      "14000  links capturados,  700  páginas\n",
      "16000  links capturados,  800  páginas\n",
      "18000  links capturados,  900  páginas\n",
      "19980  links capturados,  999  páginas\n"
     ]
    }
   ],
   "source": [
    "#Coletar o link de todas as teses\n",
    "start_page = 1\n",
    "n_pages = 1000 # Cada página retorna 20 teses\n",
    "\n",
    "links = []\n",
    "\n",
    "for p in range(start_page, n_pages):\n",
    "    link = get_links(p)\n",
    "    if link != []:\n",
    "        links = links + link\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    if p % 100 == 0:\n",
    "        print (p*20, ' links capturados, ', p, ' páginas')\n",
    "        with open('links_ufsc', \"w\") as output:\n",
    "            writer = csv.writer(output, lineterminator='\\n')\n",
    "            for val in links:\n",
    "                writer.writerow([val])\n",
    "                \n",
    "with open('links_ufsc', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in links:\n",
    "        writer.writerow([val]) \n",
    "print (p*20, ' links capturados, ', p, ' páginas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo arquivo gravado anteriormente\n",
    "\n",
    "#links = []\n",
    "#with open('links_ufsc', 'r') as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    for link in reader:\n",
    "#        links.append(link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida vamos recuperar os metadados de cada link coletado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para buscar os metadados das teses no BDTD\n",
    "def tese_link(link):\n",
    "    #definir url\n",
    "    url = 'http://bdtd.ibict.br' + link\n",
    "    \n",
    "    #Requisitar html e fazer o parser\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Dicionário para armazenar as informações da tese\n",
    "    tese = {}  \n",
    "    \n",
    "    #Adicionar título\n",
    "    tese['Title'] = soup.find('h3').get_text()\n",
    "    for doc in soup.find_all('tr'):\n",
    "        #Identificar atributo\n",
    "        try:\n",
    "            atributo = doc.find('th').get_text()\n",
    "        except:\n",
    "            pass\n",
    "        #Verificar se o atributo possui mais de um dado\n",
    "        for row in doc.find_all('td'):\n",
    "            #Adicionar o atributo no dicionário\n",
    "            if row.find('div') == None:\n",
    "                try:\n",
    "                    tese[atributo] = doc.find('td').get_text()\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                element = []\n",
    "                #No dicionário, adicionar todos os dados ao seu respectivo atributo\n",
    "                for e in doc.find_all('div'):\n",
    "                    try:\n",
    "                        sub_e = []\n",
    "                        for sub_element in e.find_all('a'):\n",
    "                            element.append(sub_element.get_text()) \n",
    "                        #element.append(sub_e)\n",
    "                    except:\n",
    "                        pass\n",
    "                tese[atributo] = element\n",
    "    \n",
    "    return(tese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como em alguns casos o resumo português e inglês se misturaram, foi implementado uma função para separar os textos misturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar resumos português e inglês\n",
    "def separacao_port_engl(abstract):\n",
    "\n",
    "    mix_sent = nltk.sent_tokenize(abstract)\n",
    "\n",
    "    new_mix = []\n",
    "    for sent in mix_sent:\n",
    "        position = sent.find('.')\n",
    "        if position != len(sent)-1:\n",
    "            sent_1 = sent[:position+1]\n",
    "            sent_2 = sent[position+1:]\n",
    "            new_mix.append(sent_1)\n",
    "            new_mix.append(sent_2)\n",
    "        else:\n",
    "            new_mix.append(sent)\n",
    "\n",
    "    mix_sent = new_mix\n",
    "\n",
    "    port = []\n",
    "    engl = []\n",
    "\n",
    "    for sent in mix_sent:\n",
    "        try:\n",
    "            if detect (sent) == 'pt':\n",
    "                port.append(sent)\n",
    "            else:\n",
    "                engl.append (sent)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    port = \" \".join(port)\n",
    "    engl = \" \".join(engl)\n",
    "\n",
    "    return(port, engl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até esse momento estamos recuperando as informações de todas as teses de uma determinada instituição. No entanto o objetivo é gravar os metadados e salvar o arquivo apenas das teses relacionadas a O&G. Portanto, vamos carregar os algoritmos de classificação e de vetorização de palavras treinados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 400, 50)           9289150   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 396, 128)          32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 194, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 93, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,814,591\n",
      "Trainable params: 525,441\n",
      "Non-trainable params: 9,289,150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Carregando modelo Word2Vec\n",
    "BDTD_word2vec_50 = Word2Vec.load(\"..\\..\\..\\Embeddings\\BDTD_word2vec_50\")\n",
    "# Carregando modelo keras\n",
    "model_keras = load_model('..\\..\\..\\model_cnn.h5')\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário proveniente do modelo de word embedding para converter palavras em índices\n",
    "word2index = {}\n",
    "for index, word in enumerate(BDTD_word2vec_50.wv.index2word):\n",
    "    word2index[word] = index\n",
    "    \n",
    "# Função para converter texto em sequência de índices\n",
    "def index_pad_text(text, maxlen, word2index):\n",
    "    maxlen = 400\n",
    "    new_text = [] \n",
    "    \n",
    "    for word in word_tokenize(text):\n",
    "        try:\n",
    "            new_text.append(word2index[word])\n",
    "        except:\n",
    "            pass\n",
    "    # Add the padding for each sentence. Here I am padding with 0\n",
    "    if len(new_text) > maxlen:\n",
    "        new_text = new_text[:400]\n",
    "    else:\n",
    "        new_text += [0] * (maxlen - len(new_text))\n",
    "\n",
    "    return np.array(new_text)\n",
    "\n",
    "maxlen = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada link coletado será feita as seguintes tarefas:\n",
    "* verificar se o texto português e inglês estão misturados;\n",
    "* transformar o texto em sequência de índices;\n",
    "* classificar quanto a relevância ao domínio de O&G;\n",
    "* se for relevante, gravar os metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18  teses avaliadas e  1  teses relacionadas a O&G encontradas.\n",
      "72  teses avaliadas e  2  teses relacionadas a O&G encontradas.\n",
      "288  teses avaliadas e  3  teses relacionadas a O&G encontradas.\n",
      "365  teses avaliadas e  4  teses relacionadas a O&G encontradas.\n",
      "388  teses avaliadas e  5  teses relacionadas a O&G encontradas.\n",
      "425  teses avaliadas e  6  teses relacionadas a O&G encontradas.\n",
      "529  teses avaliadas e  7  teses relacionadas a O&G encontradas.\n",
      "531  teses avaliadas e  8  teses relacionadas a O&G encontradas.\n",
      "541  teses avaliadas e  9  teses relacionadas a O&G encontradas.\n",
      "594  teses avaliadas e  10  teses relacionadas a O&G encontradas.\n",
      "637  teses avaliadas e  11  teses relacionadas a O&G encontradas.\n",
      "713  teses avaliadas e  12  teses relacionadas a O&G encontradas.\n",
      "728  teses avaliadas e  13  teses relacionadas a O&G encontradas.\n",
      "839  teses avaliadas e  14  teses relacionadas a O&G encontradas.\n",
      "1031  teses avaliadas e  15  teses relacionadas a O&G encontradas.\n",
      "1054  teses avaliadas e  16  teses relacionadas a O&G encontradas.\n",
      "1070  teses avaliadas e  17  teses relacionadas a O&G encontradas.\n",
      "1205  teses avaliadas e  18  teses relacionadas a O&G encontradas.\n",
      "1233  teses avaliadas e  19  teses relacionadas a O&G encontradas.\n",
      "1247  teses avaliadas e  20  teses relacionadas a O&G encontradas.\n",
      "1255  teses avaliadas e  21  teses relacionadas a O&G encontradas.\n",
      "1351  teses avaliadas e  22  teses relacionadas a O&G encontradas.\n",
      "1404  teses avaliadas e  23  teses relacionadas a O&G encontradas.\n",
      "1565  teses avaliadas e  24  teses relacionadas a O&G encontradas.\n",
      "1590  teses avaliadas e  25  teses relacionadas a O&G encontradas.\n",
      "1746  teses avaliadas e  26  teses relacionadas a O&G encontradas.\n",
      "1817  teses avaliadas e  27  teses relacionadas a O&G encontradas.\n",
      "1832  teses avaliadas e  28  teses relacionadas a O&G encontradas.\n",
      "1863  teses avaliadas e  29  teses relacionadas a O&G encontradas.\n",
      "1903  teses avaliadas e  30  teses relacionadas a O&G encontradas.\n",
      "1928  teses avaliadas e  31  teses relacionadas a O&G encontradas.\n",
      "2058  teses avaliadas e  32  teses relacionadas a O&G encontradas.\n",
      "2209  teses avaliadas e  33  teses relacionadas a O&G encontradas.\n",
      "2240  teses avaliadas e  34  teses relacionadas a O&G encontradas.\n",
      "2319  teses avaliadas e  35  teses relacionadas a O&G encontradas.\n",
      "2385  teses avaliadas e  36  teses relacionadas a O&G encontradas.\n",
      "2505  teses avaliadas e  37  teses relacionadas a O&G encontradas.\n",
      "2509  teses avaliadas e  38  teses relacionadas a O&G encontradas.\n",
      "2515  teses avaliadas e  39  teses relacionadas a O&G encontradas.\n",
      "2597  teses avaliadas e  40  teses relacionadas a O&G encontradas.\n",
      "2612  teses avaliadas e  41  teses relacionadas a O&G encontradas.\n",
      "2640  teses avaliadas e  42  teses relacionadas a O&G encontradas.\n",
      "2923  teses avaliadas e  43  teses relacionadas a O&G encontradas.\n",
      "2951  teses avaliadas e  44  teses relacionadas a O&G encontradas.\n",
      "3297  teses avaliadas e  45  teses relacionadas a O&G encontradas.\n",
      "3608  teses avaliadas e  46  teses relacionadas a O&G encontradas.\n",
      "3656  teses avaliadas e  47  teses relacionadas a O&G encontradas.\n",
      "3860  teses avaliadas e  48  teses relacionadas a O&G encontradas.\n",
      "3908  teses avaliadas e  49  teses relacionadas a O&G encontradas.\n",
      "3918  teses avaliadas e  50  teses relacionadas a O&G encontradas.\n",
      "3975  teses avaliadas e  51  teses relacionadas a O&G encontradas.\n",
      "4079  teses avaliadas e  52  teses relacionadas a O&G encontradas.\n",
      "4155  teses avaliadas e  53  teses relacionadas a O&G encontradas.\n",
      "4312  teses avaliadas e  54  teses relacionadas a O&G encontradas.\n",
      "4490  teses avaliadas e  55  teses relacionadas a O&G encontradas.\n",
      "4501  teses avaliadas e  56  teses relacionadas a O&G encontradas.\n",
      "4512  teses avaliadas e  57  teses relacionadas a O&G encontradas.\n",
      "4538  teses avaliadas e  58  teses relacionadas a O&G encontradas.\n",
      "4829  teses avaliadas e  59  teses relacionadas a O&G encontradas.\n",
      "4882  teses avaliadas e  60  teses relacionadas a O&G encontradas.\n",
      "4886  teses avaliadas e  61  teses relacionadas a O&G encontradas.\n",
      "5046  teses avaliadas e  62  teses relacionadas a O&G encontradas.\n",
      "5088  teses avaliadas e  63  teses relacionadas a O&G encontradas.\n",
      "5338  teses avaliadas e  64  teses relacionadas a O&G encontradas.\n",
      "5435  teses avaliadas e  65  teses relacionadas a O&G encontradas.\n",
      "5612  teses avaliadas e  66  teses relacionadas a O&G encontradas.\n",
      "6200  teses avaliadas e  67  teses relacionadas a O&G encontradas.\n",
      "6283  teses avaliadas e  68  teses relacionadas a O&G encontradas.\n",
      "6300  teses avaliadas e  69  teses relacionadas a O&G encontradas.\n",
      "6356  teses avaliadas e  70  teses relacionadas a O&G encontradas.\n",
      "6383  teses avaliadas e  71  teses relacionadas a O&G encontradas.\n",
      "6412  teses avaliadas e  72  teses relacionadas a O&G encontradas.\n",
      "6438  teses avaliadas e  73  teses relacionadas a O&G encontradas.\n",
      "6478  teses avaliadas e  74  teses relacionadas a O&G encontradas.\n",
      "6645  teses avaliadas e  75  teses relacionadas a O&G encontradas.\n",
      "6840  teses avaliadas e  76  teses relacionadas a O&G encontradas.\n",
      "6867  teses avaliadas e  77  teses relacionadas a O&G encontradas.\n",
      "6870  teses avaliadas e  78  teses relacionadas a O&G encontradas.\n",
      "6913  teses avaliadas e  79  teses relacionadas a O&G encontradas.\n",
      "6929  teses avaliadas e  80  teses relacionadas a O&G encontradas.\n",
      "6984  teses avaliadas e  81  teses relacionadas a O&G encontradas.\n",
      "7005  teses avaliadas e  82  teses relacionadas a O&G encontradas.\n",
      "7085  teses avaliadas e  83  teses relacionadas a O&G encontradas.\n",
      "7153  teses avaliadas e  84  teses relacionadas a O&G encontradas.\n",
      "7259  teses avaliadas e  85  teses relacionadas a O&G encontradas.\n",
      "7273  teses avaliadas e  86  teses relacionadas a O&G encontradas.\n",
      "7684  teses avaliadas e  87  teses relacionadas a O&G encontradas.\n",
      "7995  teses avaliadas e  88  teses relacionadas a O&G encontradas.\n",
      "8022  teses avaliadas e  89  teses relacionadas a O&G encontradas.\n",
      "8097  teses avaliadas e  90  teses relacionadas a O&G encontradas.\n",
      "8162  teses avaliadas e  91  teses relacionadas a O&G encontradas.\n",
      "8250  teses avaliadas e  92  teses relacionadas a O&G encontradas.\n",
      "8390  teses avaliadas e  93  teses relacionadas a O&G encontradas.\n",
      "8432  teses avaliadas e  94  teses relacionadas a O&G encontradas.\n",
      "8433  teses avaliadas e  95  teses relacionadas a O&G encontradas.\n",
      "8435  teses avaliadas e  96  teses relacionadas a O&G encontradas.\n",
      "8493  teses avaliadas e  97  teses relacionadas a O&G encontradas.\n",
      "8643  teses avaliadas e  98  teses relacionadas a O&G encontradas.\n",
      "8649  teses avaliadas e  99  teses relacionadas a O&G encontradas.\n",
      "8853  teses avaliadas e  100  teses relacionadas a O&G encontradas.\n",
      "8912  teses avaliadas e  101  teses relacionadas a O&G encontradas.\n",
      "8948  teses avaliadas e  102  teses relacionadas a O&G encontradas.\n",
      "8968  teses avaliadas e  103  teses relacionadas a O&G encontradas.\n",
      "9226  teses avaliadas e  104  teses relacionadas a O&G encontradas.\n",
      "9323  teses avaliadas e  105  teses relacionadas a O&G encontradas.\n",
      "9349  teses avaliadas e  106  teses relacionadas a O&G encontradas.\n",
      "9420  teses avaliadas e  107  teses relacionadas a O&G encontradas.\n",
      "9424  teses avaliadas e  108  teses relacionadas a O&G encontradas.\n",
      "9439  teses avaliadas e  109  teses relacionadas a O&G encontradas.\n",
      "9528  teses avaliadas e  110  teses relacionadas a O&G encontradas.\n",
      "9592  teses avaliadas e  111  teses relacionadas a O&G encontradas.\n",
      "9615  teses avaliadas e  112  teses relacionadas a O&G encontradas.\n",
      "9651  teses avaliadas e  113  teses relacionadas a O&G encontradas.\n",
      "9686  teses avaliadas e  114  teses relacionadas a O&G encontradas.\n",
      "9688  teses avaliadas e  115  teses relacionadas a O&G encontradas.\n",
      "9864  teses avaliadas e  116  teses relacionadas a O&G encontradas.\n",
      "9917  teses avaliadas e  117  teses relacionadas a O&G encontradas.\n",
      "9953  teses avaliadas e  118  teses relacionadas a O&G encontradas.\n",
      "10019  teses avaliadas e  119  teses relacionadas a O&G encontradas.\n",
      "10147  teses avaliadas e  120  teses relacionadas a O&G encontradas.\n",
      "10199  teses avaliadas e  121  teses relacionadas a O&G encontradas.\n",
      "10426  teses avaliadas e  122  teses relacionadas a O&G encontradas.\n",
      "10439  teses avaliadas e  123  teses relacionadas a O&G encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10544  teses avaliadas e  124  teses relacionadas a O&G encontradas.\n",
      "10707  teses avaliadas e  125  teses relacionadas a O&G encontradas.\n",
      "10733  teses avaliadas e  126  teses relacionadas a O&G encontradas.\n",
      "10760  teses avaliadas e  127  teses relacionadas a O&G encontradas.\n",
      "11070  teses avaliadas e  128  teses relacionadas a O&G encontradas.\n",
      "11286  teses avaliadas e  129  teses relacionadas a O&G encontradas.\n",
      "11412  teses avaliadas e  130  teses relacionadas a O&G encontradas.\n",
      "11447  teses avaliadas e  131  teses relacionadas a O&G encontradas.\n",
      "11499  teses avaliadas e  132  teses relacionadas a O&G encontradas.\n",
      "11569  teses avaliadas e  133  teses relacionadas a O&G encontradas.\n",
      "11673  teses avaliadas e  134  teses relacionadas a O&G encontradas.\n",
      "11901  teses avaliadas e  135  teses relacionadas a O&G encontradas.\n",
      "12004  teses avaliadas e  136  teses relacionadas a O&G encontradas.\n",
      "12085  teses avaliadas e  137  teses relacionadas a O&G encontradas.\n",
      "12222  teses avaliadas e  138  teses relacionadas a O&G encontradas.\n",
      "12427  teses avaliadas e  139  teses relacionadas a O&G encontradas.\n",
      "12550  teses avaliadas e  140  teses relacionadas a O&G encontradas.\n",
      "12636  teses avaliadas e  141  teses relacionadas a O&G encontradas.\n",
      "12753  teses avaliadas e  142  teses relacionadas a O&G encontradas.\n",
      "12849  teses avaliadas e  143  teses relacionadas a O&G encontradas.\n",
      "12862  teses avaliadas e  144  teses relacionadas a O&G encontradas.\n",
      "12864  teses avaliadas e  145  teses relacionadas a O&G encontradas.\n",
      "13006  teses avaliadas e  146  teses relacionadas a O&G encontradas.\n",
      "13042  teses avaliadas e  147  teses relacionadas a O&G encontradas.\n",
      "13211  teses avaliadas e  148  teses relacionadas a O&G encontradas.\n",
      "13386  teses avaliadas e  149  teses relacionadas a O&G encontradas.\n",
      "13419  teses avaliadas e  150  teses relacionadas a O&G encontradas.\n",
      "13557  teses avaliadas e  151  teses relacionadas a O&G encontradas.\n",
      "13588  teses avaliadas e  152  teses relacionadas a O&G encontradas.\n",
      "13589  teses avaliadas e  153  teses relacionadas a O&G encontradas.\n",
      "13645  teses avaliadas e  154  teses relacionadas a O&G encontradas.\n",
      "13695  teses avaliadas e  155  teses relacionadas a O&G encontradas.\n",
      "13772  teses avaliadas e  156  teses relacionadas a O&G encontradas.\n",
      "13847  teses avaliadas e  157  teses relacionadas a O&G encontradas.\n",
      "13986  teses avaliadas e  158  teses relacionadas a O&G encontradas.\n",
      "14177  teses avaliadas e  159  teses relacionadas a O&G encontradas.\n",
      "14203  teses avaliadas e  160  teses relacionadas a O&G encontradas.\n",
      "14449  teses avaliadas e  161  teses relacionadas a O&G encontradas.\n",
      "14474  teses avaliadas e  162  teses relacionadas a O&G encontradas.\n",
      "14557  teses avaliadas e  163  teses relacionadas a O&G encontradas.\n",
      "14609  teses avaliadas e  164  teses relacionadas a O&G encontradas.\n",
      "14614  teses avaliadas e  165  teses relacionadas a O&G encontradas.\n",
      "14680  teses avaliadas e  166  teses relacionadas a O&G encontradas.\n",
      "14795  teses avaliadas e  167  teses relacionadas a O&G encontradas.\n",
      "14832  teses avaliadas e  168  teses relacionadas a O&G encontradas.\n",
      "14946  teses avaliadas e  169  teses relacionadas a O&G encontradas.\n",
      "14983  teses avaliadas e  170  teses relacionadas a O&G encontradas.\n",
      "15007  teses avaliadas e  171  teses relacionadas a O&G encontradas.\n",
      "15307  teses avaliadas e  172  teses relacionadas a O&G encontradas.\n",
      "15346  teses avaliadas e  173  teses relacionadas a O&G encontradas.\n",
      "15416  teses avaliadas e  174  teses relacionadas a O&G encontradas.\n",
      "15443  teses avaliadas e  175  teses relacionadas a O&G encontradas.\n",
      "15584  teses avaliadas e  176  teses relacionadas a O&G encontradas.\n",
      "15693  teses avaliadas e  177  teses relacionadas a O&G encontradas.\n",
      "15729  teses avaliadas e  178  teses relacionadas a O&G encontradas.\n",
      "15748  teses avaliadas e  179  teses relacionadas a O&G encontradas.\n",
      "15793  teses avaliadas e  180  teses relacionadas a O&G encontradas.\n",
      "15935  teses avaliadas e  181  teses relacionadas a O&G encontradas.\n",
      "15948  teses avaliadas e  182  teses relacionadas a O&G encontradas.\n",
      "15964  teses avaliadas e  183  teses relacionadas a O&G encontradas.\n",
      "16187  teses avaliadas e  184  teses relacionadas a O&G encontradas.\n",
      "16277  teses avaliadas e  185  teses relacionadas a O&G encontradas.\n",
      "16283  teses avaliadas e  186  teses relacionadas a O&G encontradas.\n",
      "16388  teses avaliadas e  187  teses relacionadas a O&G encontradas.\n",
      "16468  teses avaliadas e  188  teses relacionadas a O&G encontradas.\n",
      "16517  teses avaliadas e  189  teses relacionadas a O&G encontradas.\n",
      "16519  teses avaliadas e  190  teses relacionadas a O&G encontradas.\n",
      "16564  teses avaliadas e  191  teses relacionadas a O&G encontradas.\n",
      "16667  teses avaliadas e  192  teses relacionadas a O&G encontradas.\n",
      "16695  teses avaliadas e  193  teses relacionadas a O&G encontradas.\n",
      "16793  teses avaliadas e  194  teses relacionadas a O&G encontradas.\n",
      "16795  teses avaliadas e  195  teses relacionadas a O&G encontradas.\n",
      "16886  teses avaliadas e  196  teses relacionadas a O&G encontradas.\n",
      "17028  teses avaliadas e  197  teses relacionadas a O&G encontradas.\n",
      "17179  teses avaliadas e  198  teses relacionadas a O&G encontradas.\n",
      "17250  teses avaliadas e  199  teses relacionadas a O&G encontradas.\n",
      "17325  teses avaliadas e  200  teses relacionadas a O&G encontradas.\n",
      "17448  teses avaliadas e  201  teses relacionadas a O&G encontradas.\n",
      "17468  teses avaliadas e  202  teses relacionadas a O&G encontradas.\n",
      "17486  teses avaliadas e  203  teses relacionadas a O&G encontradas.\n",
      "17580  teses avaliadas e  204  teses relacionadas a O&G encontradas.\n",
      "17624  teses avaliadas e  205  teses relacionadas a O&G encontradas.\n",
      "17845  teses avaliadas e  206  teses relacionadas a O&G encontradas.\n",
      "17877  teses avaliadas e  207  teses relacionadas a O&G encontradas.\n",
      "17923  teses avaliadas e  208  teses relacionadas a O&G encontradas.\n",
      "17931  teses avaliadas e  209  teses relacionadas a O&G encontradas.\n",
      "17938  teses avaliadas e  210  teses relacionadas a O&G encontradas.\n",
      "17979  teses avaliadas e  211  teses relacionadas a O&G encontradas.\n",
      "18027  teses avaliadas e  212  teses relacionadas a O&G encontradas.\n",
      "18064  teses avaliadas e  213  teses relacionadas a O&G encontradas.\n",
      "18282  teses avaliadas e  214  teses relacionadas a O&G encontradas.\n",
      "18375  teses avaliadas e  215  teses relacionadas a O&G encontradas.\n",
      "18420  teses avaliadas e  216  teses relacionadas a O&G encontradas.\n",
      "18491  teses avaliadas e  217  teses relacionadas a O&G encontradas.\n",
      "18493  teses avaliadas e  218  teses relacionadas a O&G encontradas.\n",
      "18555  teses avaliadas e  219  teses relacionadas a O&G encontradas.\n",
      "18563  teses avaliadas e  220  teses relacionadas a O&G encontradas.\n",
      "18587  teses avaliadas e  221  teses relacionadas a O&G encontradas.\n",
      "18652  teses avaliadas e  222  teses relacionadas a O&G encontradas.\n",
      "18686  teses avaliadas e  223  teses relacionadas a O&G encontradas.\n",
      "18740  teses avaliadas e  224  teses relacionadas a O&G encontradas.\n",
      "18795  teses avaliadas e  225  teses relacionadas a O&G encontradas.\n",
      "18817  teses avaliadas e  226  teses relacionadas a O&G encontradas.\n",
      "18847  teses avaliadas e  227  teses relacionadas a O&G encontradas.\n",
      "18867  teses avaliadas e  228  teses relacionadas a O&G encontradas.\n",
      "18973  teses avaliadas e  229  teses relacionadas a O&G encontradas.\n",
      "19047  teses avaliadas e  230  teses relacionadas a O&G encontradas.\n",
      "19070  teses avaliadas e  231  teses relacionadas a O&G encontradas.\n",
      "19201  teses avaliadas e  232  teses relacionadas a O&G encontradas.\n",
      "19207  teses avaliadas e  233  teses relacionadas a O&G encontradas.\n",
      "19304  teses avaliadas e  234  teses relacionadas a O&G encontradas.\n",
      "19309  teses avaliadas e  235  teses relacionadas a O&G encontradas.\n",
      "19375  teses avaliadas e  236  teses relacionadas a O&G encontradas.\n",
      "19422  teses avaliadas e  237  teses relacionadas a O&G encontradas.\n",
      "19429  teses avaliadas e  238  teses relacionadas a O&G encontradas.\n",
      "19452  teses avaliadas e  239  teses relacionadas a O&G encontradas.\n",
      "19534  teses avaliadas e  240  teses relacionadas a O&G encontradas.\n",
      "19537  teses avaliadas e  241  teses relacionadas a O&G encontradas.\n",
      "19551  teses avaliadas e  242  teses relacionadas a O&G encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19727  teses avaliadas e  243  teses relacionadas a O&G encontradas.\n",
      "19812  teses avaliadas e  244  teses relacionadas a O&G encontradas.\n",
      "19815  teses avaliadas e  245  teses relacionadas a O&G encontradas.\n",
      "19823  teses avaliadas e  246  teses relacionadas a O&G encontradas.\n",
      "19840  teses avaliadas e  247  teses relacionadas a O&G encontradas.\n",
      "19899  teses avaliadas e  248  teses relacionadas a O&G encontradas.\n"
     ]
    }
   ],
   "source": [
    "# Dicionário para agrupar os metadados\n",
    "metadados = {}\n",
    "# Contadores te links testados e classificados como O&G\n",
    "n_test = 0\n",
    "n_pet = 0\n",
    "# Testando cada link de links\n",
    "for link in links:\n",
    "    n_test += 1\n",
    "    try:\n",
    "        # Recuperar o metadados de uma tese\n",
    "        metadado = tese_link(link)\n",
    "        # Verificar se existe resumo em inglês, separar texto português/inglês e realocar \n",
    "        # os textos separados nas respectivas colunas\n",
    "        if 'Resumo inglês:' not in metadado:\n",
    "            metadado['Resumo inglês:'] = separacao_port_engl(metadado['Resumo Português:'])[1]\n",
    "        metadado['Resumo Português:'] = separacao_port_engl(metadado['Resumo Português:'])[0]\n",
    "        # Colocando o texto em minúscula\n",
    "        text = metadado['Resumo Português:'].lower()\n",
    "        # Convertendo as palavras em sequencias de acordo com o modelo word2vec\n",
    "        text_seq = index_pad_text(text, maxlen, word2index)\n",
    "        text_seq = text_seq.reshape((1, 400))\n",
    "        # Usando o algoritmo classificador para prever se a tese é relevante\n",
    "        pred = model_keras.predict(text_seq)[0]\n",
    "        #Se a classificação for menor do que 0.2 manter os metadados\n",
    "        if (pred < 0.2 and len(text) > 100):\n",
    "            metadado['Classificador'] = pred[0]\n",
    "            texto_completo = metadado['Download Texto Completo:']\n",
    "            metadados[texto_completo] = metadado\n",
    "            n_pet += 1\n",
    "            # Gravando os resultados em JSON\n",
    "            metadados_ufsc = pd.DataFrame.from_dict(metadados, orient='index')\n",
    "            metadados_ufsc.to_json('metadados_ufsc_1.json', orient = 'index')\n",
    "            print(n_test, \" teses avaliadas e \", n_pet, \" teses relacionadas a O&G encontradas.\")\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluindo um ID para cada tese\n",
    "universidade = 'UFSC'\n",
    "metadados_ufsc['PDF_ID'] = metadados_ufsc['Download Texto Completo:'].apply(lambda x: universidade + \n",
    "                                                                            '_' + \n",
    "                                                                            re.sub('/', '_', x[-6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadados_ufsc.to_json('metadados_ufsc_1.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando arquivos já gravados\n",
    "metadados_ufsc = pd.read_json('metadados_ufsc_1.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa será fazer o download das teses classificadas como relevante para o domínio de O&G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UFSC_100372\n",
      "UFSC_100447\n",
      "UFSC_100450\n",
      "UFSC_100554\n",
      "UFSC_100593\n",
      "UFSC_100657\n",
      "UFSC_100701\n",
      "UFSC_100924\n",
      "UFSC_100944\n",
      "UFSC_100997\n",
      "UFSC__75530\n",
      "UFSC__76071\n",
      "UFSC__76283\n",
      "UFSC__77644\n",
      "UFSC__78583\n",
      "UFSC__78912\n",
      "UFSC__79018\n",
      "UFSC__79119\n",
      "UFSC__79176\n",
      "UFSC__79179\n",
      "UFSC__79215\n",
      "UFSC__79280\n",
      "UFSC__79349\n",
      "UFSC__79388\n",
      "UFSC__79581\n",
      "UFSC__79624\n",
      "UFSC__79818\n",
      "UFSC__80044\n",
      "UFSC__80062\n",
      "UFSC__80552\n",
      "UFSC__80857\n",
      "UFSC__81034\n",
      "UFSC__81270\n",
      "UFSC__81354\n",
      "UFSC__81586\n",
      "UFSC__81620\n",
      "UFSC__81794\n",
      "UFSC__82019\n",
      "UFSC__82625\n",
      "UFSC__82648\n",
      "UFSC__82685\n",
      "UFSC__82738\n",
      "UFSC__82759\n",
      "UFSC__82890\n",
      "UFSC__83153\n",
      "UFSC__83293\n",
      "UFSC__83401\n",
      "UFSC__83543\n",
      "UFSC__83780\n",
      "UFSC__83897\n",
      "UFSC__83947\n",
      "UFSC__83948\n",
      "UFSC__84066\n",
      "UFSC__84089\n",
      "UFSC__84403\n",
      "UFSC__84558\n",
      "UFSC__84610\n",
      "UFSC__84918\n",
      "UFSC__85051\n",
      "UFSC__85083\n",
      "UFSC__85166\n",
      "UFSC__85329\n",
      "UFSC__85401\n",
      "UFSC__85596\n",
      "UFSC__85893\n",
      "UFSC__85895\n",
      "UFSC__85911\n",
      "UFSC__86107\n",
      "UFSC__86198\n",
      "UFSC__86575\n",
      "UFSC__86609\n",
      "UFSC__86801\n",
      "UFSC__86858\n",
      "UFSC__87113\n",
      "UFSC__87208\n",
      "UFSC__87335\n",
      "UFSC__87423\n",
      "UFSC__87541\n",
      "UFSC__87543\n",
      "UFSC__87861\n",
      "UFSC__87947\n",
      "UFSC__88023\n",
      "UFSC__88159\n",
      "UFSC__88736\n",
      "UFSC__88774\n",
      "UFSC__88973\n",
      "UFSC__89020\n",
      "UFSC__89137\n",
      "UFSC__89231\n",
      "UFSC__89253\n",
      "UFSC__89286\n",
      "UFSC__89453\n",
      "UFSC__89520\n",
      "UFSC__89529\n",
      "UFSC__89548\n",
      "UFSC__89606\n",
      "UFSC__89867\n",
      "UFSC__89900\n",
      "UFSC__89952\n",
      "UFSC__90010\n",
      "UFSC__90108\n",
      "UFSC__90127\n",
      "UFSC__90211\n",
      "UFSC__90393\n",
      "UFSC__90442\n",
      "UFSC__90468\n",
      "UFSC__90492\n",
      "UFSC__90621\n",
      "UFSC__90767\n",
      "UFSC__90789\n",
      "UFSC__90790\n",
      "UFSC__90810\n",
      "UFSC__90815\n",
      "UFSC__90823\n",
      "UFSC__90828\n",
      "UFSC__91318\n",
      "UFSC__91329\n",
      "UFSC__91419\n",
      "UFSC__91491\n",
      "UFSC__91535\n",
      "UFSC__91589\n",
      "UFSC__91617\n",
      "UFSC__91622\n",
      "UFSC__91796\n",
      "UFSC__92000\n",
      "UFSC__92009\n",
      "UFSC__92138\n",
      "UFSC__92225\n",
      "UFSC__92390\n",
      "UFSC__92450\n",
      "UFSC__92487\n",
      "UFSC__92496\n",
      "UFSC__92751\n",
      "UFSC__92785\n",
      "UFSC__93159\n",
      "UFSC__93173\n",
      "UFSC__93236\n",
      "UFSC__93383\n",
      "UFSC__93471\n",
      "UFSC__93678\n",
      "UFSC__93694\n",
      "UFSC__93697\n",
      "UFSC__93698\n",
      "UFSC__93792\n",
      "UFSC__94180\n",
      "UFSC__94194\n",
      "UFSC__94202\n",
      "UFSC__94694\n",
      "UFSC__94700\n",
      "UFSC__94750\n",
      "UFSC__94949\n",
      "UFSC__94979\n",
      "UFSC__95213\n",
      "UFSC__95283\n",
      "UFSC__95414\n",
      "UFSC__95516\n",
      "UFSC__95585\n",
      "UFSC__95636\n",
      "UFSC__95656\n",
      "UFSC__95909\n",
      "UFSC__96274\n",
      "UFSC__96339\n",
      "UFSC__96454\n",
      "UFSC__99364\n",
      "UFSC__99486\n",
      "UFSC_189146\n",
      "UFSC_122552\n",
      "UFSC_122567\n",
      "UFSC_122615\n",
      "UFSC_122637\n",
      "UFSC_122658\n",
      "UFSC_122661\n",
      "UFSC_122667\n",
      "UFSC_122905\n",
      "UFSC_122921\n",
      "UFSC_122928\n",
      "UFSC_122957\n",
      "UFSC_122997\n",
      "UFSC_123014\n",
      "UFSC_123088\n",
      "UFSC_123267\n",
      "UFSC_128690\n",
      "UFSC_128744\n",
      "UFSC_128769\n",
      "UFSC_129211\n",
      "UFSC_129212\n",
      "UFSC_129372\n",
      "UFSC_129384\n",
      "UFSC_129399\n",
      "UFSC_129457\n",
      "UFSC_129466\n",
      "UFSC_129591\n",
      "UFSC_129595\n",
      "UFSC_129679\n",
      "UFSC_130886\n",
      "UFSC_130907\n",
      "UFSC_131010\n",
      "UFSC_132421\n",
      "UFSC_132445\n",
      "UFSC_132449\n",
      "UFSC_132601\n",
      "UFSC_132945\n",
      "UFSC_133218\n",
      "UFSC_134664\n",
      "UFSC_134769\n",
      "UFSC_134912\n",
      "UFSC_135274\n",
      "UFSC_135491\n",
      "UFSC_135976\n",
      "UFSC_136465\n",
      "UFSC_156533\n",
      "UFSC_157544\n",
      "UFSC_157930\n",
      "UFSC_158097\n",
      "UFSC_158844\n",
      "UFSC_159022\n",
      "UFSC_159400\n",
      "UFSC_159433\n",
      "UFSC_159630\n",
      "UFSC_159870\n",
      "UFSC_160575\n",
      "UFSC_160633\n",
      "UFSC_167914\n",
      "UFSC_169290\n",
      "UFSC_169382\n",
      "UFSC_169431\n",
      "UFSC_169480\n",
      "UFSC_169483\n",
      "UFSC_172363\n",
      "UFSC_172803\n",
      "UFSC_173041\n",
      "UFSC_174027\n",
      "UFSC_174301\n",
      "UFSC_174422\n",
      "UFSC_174435\n",
      "UFSC_175076\n",
      "UFSC_175312\n",
      "UFSC_176015\n",
      "UFSC_176665\n",
      "UFSC_176912\n",
      "UFSC_176914\n",
      "UFSC_177884\n",
      "UFSC_178987\n",
      "UFSC_179667\n",
      "UFSC_180412\n",
      "UFSC_182070\n",
      "UFSC_182608\n",
      "UFSC_182610\n"
     ]
    }
   ],
   "source": [
    "for tese in metadados_ufsc.iterrows():\n",
    "    print(tese[1]['PDF_ID'])\n",
    "    try:\n",
    "        #preparar a url\n",
    "        url = tese[1]['Download Texto Completo:']\n",
    "\n",
    "        #Fazer requisição e parsear o arquivo html\n",
    "        f = requests.get(url, proxies = proxies).text \n",
    "        soup = bs(f, \"html.parser\")\n",
    "\n",
    "        #Coletando link para arquivo das teses\n",
    "        links = []\n",
    "        for doc in soup.find_all('a', href=True):\n",
    "            if doc['href'][:23] == '/xmlui/bitstream/handle':\n",
    "                links.append(doc['href'])\n",
    "\n",
    "        #Recuperando e gravando arquivo PDF\n",
    "        url = 'https://repositorio.ufsc.br' + links[0]\n",
    "        pdf = requests.get(url, proxies = proxies)\n",
    "        filename = tese[1]['PDF_ID'] + '.pdf'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(pdf.content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
