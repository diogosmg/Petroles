{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para buscar resumos das teses elaboradas pelos empregados da Petrobras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from keras.models import load_model\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo configurações globais de proxy para realizar a extração dentro da rede Petrobras\n",
    "chave = 'upe2'\n",
    "pwd = 'fBO61290'\n",
    "proxy_url = 'http://'+chave+':'+pwd+'@inet-sys.gnet.petrobras.com.br:804/'\n",
    "proxies = {\n",
    "  'http' : proxy_url ,\n",
    "  'https' : proxy_url ,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente entraremos no site da BDTD e buscaremos os links de todas as teses de uma determinada intituição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para coletar os links das tese\n",
    "\n",
    "def get_links(page):\n",
    "        \n",
    "    #preparar a url\n",
    "    url = ('http://bdtd.ibict.br/vufind/Search/Results?filter%5B%5D=institution%3A\"UNESP\"&type=AllFields&page=' +\n",
    "           str(page))\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Coletando link para as teses\n",
    "    links = []\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if 'title' in doc.get('class', []):\n",
    "            links.append(doc['href'])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000  links capturados,  100  páginas\n",
      "4000  links capturados,  200  páginas\n",
      "6000  links capturados,  300  páginas\n",
      "8000  links capturados,  400  páginas\n",
      "10000  links capturados,  500  páginas\n",
      "12000  links capturados,  600  páginas\n",
      "14000  links capturados,  700  páginas\n",
      "16000  links capturados,  800  páginas\n",
      "18000  links capturados,  900  páginas\n",
      "19980  links capturados,  999  páginas\n"
     ]
    }
   ],
   "source": [
    "#Coletar o link de todas as teses\n",
    "start_page = 1\n",
    "n_pages = 1000 # Cada página retorna 20 teses\n",
    "\n",
    "links = []\n",
    "\n",
    "for p in range(start_page, n_pages):\n",
    "    link = get_links(p)\n",
    "    if link != []:\n",
    "        links = links + link\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    if p % 100 == 0:\n",
    "        print (p*20, ' links capturados, ', p, ' páginas')\n",
    "        with open('links_unesp', \"w\") as output:\n",
    "            writer = csv.writer(output, lineterminator='\\n')\n",
    "            for val in links:\n",
    "                writer.writerow([val])\n",
    "                \n",
    "with open('links_unesp', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in links:\n",
    "        writer.writerow([val]) \n",
    "print (p*20, ' links capturados, ', p, ' páginas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo arquivo gravado anteriormente\n",
    "\n",
    "#links = []\n",
    "#with open('links_unesp', 'r') as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    for link in reader:\n",
    "#        links.append(link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida vamos recuperar os metadados de cada link coletado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para buscar os metadados das teses no BDTD\n",
    "def tese_link(link):\n",
    "    #definir url\n",
    "    url = 'http://bdtd.ibict.br' + link\n",
    "    \n",
    "    #Requisitar html e fazer o parser\n",
    "    f = requests.get(url, proxies = proxies).text \n",
    "    soup = bs(f, \"html.parser\")\n",
    "\n",
    "    #Dicionário para armazenar as informações da tese\n",
    "    tese = {}  \n",
    "    \n",
    "    #Adicionar título\n",
    "    tese['Title'] = soup.find('h3').get_text()\n",
    "    for doc in soup.find_all('tr'):\n",
    "        #Identificar atributo\n",
    "        try:\n",
    "            atributo = doc.find('th').get_text()\n",
    "        except:\n",
    "            pass\n",
    "        #Verificar se o atributo possui mais de um dado\n",
    "        for row in doc.find_all('td'):\n",
    "            #Adicionar o atributo no dicionário\n",
    "            if row.find('div') == None:\n",
    "                try:\n",
    "                    tese[atributo] = doc.find('td').get_text()\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                element = []\n",
    "                #No dicionário, adicionar todos os dados ao seu respectivo atributo\n",
    "                for e in doc.find_all('div'):\n",
    "                    try:\n",
    "                        sub_e = []\n",
    "                        for sub_element in e.find_all('a'):\n",
    "                            element.append(sub_element.get_text()) \n",
    "                        #element.append(sub_e)\n",
    "                    except:\n",
    "                        pass\n",
    "                tese[atributo] = element\n",
    "    \n",
    "    return(tese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como em alguns casos o resumo português e inglês se misturaram, foi implementado uma função para separar os textos misturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar resumos português e inglês\n",
    "def separacao_port_engl(abstract):\n",
    "\n",
    "    mix_sent = nltk.sent_tokenize(abstract)\n",
    "\n",
    "    new_mix = []\n",
    "    for sent in mix_sent:\n",
    "        position = sent.find('.')\n",
    "        if position != len(sent)-1:\n",
    "            sent_1 = sent[:position+1]\n",
    "            sent_2 = sent[position+1:]\n",
    "            new_mix.append(sent_1)\n",
    "            new_mix.append(sent_2)\n",
    "        else:\n",
    "            new_mix.append(sent)\n",
    "\n",
    "    mix_sent = new_mix\n",
    "\n",
    "    port = []\n",
    "    engl = []\n",
    "\n",
    "    for sent in mix_sent:\n",
    "        try:\n",
    "            if detect (sent) == 'pt':\n",
    "                port.append(sent)\n",
    "            else:\n",
    "                engl.append (sent)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    port = \" \".join(port)\n",
    "    engl = \" \".join(engl)\n",
    "\n",
    "    return(port, engl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até esse momento estamos recuperando as informações de todas as teses de uma determinada instituição. No entanto o objetivo é gravar os metadados e salvar o arquivo apenas das teses relacionadas a O&G. Portanto, vamos carregar os algoritmos de classificação e de vetorização de palavras treinados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 400, 50)           9289150   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 396, 128)          32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 198, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 194, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 93, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,814,591\n",
      "Trainable params: 525,441\n",
      "Non-trainable params: 9,289,150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Carregando modelo Word2Vec\n",
    "BDTD_word2vec_50 = Word2Vec.load(\"..\\..\\..\\Embeddings\\BDTD_word2vec_50\")\n",
    "# Carregando modelo keras\n",
    "model_keras = load_model('..\\..\\..\\model_cnn.h5')\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário proveniente do modelo de word embedding para converter palavras em índices\n",
    "word2index = {}\n",
    "for index, word in enumerate(BDTD_word2vec_50.wv.index2word):\n",
    "    word2index[word] = index\n",
    "    \n",
    "# Função para converter texto em sequência de índices\n",
    "def index_pad_text(text, maxlen, word2index):\n",
    "    maxlen = 400\n",
    "    new_text = [] \n",
    "    \n",
    "    for word in word_tokenize(text):\n",
    "        try:\n",
    "            new_text.append(word2index[word])\n",
    "        except:\n",
    "            pass\n",
    "    # Add the padding for each sentence. Here I am padding with 0\n",
    "    if len(new_text) > maxlen:\n",
    "        new_text = new_text[:400]\n",
    "    else:\n",
    "        new_text += [0] * (maxlen - len(new_text))\n",
    "\n",
    "    return np.array(new_text)\n",
    "\n",
    "maxlen = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada link coletado será feita as seguintes tarefas:\n",
    "* verificar se o texto português e inglês estão misturados;\n",
    "* transformar o texto em sequência de índices;\n",
    "* classificar quanto a relevância ao domínio de O&G;\n",
    "* se for relevante, gravar os metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513  teses avaliadas e  1  teses relacionadas a O&G encontradas.\n",
      "582  teses avaliadas e  2  teses relacionadas a O&G encontradas.\n",
      "594  teses avaliadas e  3  teses relacionadas a O&G encontradas.\n",
      "636  teses avaliadas e  4  teses relacionadas a O&G encontradas.\n",
      "879  teses avaliadas e  5  teses relacionadas a O&G encontradas.\n",
      "932  teses avaliadas e  6  teses relacionadas a O&G encontradas.\n",
      "1019  teses avaliadas e  7  teses relacionadas a O&G encontradas.\n",
      "1116  teses avaliadas e  8  teses relacionadas a O&G encontradas.\n",
      "1185  teses avaliadas e  9  teses relacionadas a O&G encontradas.\n",
      "2342  teses avaliadas e  10  teses relacionadas a O&G encontradas.\n",
      "2837  teses avaliadas e  11  teses relacionadas a O&G encontradas.\n",
      "3187  teses avaliadas e  12  teses relacionadas a O&G encontradas.\n",
      "3273  teses avaliadas e  13  teses relacionadas a O&G encontradas.\n",
      "3282  teses avaliadas e  14  teses relacionadas a O&G encontradas.\n",
      "3384  teses avaliadas e  15  teses relacionadas a O&G encontradas.\n",
      "3754  teses avaliadas e  16  teses relacionadas a O&G encontradas.\n",
      "3845  teses avaliadas e  17  teses relacionadas a O&G encontradas.\n",
      "3869  teses avaliadas e  18  teses relacionadas a O&G encontradas.\n",
      "3976  teses avaliadas e  19  teses relacionadas a O&G encontradas.\n",
      "3984  teses avaliadas e  20  teses relacionadas a O&G encontradas.\n",
      "4005  teses avaliadas e  21  teses relacionadas a O&G encontradas.\n",
      "4071  teses avaliadas e  22  teses relacionadas a O&G encontradas.\n",
      "4094  teses avaliadas e  23  teses relacionadas a O&G encontradas.\n",
      "4128  teses avaliadas e  24  teses relacionadas a O&G encontradas.\n",
      "4263  teses avaliadas e  25  teses relacionadas a O&G encontradas.\n",
      "4488  teses avaliadas e  26  teses relacionadas a O&G encontradas.\n",
      "4495  teses avaliadas e  27  teses relacionadas a O&G encontradas.\n",
      "4496  teses avaliadas e  28  teses relacionadas a O&G encontradas.\n",
      "4511  teses avaliadas e  29  teses relacionadas a O&G encontradas.\n",
      "4581  teses avaliadas e  30  teses relacionadas a O&G encontradas.\n",
      "4646  teses avaliadas e  31  teses relacionadas a O&G encontradas.\n",
      "4817  teses avaliadas e  32  teses relacionadas a O&G encontradas.\n",
      "4978  teses avaliadas e  33  teses relacionadas a O&G encontradas.\n",
      "5020  teses avaliadas e  34  teses relacionadas a O&G encontradas.\n",
      "5042  teses avaliadas e  35  teses relacionadas a O&G encontradas.\n",
      "5051  teses avaliadas e  36  teses relacionadas a O&G encontradas.\n",
      "5163  teses avaliadas e  37  teses relacionadas a O&G encontradas.\n",
      "5340  teses avaliadas e  38  teses relacionadas a O&G encontradas.\n",
      "5835  teses avaliadas e  39  teses relacionadas a O&G encontradas.\n",
      "5935  teses avaliadas e  40  teses relacionadas a O&G encontradas.\n",
      "6091  teses avaliadas e  41  teses relacionadas a O&G encontradas.\n",
      "6305  teses avaliadas e  42  teses relacionadas a O&G encontradas.\n",
      "6952  teses avaliadas e  43  teses relacionadas a O&G encontradas.\n",
      "6970  teses avaliadas e  44  teses relacionadas a O&G encontradas.\n",
      "6983  teses avaliadas e  45  teses relacionadas a O&G encontradas.\n",
      "6992  teses avaliadas e  46  teses relacionadas a O&G encontradas.\n",
      "7005  teses avaliadas e  47  teses relacionadas a O&G encontradas.\n",
      "7018  teses avaliadas e  48  teses relacionadas a O&G encontradas.\n",
      "7121  teses avaliadas e  49  teses relacionadas a O&G encontradas.\n",
      "7404  teses avaliadas e  50  teses relacionadas a O&G encontradas.\n",
      "7599  teses avaliadas e  51  teses relacionadas a O&G encontradas.\n",
      "8158  teses avaliadas e  52  teses relacionadas a O&G encontradas.\n",
      "8406  teses avaliadas e  53  teses relacionadas a O&G encontradas.\n",
      "8407  teses avaliadas e  54  teses relacionadas a O&G encontradas.\n",
      "8507  teses avaliadas e  55  teses relacionadas a O&G encontradas.\n",
      "8509  teses avaliadas e  56  teses relacionadas a O&G encontradas.\n",
      "8515  teses avaliadas e  57  teses relacionadas a O&G encontradas.\n",
      "8647  teses avaliadas e  58  teses relacionadas a O&G encontradas.\n",
      "8655  teses avaliadas e  59  teses relacionadas a O&G encontradas.\n",
      "8656  teses avaliadas e  60  teses relacionadas a O&G encontradas.\n",
      "8666  teses avaliadas e  61  teses relacionadas a O&G encontradas.\n",
      "8689  teses avaliadas e  62  teses relacionadas a O&G encontradas.\n",
      "8694  teses avaliadas e  63  teses relacionadas a O&G encontradas.\n",
      "8697  teses avaliadas e  64  teses relacionadas a O&G encontradas.\n",
      "8706  teses avaliadas e  65  teses relacionadas a O&G encontradas.\n",
      "8708  teses avaliadas e  66  teses relacionadas a O&G encontradas.\n",
      "8709  teses avaliadas e  67  teses relacionadas a O&G encontradas.\n",
      "8714  teses avaliadas e  68  teses relacionadas a O&G encontradas.\n",
      "8720  teses avaliadas e  69  teses relacionadas a O&G encontradas.\n",
      "9105  teses avaliadas e  70  teses relacionadas a O&G encontradas.\n",
      "9124  teses avaliadas e  71  teses relacionadas a O&G encontradas.\n",
      "9128  teses avaliadas e  72  teses relacionadas a O&G encontradas.\n",
      "9133  teses avaliadas e  73  teses relacionadas a O&G encontradas.\n",
      "9135  teses avaliadas e  74  teses relacionadas a O&G encontradas.\n",
      "9137  teses avaliadas e  75  teses relacionadas a O&G encontradas.\n",
      "9138  teses avaliadas e  76  teses relacionadas a O&G encontradas.\n",
      "9140  teses avaliadas e  77  teses relacionadas a O&G encontradas.\n",
      "9144  teses avaliadas e  78  teses relacionadas a O&G encontradas.\n",
      "9145  teses avaliadas e  79  teses relacionadas a O&G encontradas.\n",
      "9146  teses avaliadas e  80  teses relacionadas a O&G encontradas.\n",
      "9148  teses avaliadas e  81  teses relacionadas a O&G encontradas.\n",
      "9313  teses avaliadas e  82  teses relacionadas a O&G encontradas.\n",
      "9575  teses avaliadas e  83  teses relacionadas a O&G encontradas.\n",
      "9672  teses avaliadas e  84  teses relacionadas a O&G encontradas.\n",
      "10169  teses avaliadas e  85  teses relacionadas a O&G encontradas.\n",
      "10314  teses avaliadas e  86  teses relacionadas a O&G encontradas.\n",
      "10620  teses avaliadas e  87  teses relacionadas a O&G encontradas.\n",
      "10714  teses avaliadas e  88  teses relacionadas a O&G encontradas.\n",
      "10716  teses avaliadas e  89  teses relacionadas a O&G encontradas.\n",
      "10735  teses avaliadas e  90  teses relacionadas a O&G encontradas.\n",
      "10753  teses avaliadas e  91  teses relacionadas a O&G encontradas.\n",
      "10756  teses avaliadas e  92  teses relacionadas a O&G encontradas.\n",
      "10757  teses avaliadas e  93  teses relacionadas a O&G encontradas.\n",
      "10760  teses avaliadas e  94  teses relacionadas a O&G encontradas.\n",
      "10762  teses avaliadas e  95  teses relacionadas a O&G encontradas.\n",
      "11591  teses avaliadas e  96  teses relacionadas a O&G encontradas.\n",
      "11610  teses avaliadas e  97  teses relacionadas a O&G encontradas.\n",
      "11881  teses avaliadas e  98  teses relacionadas a O&G encontradas.\n",
      "12222  teses avaliadas e  99  teses relacionadas a O&G encontradas.\n",
      "12226  teses avaliadas e  100  teses relacionadas a O&G encontradas.\n",
      "12461  teses avaliadas e  101  teses relacionadas a O&G encontradas.\n",
      "12463  teses avaliadas e  102  teses relacionadas a O&G encontradas.\n",
      "12464  teses avaliadas e  103  teses relacionadas a O&G encontradas.\n",
      "12466  teses avaliadas e  104  teses relacionadas a O&G encontradas.\n",
      "12475  teses avaliadas e  105  teses relacionadas a O&G encontradas.\n",
      "12833  teses avaliadas e  106  teses relacionadas a O&G encontradas.\n",
      "12842  teses avaliadas e  107  teses relacionadas a O&G encontradas.\n",
      "13226  teses avaliadas e  108  teses relacionadas a O&G encontradas.\n",
      "13242  teses avaliadas e  109  teses relacionadas a O&G encontradas.\n",
      "13373  teses avaliadas e  110  teses relacionadas a O&G encontradas.\n",
      "13375  teses avaliadas e  111  teses relacionadas a O&G encontradas.\n",
      "13377  teses avaliadas e  112  teses relacionadas a O&G encontradas.\n",
      "13416  teses avaliadas e  113  teses relacionadas a O&G encontradas.\n",
      "13429  teses avaliadas e  114  teses relacionadas a O&G encontradas.\n",
      "13452  teses avaliadas e  115  teses relacionadas a O&G encontradas.\n",
      "13460  teses avaliadas e  116  teses relacionadas a O&G encontradas.\n",
      "13510  teses avaliadas e  117  teses relacionadas a O&G encontradas.\n",
      "13592  teses avaliadas e  118  teses relacionadas a O&G encontradas.\n",
      "13604  teses avaliadas e  119  teses relacionadas a O&G encontradas.\n",
      "13629  teses avaliadas e  120  teses relacionadas a O&G encontradas.\n",
      "13661  teses avaliadas e  121  teses relacionadas a O&G encontradas.\n",
      "13712  teses avaliadas e  122  teses relacionadas a O&G encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13721  teses avaliadas e  123  teses relacionadas a O&G encontradas.\n",
      "13875  teses avaliadas e  124  teses relacionadas a O&G encontradas.\n",
      "13918  teses avaliadas e  125  teses relacionadas a O&G encontradas.\n",
      "13922  teses avaliadas e  126  teses relacionadas a O&G encontradas.\n",
      "14038  teses avaliadas e  127  teses relacionadas a O&G encontradas.\n",
      "14763  teses avaliadas e  128  teses relacionadas a O&G encontradas.\n",
      "15017  teses avaliadas e  129  teses relacionadas a O&G encontradas.\n",
      "15067  teses avaliadas e  130  teses relacionadas a O&G encontradas.\n",
      "15096  teses avaliadas e  131  teses relacionadas a O&G encontradas.\n",
      "15782  teses avaliadas e  132  teses relacionadas a O&G encontradas.\n",
      "15827  teses avaliadas e  133  teses relacionadas a O&G encontradas.\n",
      "16130  teses avaliadas e  134  teses relacionadas a O&G encontradas.\n",
      "16148  teses avaliadas e  135  teses relacionadas a O&G encontradas.\n",
      "16183  teses avaliadas e  136  teses relacionadas a O&G encontradas.\n",
      "16190  teses avaliadas e  137  teses relacionadas a O&G encontradas.\n",
      "16212  teses avaliadas e  138  teses relacionadas a O&G encontradas.\n",
      "16219  teses avaliadas e  139  teses relacionadas a O&G encontradas.\n",
      "16220  teses avaliadas e  140  teses relacionadas a O&G encontradas.\n",
      "16230  teses avaliadas e  141  teses relacionadas a O&G encontradas.\n",
      "16232  teses avaliadas e  142  teses relacionadas a O&G encontradas.\n",
      "16234  teses avaliadas e  143  teses relacionadas a O&G encontradas.\n",
      "16283  teses avaliadas e  144  teses relacionadas a O&G encontradas.\n",
      "16344  teses avaliadas e  145  teses relacionadas a O&G encontradas.\n",
      "16345  teses avaliadas e  146  teses relacionadas a O&G encontradas.\n",
      "16492  teses avaliadas e  147  teses relacionadas a O&G encontradas.\n",
      "16726  teses avaliadas e  148  teses relacionadas a O&G encontradas.\n",
      "16831  teses avaliadas e  149  teses relacionadas a O&G encontradas.\n",
      "16915  teses avaliadas e  150  teses relacionadas a O&G encontradas.\n",
      "17151  teses avaliadas e  151  teses relacionadas a O&G encontradas.\n",
      "17184  teses avaliadas e  152  teses relacionadas a O&G encontradas.\n",
      "17309  teses avaliadas e  153  teses relacionadas a O&G encontradas.\n",
      "17893  teses avaliadas e  154  teses relacionadas a O&G encontradas.\n",
      "17999  teses avaliadas e  155  teses relacionadas a O&G encontradas.\n",
      "18001  teses avaliadas e  156  teses relacionadas a O&G encontradas.\n",
      "18003  teses avaliadas e  157  teses relacionadas a O&G encontradas.\n",
      "18004  teses avaliadas e  158  teses relacionadas a O&G encontradas.\n",
      "18015  teses avaliadas e  159  teses relacionadas a O&G encontradas.\n",
      "18048  teses avaliadas e  160  teses relacionadas a O&G encontradas.\n",
      "18063  teses avaliadas e  161  teses relacionadas a O&G encontradas.\n",
      "18174  teses avaliadas e  162  teses relacionadas a O&G encontradas.\n",
      "18296  teses avaliadas e  163  teses relacionadas a O&G encontradas.\n",
      "19238  teses avaliadas e  164  teses relacionadas a O&G encontradas.\n",
      "19258  teses avaliadas e  165  teses relacionadas a O&G encontradas.\n",
      "19558  teses avaliadas e  166  teses relacionadas a O&G encontradas.\n"
     ]
    }
   ],
   "source": [
    "# Dicionário para agrupar os metadados\n",
    "metadados = {}\n",
    "# Contadores te links testados e classificados como O&G\n",
    "n_test = 0\n",
    "n_pet = 0\n",
    "# Testando cada link de links\n",
    "for link in links:\n",
    "    n_test += 1\n",
    "    try:\n",
    "        # Recuperar o metadados de uma tese\n",
    "        metadado = tese_link(link)\n",
    "        # Verificar se existe resumo em inglês, separar texto português/inglês e realocar \n",
    "        # os textos separados nas respectivas colunas\n",
    "        if 'Resumo inglês:' not in metadado:\n",
    "            metadado['Resumo inglês:'] = separacao_port_engl(metadado['Resumo Português:'])[1]\n",
    "        metadado['Resumo Português:'] = separacao_port_engl(metadado['Resumo Português:'])[0]\n",
    "        # Colocando o texto em minúscula\n",
    "        text = metadado['Resumo Português:'].lower()\n",
    "        # Convertendo as palavras em sequencias de acordo com o modelo word2vec\n",
    "        text_seq = index_pad_text(text, maxlen, word2index)\n",
    "        text_seq = text_seq.reshape((1, 400))\n",
    "        # Usando o algoritmo classificador para prever se a tese é relevante\n",
    "        pred = model_keras.predict(text_seq)[0]\n",
    "        #Se a classificação for menor do que 0.2 manter os metadados\n",
    "        if (pred < 0.2 and len(text) > 100):\n",
    "            metadado['Classificador'] = pred[0]\n",
    "            texto_completo = metadado['Download Texto Completo:']\n",
    "            metadados[texto_completo] = metadado\n",
    "            n_pet += 1\n",
    "            # Gravando os resultados em JSON\n",
    "            metadados_unesp = pd.DataFrame.from_dict(metadados, orient='index')\n",
    "            metadados_unesp.to_json('metadados_unesp_1.json', orient = 'index')\n",
    "            print(n_test, \" teses avaliadas e \", n_pet, \" teses relacionadas a O&G encontradas.\")\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluindo um ID para cada tese\n",
    "universidade = 'UNESP'\n",
    "metadados_unesp['PDF_ID'] = metadados_unesp['Download Texto Completo:'].apply(lambda x: universidade + \n",
    "                                                                            '_' + \n",
    "                                                                            re.sub('/', '_', x[-6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadados_unesp.to_json('metadados_unesp_1.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando arquivos já gravados\n",
    "metadados_unesp = pd.read_json('metadados_unesp_1.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa será fazer o download das teses classificadas como relevante para o domínio de O&G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNESP_100156\n",
      "UNESP_100301\n",
      "UNESP_100335\n",
      "UNESP_100365\n",
      "UNESP_100458\n",
      "UNESP_100571\n",
      "UNESP_100572\n",
      "UNESP_100722\n",
      "UNESP_100904\n",
      "UNESP_102859\n",
      "UNESP_102861\n"
     ]
    }
   ],
   "source": [
    "for tese in metadados_unesp.iterrows():\n",
    "    print(tese[1]['PDF_ID'])\n",
    "    try:\n",
    "        #preparar a url\n",
    "        url = tese[1]['Download Texto Completo:']\n",
    "\n",
    "        #Fazer requisição e parsear o arquivo html\n",
    "        f = requests.get(url, proxies = proxies).text \n",
    "        soup = bs(f, \"html.parser\")\n",
    "\n",
    "        #Coletando link para arquivo das teses\n",
    "        links = []\n",
    "        for doc in soup.find_all('a', href=True):\n",
    "            if doc['href'][:17] == '/bitstream/handle':\n",
    "                links.append(doc['href'])\n",
    "\n",
    "        #Recuperando e gravando arquivo PDF\n",
    "        url = 'https://repositorio.unesp.br' + links[0]\n",
    "        pdf = requests.get(url, proxies = proxies)\n",
    "        filename = tese[1]['PDF_ID'] + '.pdf'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(pdf.content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
