{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização de Planejamento \n",
    "Trabalho final da disciplina Otimiação de Planejamento.\n",
    " \n",
    "**Problema**: Identificar o melhor conjunto de parâmetros para um algoritmo de Machine Learning \n",
    " \n",
    "Temos um algoritmo de machine learning que lê resumos de textos e classifica se eles pertencem ou não a uma determinada área de interesse. No entanto, há diversas possíveis parêmetros possíves para esse algoritmo. Queremos encontrar a combinação de parâmetros que retorne o medelo com melhor acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo arquivos JSON com os dados das teses Petrobras no BDTD, das teses no BDTD com assunto \"Petroleo\" e teses de assunto opostos ao de interesse Petrobras (\"Linguas, Letras e Artes\", \"Arqueologia\", \"Demografia\", ...). Eles já foram previamente preprocessados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teses_petroleo = pd.read_json('../BDTD/tese_petroleo_processada.json', orient = 'index')\n",
    "teses_areas = pd.read_json('../BDTD/tese_areas_processada.json', orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teses_petroleo = teses_petroleo.sample(30)\n",
    "#teses_areas = teses_areas.sample(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo o conjunto de treino, validação e de teste  \n",
    "  \n",
    "Vamos dividir os dados em 80% treino e 20% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que pega um dataframe com as teses e retorna três dataframes com dados de treino e teste.\n",
    "#'train' é a fração dos dados para treino, o restante é para teste\n",
    "def train_test(teses, train):\n",
    "    corte_train = int(round((len(teses)*train),0))\n",
    "    teses = teses.sample(frac=1)\n",
    "    teses_train = teses[:corte_train]\n",
    "    teses_test = teses[corte_train:]\n",
    "    return(teses_train, teses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceando as amostras. As duas classes terão o mesmo número de amostras\n",
    "teses_areas = teses_areas.sample(len(teses_petroleo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121\n",
      "2121\n"
     ]
    }
   ],
   "source": [
    "print(len(teses_areas))\n",
    "print(len(teses_petroleo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "teses_petroleo_train, teses_petroleo_test = train_test(teses_petroleo, 0.8)\n",
    "teses_areas_train, teses_areas_test = train_test(teses_areas, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "tese_train = teses_petroleo_train\n",
    "tese_train = tese_train.append(teses_areas_train)\n",
    "tese_train = tese_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Test\n",
    "tese_test = teses_petroleo_test\n",
    "tese_test = tese_test.append(teses_areas_test)\n",
    "tese_test = tese_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando texto e classe\n",
    "train_x = tese_train['Resumo Português:']\n",
    "train_y = tese_train['classe']\n",
    "\n",
    "test_x = tese_test['Resumo Português:']\n",
    "test_y = tese_test['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y  = encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petrobras =  0\n",
      "Outro =  1\n"
     ]
    }
   ],
   "source": [
    "print ('Petrobras = ', encoder.transform(['Petroleo'])[0])\n",
    "print ('Outro = ', encoder.transform(['Todas Areas'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engenharia de atributos \n",
    "Como atributos de entrada para o algoritmo de machine learning, será utiliza os vetores TF-IDF dos textos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(tese_train['Resumo Português:'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, será estruturado o algoritmo genético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialization_populacao_mlp(size_mlp):\n",
    "    pop =  [[]]*size_mlp\n",
    "    activation = ['identity','logistic', 'tanh', 'relu']\n",
    "    solver = ['lbfgs','sgd', 'adam']\n",
    "    learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "    pop = [[random.choice(activation), #activation\n",
    "            random.choice(solver),     #solver\n",
    "            randint(2,100),            #hiden layer 1\n",
    "            randint(2,100),            #hiden layer 2\n",
    "            randint(1,10000)/10000,          #alpha\n",
    "            random.choice(learning_rate) #learning rate\n",
    "           ] for i in range(0, size_mlp)]\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_mlp(mother_1, mother_2):\n",
    "    child = [mother_1[0], mother_2[1], mother_1[2], mother_2[3], mother_1[4], mother_2[5]]    \n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_mlp(child, prob_mut):\n",
    "    indiv = inicialization_populacao_mlp(1)[0]\n",
    "    for c in range(0, len(child)):\n",
    "        if np.random.rand() > prob_mut:\n",
    "            k = randint(0,5)\n",
    "            child[c][k] = indiv[k]\n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_fitness_mlp(pop, train_x, train_y, test_x, test_y, size_mlp): \n",
    "    fitness = [[]]*size_mlp\n",
    "    classifiers = [[]]*size_mlp\n",
    "    j = 0\n",
    "    for w in pop:\n",
    "        clf = MLPClassifier(activation=w[0],\n",
    "                            solver=w[1],\n",
    "                            hidden_layer_sizes=(int(w[2]), int(w[3])),\n",
    "                            alpha=float(w[4]),\n",
    "                            learning_rate = w[5],\n",
    "                            random_state=1,\n",
    "                            max_iter=5)\n",
    "        clf.fit(train_x, train_y)\n",
    "        fitness[j] = acc(clf.predict(test_x), test_y)\n",
    "        classifiers[j] = clf\n",
    "        j = j+1\n",
    "    return fitness, classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ag_mlp(train_x, train_y, test_x, test_y, num_epochs = 30, size_mlp=6, prob_mut=0.5):\n",
    "    pop = inicialization_populacao_mlp(size_mlp)\n",
    "    fitness, classifiers = function_fitness_mlp(pop,  train_x, train_y, test_x, test_y, size_mlp)\n",
    "    pop_fitness = np.array(list(zip(pop, fitness, classifiers)))\n",
    "    pop_fitness_sort = pop_fitness[pop_fitness[:,1].argsort()]\n",
    "    # population initialization\n",
    "    acc_epoch = []\n",
    "    for j in range(0, num_epochs):\n",
    "        #seleciona os pais\n",
    "        parent_1 = pop_fitness_sort[0:int(size_mlp/2)][:,0]\n",
    "        parent_2 = pop_fitness_sort[int(size_mlp/2)::][:,0]\n",
    "        #cruzamento\n",
    "        child_1 = [crossover_mlp(parent_1[i], parent_2[i]) for i in range(0, len(parent_1))]\n",
    "        child_1 = np.array(list(map(list, child_1)))\n",
    "        child_2 = [crossover_mlp(parent_2[i], parent_1[i]) for i in range(0, len(parent_1))]\n",
    "        child_2 = np.array(list(map(list, child_2)))\n",
    "        child_2 = mutation_mlp(child_2, prob_mut)\n",
    "        #calculates children's fitness to choose who will move on to the next generation\n",
    "        fitness_child_1, classifiers_child_1 = function_fitness_mlp(child_1,train_x, train_y, test_x, test_y, size_mlp)\n",
    "        fitness_child_2, classifiers_child_2 = function_fitness_mlp(child_2, train_x, train_y, test_x, test_y, size_mlp)\n",
    "        fitness_child_1 = np.array(list(zip(child_1, fitness_child_1, classifiers_child_1)))\n",
    "        fitness_child_2 = np.array(list(zip(child_2, fitness_child_2, classifiers_child_2)))\n",
    "        #selects next generation individuals\n",
    "        pop_all = np.concatenate((fitness_child_1, fitness_child_2, pop_fitness_sort), axis=0)\n",
    "        pop_all_sort = pop_all[pop_all[:,1].argsort()]\n",
    "        best_individual = pop_all_sort[-1]\n",
    "        # Print epoch results\n",
    "        print('Época = ', j)\n",
    "        print('Acurácia do melhor indivíduo = ', best_individual[1])\n",
    "        acc_epoch.append(best_individual[1])\n",
    "        pop_fitness_sort = pop_all_sort[size_mlp:]\n",
    "    return (pop_fitness_sort[0], acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época =  0\n",
      "Acurácia do melhor indivíduo =  0.8985849056603774\n",
      "Época =  1\n",
      "Acurácia do melhor indivíduo =  0.8985849056603774\n",
      "Época =  2\n",
      "Acurácia do melhor indivíduo =  0.8985849056603774\n",
      "Época =  3\n",
      "Acurácia do melhor indivíduo =  0.8997641509433962\n",
      "Época =  4\n",
      "Acurácia do melhor indivíduo =  0.8997641509433962\n",
      "Época =  5\n",
      "Acurácia do melhor indivíduo =  0.8997641509433962\n"
     ]
    }
   ],
   "source": [
    "best_individual, acc_epoch = ag_mlp(xtrain_tfidf, train_y, xtest_tfidf, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_individual)\n",
    "print(acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_epoch[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
